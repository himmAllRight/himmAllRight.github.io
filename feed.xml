<?xml version='1.0' encoding='UTF-8'?>
<rss version='2.0' xmlns:atom='http://www.w3.org/2005/Atom'>
<channel>
<atom:link href='http://ryan.himmelwright.net' rel='self' type='application/rss+xml'/>
<title>
Î» ryan himmelwright . net
</title>
<link>
http://ryan.himmelwright.net
</link>
<description>
Software Developer, Functional Programming and Linux Enthusiast
</description>
<lastBuildDate>
Wed, 02 Aug 2017 06:14:21 -0400
</lastBuildDate>
<generator>
clj-rss
</generator>
<item>
<guid>
http://ryan.himmelwright.net/posts/back-to-solus/
</guid>
<link>
http://ryan.himmelwright.net/posts/back-to-solus/
</link>
<title>
Back to Solus
</title>
<description>
&lt;p&gt;Well, that was faster than I expected. This past weekend, I wiped the Fedora installation on my main computer, and replaced it with Solus. My Fedora install broke, and I needed to use a Fedora Live CD to fix it. I thought that if I had to use a live CD to fix the issue, I might as well just do a clean install. With the idea of a clean install in my head... I thought (possibly influenced by my recent &lt;a href='http://ryan.himmelwright.net/posts/dabbling-with-go/#motivation'&gt;motivation&lt;/a&gt; to play with Go), that I might as well do the clean install with &lt;a href='solus-project.com/'&gt;Solus&lt;/a&gt;...&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more&amp;ndash;&gt;&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;nvidia&amp;#95;issues&quot;&gt;&lt;/a&gt;Nvidia Issues&lt;/h2&gt;&lt;p&gt;&lt;div class=&quot;video-container&quot;&gt; &lt;iframe width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/IVpOyKCNZYw?start=101&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; &lt;/div&gt; &lt;div id=&quot;caption&quot;&gt;Linus Torvalds famously flipped off Nvidia during a Q&amp;A&lt;/div&gt;&lt;/p&gt;&lt;p&gt;Basically, what I think happened was that my Nvidia drivers got messed up during an update. When I rebooted my computer, my screens were black. This happened no matter which kernel I booted into from Grub. I assumed it was a graphics problem and preceded to switch to another tty to login and fix the problem. I was able to get to a CLI login screen (with the normal &lt;code&gt;user:&lt;/code&gt; prompt) and tried login in. However, after typing in my user name and hitting enter, instead of being promoted for a password, I received an &quot;Error Logging In&quot; message. So, I tried the same thing with the root user account. Same thing. After typing in a user name, it yelled at me. There was no way to log in.&lt;/p&gt;&lt;p&gt;I jumped into the IRC chat and started asking around for advice. As always, everyone was very helpful and tried to help me troubleshoot. They shared my bewilderment. We came to the conclusion that it must of been something with the Nvidia drivers. I was told that it is common to have issues when installing the drivers from Nvidia's web site instead of the &lt;a href='https://rpmfusion.org/'&gt;RPM Fusion Repos&lt;/a&gt; (I intended to install from the RPM fusion repos, but I went to the nvidia site to find out what version to should use... and then just downloaded it from there. My bad :P).&lt;/p&gt;&lt;p&gt;Anyway, I quickly realized that at the very least, I would have to boot up and log into a Live CD to fix the problem. As stated in the intro paragraph, while waiting for the ISO image to download I thought that if I have to load up the CD, I might as well just do a clean Fedora 26 install. A couple minutes later as I was booting up the Live CD, I through that as long as I was reinstalling my OS... l should consider installing... Solus.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;installed&amp;#95;solus&quot;&gt;&lt;/a&gt;Installed Solus&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/back-to-solus/install.png&quot; alt=&quot;Installing Solus&quot; /&gt; &lt;div id=&quot;caption&quot;&gt;Installing Solus&lt;/div&gt;&lt;/p&gt;&lt;p&gt;With the Fedora live environment all booted and ready, I started downloading the latest Solus ISO (Budgie) on my other laptop. Once the ISO image was mounted to a drive, I booted it up and started installing Solus. After the install, I immediately updated because I knew there have been a TON of updates since the last ISO snapshot (mid-April). When I rebooted, I absolutely loved what I saw. It is amazing how much Solus and Budgie have improved, even during my short distro-hopping vacation.&lt;/p&gt;&lt;p&gt;Looking at my post history, it may appear as though I used Fedora for a few days, became fed up with it, and came running back to Solus. That is not entirely true. The reality is that I sat on writing my &lt;a href='../solus-to-fedora/'&gt;Fedora post&lt;/a&gt; for a long time. I used Fedora for about a month, and it was generally a great experience. If it didn't break, I probably would have stayed for a bit longer. When considering a new install though, I realized that I had missed Solus.&lt;/p&gt;&lt;p&gt;As of now, my plan is to keep using Solus, at least on my main computer. I am also hoping to get more involved with the project, and start packing up some software again. Maybe I can even help with some debugging and development. We shall see...&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Mon, 31 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/dabbling-with-go/
</guid>
<link>
http://ryan.himmelwright.net/posts/dabbling-with-go/
</link>
<title>
Dabbling with GO
</title>
<description>
&lt;p&gt;After spending most of this month's dedicated learning time working on &lt;a href='http://ryan.himmelwright.net/posts/solus-to-fedora/'&gt;system&lt;/a&gt;, &lt;a href='http://ryan.himmelwright.net/posts/creating-a-git-remote/'&gt;server&lt;/a&gt;, and &lt;a href='http://ryan.himmelwright.net/posts/issues-setting-up-ubiquiti-network/'&gt;network&lt;/a&gt; activities,  I have been itching to start some home programming again. To motivate myself, I even considered dabbling with a new programming language... and with very little internal debate, I decided to just &lt;a href='https://golang.org'&gt;Gopher&lt;/a&gt; it (I'm so sorry).&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;what&amp;#95;is&amp;#95;go?&quot;&gt;&lt;/a&gt;What is GO?&lt;/h2&gt;&lt;img src=&quot;../../img/posts/dabbling-with-go/gopher.png&quot; style=&quot;width: 30%; float: right; margin: 0px 10px 0px 10px;&quot;/)&lt;p&gt;Go (sometimes referred to as &quot;golang&quot;) is an open source programming language, developed in 2007 by a team at Google (Robert Griesemer, Rob Pike, and Ken Thompson). Distributed under a &lt;a href='https://golang.org/LICENSE'&gt;BSD-like license&lt;/a&gt;, Go is also maintained and developed by open source volunteers all over the world. &lt;/p&gt;&lt;p&gt;Like C, it is a compiled and statically typed language. Unlike C, Go includes garbage collection and memory safety features, as well as other design aspects that are reminiscent of modern dynamic languages like python (ex: type inference and package &lt;code&gt;import&lt;/code&gt; statements). Lastly, Go has a concurrent programming implementation that utilizes what are known as '&lt;a href='https://tour.golang.org/concurrency/1'&gt;goroutines&lt;/a&gt;'. Goroutines are special light-weight &quot;threads&quot; that can process many concurrent tasks. All of these features work together to form an extremely relevant language for modern computing.&lt;/p&gt;&lt;p&gt;Like the programming language itself, the Go project summarizes all of this in a nice and concise statement on their &lt;a href='https://golang.org/doc/'&gt;documentation page&lt;/a&gt;:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; The Go programming language is an open source project to make programmers more productive. Go is expressive, concise, clean, and efficient. Its concurrency mechanisms make it easy to write programs that get the most out of multicore and networked machines, while its novel type system enables flexible and modular program construction. Go compiles quickly to machine code yet has the convenience of garbage collection and the power of run-time reflection. It's a fast, statically typed, compiled language that feels like a dynamically typed, interpreted language.&lt;br /&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a name=&quot;motivation&quot;&gt;&lt;/a&gt;&lt;h2&gt;&lt;a name=&quot;motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h2&gt;&lt;/p&gt;&lt;p&gt;I've wanted to try &lt;a href='https://golang.org/'&gt;Go&lt;/a&gt; for a long time now. A couple of months ago, I was trying to decide if I should pursue learning Rust or Go. At the time, I ultimately ended up experimenting with &lt;a href='https://www.rust-lang.org/en-US/'&gt;Rust&lt;/a&gt;. I was toying with the idea of creating an experimental lisp, and Rust's feature set makes it great language for writing compilers and interpreters. However, while Rust is a great language, it can be quite complicated to learn. Go on the other hand, is apparently simpler and quick to grasp, which is &lt;a href='https://golang.org/doc/faq#creating_a_new_language'&gt;why it was created&lt;/a&gt; in the first place.&lt;/p&gt;&lt;p&gt;When the Solus team &lt;a href='https://solus-project.com/forums/viewtopic.php?f=13&amp;t=2634'&gt;announced&lt;/a&gt; that they were declaring Go a first class citizen language of the project, my interest peaked. &lt;a href='https://github.com/solus-project/solbuild'&gt;Solbuild&lt;/a&gt;, the Solus package build system was written in Go. In the announcement, the project stated that they intended to use Go for building tools. True to that statement, this past week, Ikey (the creator of Solus) published a patreon post detailing the new repo manager (&lt;a href='https://github.com/solus-project/ferryd'&gt;ferryd&lt;/a&gt;) he's been working on... again in Go. After reading that post, I decided it was time for me to give it a Go (again, very sorry).&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;installation&quot;&gt;&lt;/a&gt;Installation&lt;/h2&gt;&lt;p&gt;I first went to the Go &lt;a href='https://golang.org/doc/install'&gt;install page&lt;/a&gt; to figure out if there were any odd components to install. It didn't appear so. &lt;/p&gt;&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; Before progressing any further, I should point out that if you just want to &lt;em&gt;try&lt;/em&gt; go, the project has a little embedded editor/compiler on the &lt;a href='https://golang.org'&gt;home page&lt;/a&gt; of the website. Beyond that, they have an amazing &lt;a href='https://tour.golang.org/welcome/1'&gt;Go tour&lt;/a&gt; that also has an embedded programming environment, and can be completed entirely in a web browser.&lt;/p&gt;&lt;p&gt;After playing with the online editor online for a bit, I decided that I wanted to install Go on my system. I was on my NixOS laptop at the time, so I installed go with the command: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;nix-env -i go
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On Alakazam, it was&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo dnf install golang
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;(... and then when I jumped back to Solus on Alakazam, it was &lt;code&gt;sudo eopkg it golang&lt;/code&gt;... but more on that later...)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Next, I walked through the &lt;a href='https://golang.org/doc/install#testing'&gt;test your install&lt;/a&gt; steps, building a simple &quot;hello world&quot; app to make sure everything was working properly. This was especially important, given that I was on nixOS, which can sometimes be picky with system paths and environment variables. Luckily, everything worked fine. If I continue down the Go path, I might write a &quot;Getting started&quot; post to detail how to setup a proper Go environment on Linux.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;first&amp;#95;steps&quot;&gt;&lt;/a&gt;First Steps&lt;/h2&gt;&lt;p&gt;After confirming my install, I went back and continued  &lt;a href='https://tour.golang.org/welcome/1'&gt;A Tour of Go&lt;/a&gt; to better learn the language. I am interested to eventually read the &lt;a href='https://golang.org/doc/effective_go.html'&gt;Effective Go&lt;/a&gt; documentation. It will be interesting to simply &lt;em&gt;read&lt;/em&gt; the correct style and conventions for the language, instead of trudging through a holly war to find answers.&lt;/p&gt;&lt;p&gt;After working on the tutorial for awhile, I started playing around with the language on my own.  Below is a snippet of code I wrote while fooling around. It's nothing fancy. I was impressed though with how easy it really was to pick up the basics of the language and get going. I am excited to learn more.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;package main

import &amp;#40;
	&amp;quot;fmt&amp;quot;
	&amp;quot;runtime&amp;quot;
&amp;#41;

func main&amp;#40;&amp;#41; {
	fmt.Printf&amp;#40;&amp;quot;hello, world\n&amp;quot;&amp;#41;
	getOS&amp;#40;&amp;#41;
	fmt.Printf&amp;#40;&amp;quot;\n&amp;quot;&amp;#41; // I know this is dumb

	x, y := 74, 83
	sum := sumInts&amp;#40;x, y&amp;#41;
	fsum := factorial&amp;#40;sum&amp;#41;

	fmt.Printf&amp;#40;&amp;quot;sum: %v\n&amp;quot;, sum&amp;#41;
	fmt.Printf&amp;#40;&amp;quot;Factorial of sum&amp;#40;%v&amp;#41;: %v\n&amp;quot;, sum, fsum&amp;#41;
}

func sumInts&amp;#40;x int, y int&amp;#41; int {
	sum := x + y
	return sum
}

func factorial&amp;#40;n int&amp;#41; int {
	if n &amp;lt;= 1 {
		return 1
	} else {
		return n + factorial&amp;#40;n-1&amp;#41;
	}
}

func getOS&amp;#40;&amp;#41; {
	os := runtime.GOOS
	fmt.Printf&amp;#40;&amp;quot;OS: %v\n&amp;quot;, os&amp;#41; // impure
}

&lt;/code&gt;&lt;/pre&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Sun, 30 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/solus-to-fedora/
</guid>
<link>
http://ryan.himmelwright.net/posts/solus-to-fedora/
</link>
<title>
Migrating from Solus to Fedora for now
</title>
<description>
&lt;p&gt;For awhile, I have been debating the idea of switching back to Fedora (from Solus). At least on my &lt;a href='../../pages/homelab/#alakazam'&gt;main computer&lt;/a&gt;. First, let me state this right up front: I am still &lt;em&gt;very&lt;/em&gt; satisfied with Solus. I think it is one of the best current Linux distros, and I want to still contribute to the project. However, there are a few reasons why Solus isn't the best fit for my needs &lt;em&gt;right now&lt;/em&gt;, and I will highlight them below.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;why&amp;#95;switch&quot;&gt;&lt;/a&gt;Why Switch&lt;/h3&gt;&lt;center&gt;&lt;img alt=&quot;Solus and Fedora Logos&quot; src=&quot;../../img/posts/solus-to-fedora/logos.png&quot;  width=85%&gt;&lt;/center&gt;&lt;div id=&quot;caption&quot;&gt;The Solus (Left) and Fedora (right) Project Logos&lt;/div&gt;&lt;p&gt;The first phrase stated on the &lt;a href='https://solus-project.com'&gt;Solus Project homepage&lt;/a&gt; is &quot;Solus is an operating system that is designed for &lt;strong&gt;home computing&lt;/strong&gt;.&quot; I find this to be true, and Solus does a great job at it. The Linux community needs a few good, focused, distros. While I have been using Solus for my &quot;&lt;em&gt;home&lt;/em&gt;&quot; computing, the computing tasks I've focused on recently do not fall into the category of standard &lt;em&gt;home computing&lt;/em&gt; use. Recently, my main top computing activities and goals are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Writing (okay... but still)&lt;/li&gt;&lt;li&gt;Running all sorts of VMs&lt;/li&gt;&lt;li&gt;Trying various Server Technologies&lt;ul&gt;&lt;li&gt;ZFS&lt;/li&gt;&lt;li&gt;KVM&lt;/li&gt;&lt;li&gt;Containerization Technologies (LXC, Docker, ...)&lt;/li&gt;&lt;li&gt;Ansible and other automation tools&lt;/li&gt;&lt;li&gt;Etc.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Learning about Clustering&lt;ul&gt;&lt;li&gt;OpenMP&lt;/li&gt;&lt;li&gt;High Availability&lt;/li&gt;&lt;li&gt;Distributed File systems&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;Trying to get involved with some other Open Source Projects&lt;ul&gt;&lt;li&gt;Fedora (Infrastructure, Dev)&lt;/li&gt;&lt;li&gt;NixOS&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;As you can see, many of the above items are not desktop based, but really &lt;em&gt;server&lt;/em&gt; based operations. Solus is &lt;em&gt;not&lt;/em&gt; a server distribution, as it doesn't &lt;em&gt;try&lt;/em&gt; to be one. Which is a good thing. It is focused on its audience. I  just happen to not be in that audience at the moment.&lt;/p&gt;&lt;p&gt;Additionally, one of my goals for the near future is to transform my long-time Proxmox server into a &lt;a href='https://www.centos.org/'&gt;CentOS&lt;/a&gt; box. Using Fedora on my main workstation does help me get accustom to that environment. It also allows me to more accurately test out ideas before I plan the big move.&lt;/p&gt;&lt;p&gt;Lastly, I had been eyeing up the Plasma desktop, and wanted to try that out again. At the time of writing this post, Solus doesn't fully support the Plasma desktop (yet). However, Fedora &lt;em&gt;does&lt;/em&gt; have a &lt;a href='https://spins.fedoraproject.org/kde/'&gt;KDE Plasma Desktop Spin&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;the&amp;#95;switch&quot;&gt;&lt;/a&gt;The Switch&lt;/h3&gt;&lt;p&gt;&lt;center&gt; &lt;img alt=&quot;Solus and Fedora Logos&quot; src=&quot;../../img/posts/solus-to-fedora/fedora25.png&quot;  width=85%&gt; &lt;/center&gt; &lt;div id=&quot;caption&quot;&gt;Screenfetch on my new Fedora Install&lt;/div&gt;&lt;/p&gt;&lt;p&gt;I eventually (and somewhat sporadically), made the switch to Fedora. I switched the week before the 26 release, so I decided to start with 25, and then upgrade later (although I did test out 26 on my other laptop). This let me ensure that the 26 issues were ironed out before upgrading. I also got to test out the &lt;code&gt;dnf&lt;/code&gt; system upgrade process. I recorded &lt;em&gt;post-switch&lt;/em&gt; notes during the last few weeks to document how everything went.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&quot;Well... I did it. I switched to Fedora on Alakazam yesterday. I went with the Fedora 25 KDE spin and did all of the hoops to get that up and going. Not only is it taking some time to get used to Fedora again, but I am needing to reacquaint myself with the KDE environment... it does seem different that other Plasma setups I've used in the past... But I like it.&quot; &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;I got used to it in no time:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;Alakazam is doing well on Fedora. I've been enjoying it and think I will stay on it. &lt;/p&gt;&lt;/blockquote&gt;&lt;h3&gt;&lt;a name=&quot;updates&quot;&gt;&lt;/a&gt;Updates&lt;/h3&gt;&lt;p&gt;I ran some updates that I thought &lt;em&gt;might&lt;/em&gt; be problematic, based on &lt;a href='../back-on-arch/#fedora'&gt;previous issues&lt;/a&gt; I've encountered with Fedora. I made sure to note the results as well. The first notable update was from the first time I updated the kernel, and the second was  upgrading from Fedora 25 to 26. Both updates went very smoothly without any issues:&lt;/p&gt;&lt;h4&gt;&lt;a name=&quot;kernel&amp;#95;upgrade&quot;&gt;&lt;/a&gt;Kernel Upgrade&lt;/h4&gt;&lt;blockquote&gt;&lt;p&gt;So I am about to do my first Kernel update since being on Fedora again (on Alakazam). We'll see how the video drivers respond... To note, I am still on 25 so it hopefully won't be too bad... &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;em&gt;...reboot...&lt;/em&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;No issues whatsoever :) &lt;/p&gt;&lt;/blockquote&gt;&lt;h4&gt;&lt;a name=&quot;upgrade&amp;#95;to&amp;#95;fedora&amp;#95;26&quot;&gt;&lt;/a&gt;Upgrade to Fedora 26&lt;/h4&gt;&lt;center&gt;&lt;img alt=&quot;Solus and Fedora Logos&quot; src=&quot;../../img/posts/solus-to-fedora/fedora26-upgrade.png&quot;  width=85%&gt;&lt;/center&gt;&lt;div id=&quot;caption&quot;&gt;I upgraded my Fedora 25 Plasma Install to Fedora 26&lt;/div&gt;&lt;p&gt;Other than some odd issues with the GUI tool, the upgrade from 25 to 26 was  smooth and uneventful.&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;I just upgraded Alakazam from Fedora 25 KDE, to Fedora 26 this morning. I couldn't really get the graphical installer to start, but that could be because I have several desktop environments setup (Plasma &amp; Gnome), so it may have been confused (I was using the Gnome Software App in Plasma...)&lt;br /&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;I just did the upgrade using the (command line) dnf upgrade tool, like I normally use, and it worked wonderfully. It even looks like my nvidia drivers stayed and my monitors were configured correctly after rebooting. The only difference is I don't seem to have the same Plasma animations I had before, but that is fine, and likely part of the update.&lt;br /&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;So that it. Those are my reasons for switching (for now), and the results of my switch. I am still happy with Fedora, at least on Alakazam, and will likely remain on it until I have a convincing reason to leave.&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Tue, 25 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/creating-a-git-remote/
</guid>
<link>
http://ryan.himmelwright.net/posts/creating-a-git-remote/
</link>
<title>
Creating a git Repo Remote
</title>
<description>
&lt;p&gt;For over a year or so, I have been using a self-hosted &lt;a href='https://about.gitlab.com/'&gt;Gitlab&lt;/a&gt; to host all of my private repos. For a few months now, I have been meaning to migrate my Gitlab repos to bare, minimal ones, hosted directly on a server. The majority of my code/configs are hosted publicly on &lt;a href='https://github.com/himmAllRight'&gt;my Github&lt;/a&gt; page, and it really doesn't make sense to maintain a full Gitlab instance for the few (like...2) private repositories that I keep. Moving the git repos to new ones right on the server is actually fairly simple. For such a simple process, all the guides I saw online went way above and beyond what I needed. So, here are the &lt;em&gt;two&lt;/em&gt; steps I did to migrate my repos.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;ssh&amp;#95;keys&quot;&gt;&lt;/a&gt;SSH Keys&lt;/h3&gt;The &lt;em&gt;pre&lt;/em&gt; (and somewhat optional) step to is to setup ssh key authentication. If ssh keys are not configured, git will prompt for the password of the repo's host user . When using a git service (ex: Github or Gitlab), this is usually unknown, so ssh keys are required. When rolling your own remote git repo, the password will likely be known. Still, setting up ssh authentication makes the process easier and more secure. If you do not know how to configure ssh keys, I included a small ssh key how-to &lt;a href='../Ansible-On-Pi-Cluster#ssh'&gt;here&lt;/a&gt; in &lt;a href='../Ansible-On-Pi-Cluster'&gt;a previous post&lt;/a&gt;. Many of the git guides out there call for creating a &lt;code&gt;git&lt;/code&gt; user and setting up ssh keys with that user. This is a great idea if multiple people need access to the git repo. However, for my purposes I will use my username, as I will be the only one accessing it (which in my case is a good thing). &lt;h3&gt;&lt;a name=&quot;creating&amp;#95;server&amp;#95;repo&quot;&gt;&lt;/a&gt;Creating Server Repo&lt;/h3&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/creating-remote-git-repo/init-bare-repo.png&quot; name=&quot;bare init&quot; onmouseover=&quot;this.src='../../img/posts/creating-remote-git-repo/init-bare-repo.gif'&quot; onmouseout=&quot;this.src='../../img/posts/creating-remote-git-repo/init-bare-repo.png'&quot;&gt;  &lt;/center&gt; &lt;div id=&quot;caption&quot;&gt;Creating the remote git repo&lt;/div&gt;&lt;/p&gt;&lt;p&gt;Once ssh authentication is configured, ssh into the remote server that will host the git repository. Creating the remote repo is a simple process. First, make a directory for the repo (the normal convention is to use a &lt;code&gt;.git&lt;/code&gt; ending: &lt;code&gt;REPO-NAME.git&lt;/code&gt;). Next, jump into the created directory (&lt;code&gt;cd&lt;/code&gt;) and run the command &lt;code&gt;git init &amp;ndash;bare&lt;/code&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;mkdir REPO-NAME.git
cd REPO-NAME.git
git init --bare
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This will initialize the repository inside that directory. The &lt;code&gt;git init&lt;/code&gt; command is used to create a git repository. The &lt;code&gt;&amp;ndash;bare&lt;/code&gt; option flag tells git to treat it as a bare repository. Bare repositories do not contain a working or checked out copy of the source files. Thus, the plain &lt;code&gt;git init&lt;/code&gt; command creates a &lt;em&gt;working&lt;/em&gt; repo, while &lt;code&gt;git init &amp;ndash;bare&lt;/code&gt; is used to create a &lt;em&gt;sharing(server) repo&lt;/em&gt;. This allows the working repositories of many developers to be synced with the server repo. &lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;cloning&amp;#95;repo&quot;&gt;&lt;/a&gt;Cloning Repo&lt;/h3&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/creating-remote-git-repo/clone-new-remote.png&quot; name=&quot;bare init&quot; onmouseover=&quot;this.src='../../img/posts/creating-remote-git-repo/clone-new-remote.gif'&quot; onmouseout=&quot;this.src='../../img/posts/creating-remote-git-repo/clone-new-remote.png'&quot;&gt;  &lt;/center&gt; &lt;div id=&quot;caption&quot;&gt;Clone the Remote to a Local Dir&lt;/div&gt;&lt;/p&gt;&lt;p&gt;If the remote git repository is a totally new repository, it can be cloned down to a working directory on a developer machine fairly easily:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;git clone user@hostname:REPONAME.git
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;pointing&amp;#95;local&amp;#95;repo&amp;#95;to&amp;#95;server&quot;&gt;&lt;/a&gt;Pointing Local Repo to Server&lt;/h3&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/creating-remote-git-repo/point-to-new-remote.png&quot; name=&quot;bare init&quot; onmouseover=&quot;this.src='../../img/posts/creating-remote-git-repo/point-to-new-remote.gif'&quot; onmouseout=&quot;this.src='../../img/posts/creating-remote-git-repo/point-to-new-remote.png'&quot;&gt;  &lt;/center&gt; &lt;div id=&quot;caption&quot;&gt;Pointing a working repo to the new remote&lt;/div&gt;&lt;/p&gt;&lt;p&gt;However, I already had an existing working repository that I wanted to sync with the new remote shared repo. With the remote repo initialized, I wanted to point my existing git repository on the local machine to it. To do this, enter the directory of the git repository, and edit the config the (&lt;code&gt;.git/config&lt;/code&gt;). To redirect the repo to point to the new remote, edit the &lt;code&gt;url&lt;/code&gt; line to the location of the repo:&lt;/p&gt;&lt;p&gt;&lt;code&gt;username@hostname:reponame&lt;/code&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;cd Server-Node-Files
vim ./git/config
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After pointing to the new remote, feel free to push the content to it: (Only push everything (*) if it is desired)&lt;/p&gt;&lt;pre&gt;&lt;code&gt;git add &amp;#42;
git commit -m &amp;quot;First push to new Remote&amp;quot;
git push origin master
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And that's it. Enjoy spinning up and using your own personal git repositories! &lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Wed, 19 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/issues-setting-up-ubiquiti-network/
</guid>
<link>
http://ryan.himmelwright.net/posts/issues-setting-up-ubiquiti-network/
</link>
<title>
Encountered Issues Setting Up Ubiquiti Network
</title>
<description>
&lt;p&gt;This past weekend, I setup my new ubiquiti network. It actually took up a good portion of Sunday, because I ran into a few minor issues. Fortunately/Unfortunately, these issues were mostly because it my first time configuring this type of setup, and there was a lot of trial and error. The basic network is now all configured and has been running great. It was a good day and I learned a lot :). In fact, I am confident that if I had to start over from scratch, the process would take me about 10-15 minutes. Just to be sure, I'm  going to quickly jot down the major pain points I experienced my first time around. &lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;trouble&amp;#95;connecting&amp;#95;to&amp;#95;the&amp;#95;edgerouter-x&amp;#95;for&amp;#95;initial&amp;#95;setup&quot;&gt;&lt;/a&gt;Trouble Connecting to the EdgeRouter-x for Initial Setup&lt;/h2&gt;&lt;center&gt;&lt;img alt=&quot;During initial setup, I was connecting the router wrong&quot; src=&quot;../../img/posts/ubiquiti-setup-issues/wrong-router-connection.png&quot; width=&quot;90%&quot;&gt;&lt;/center&gt;&lt;div id=&quot;caption&quot;&gt;During initial setup, I was connecting the router wrong&lt;/div&gt;&lt;p&gt;The edgerouter needed to be directly connected to a computer during its initial setup, to make the EdgeOS configuration wizard accessible. The instructions clearly stated to connect an ethernet cable from my laptop to the &lt;code&gt;eth0/POE&lt;/code&gt; port on the edgerouter, but I guess I didn't believe them.&lt;/p&gt;&lt;p&gt;Instead, I plugged the ethernet cable from my modem into &lt;code&gt;eth0&lt;/code&gt;, and my computer to &lt;code&gt;eth1&lt;/code&gt;. That didn't work. However, once I &lt;em&gt;properly&lt;/em&gt; connected the devices (and manually set a static IP on my laptop, &lt;code&gt;192.168.1.2&lt;/code&gt; for example), I was able to access the configuration page in my browser via &lt;code&gt;https://192.168.1.1&lt;/code&gt; (don't forget the &lt;em&gt;s&lt;/em&gt; in &lt;em&gt;https&lt;/em&gt;). Lesson Learned: manuals are (&lt;em&gt;usually&lt;/em&gt;) not out to get you.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;setting&amp;#95;up&amp;#95;poe&amp;#95;and&amp;#95;connecting&amp;#95;the&amp;#95;ap&quot;&gt;&lt;/a&gt;Setting up POE and Connecting the AP&lt;/h2&gt;This was not actually an issue I encountered, but rather a confusion. I was unsure what the best setup for the &lt;a href='https://en.wikipedia.org/wiki/Power_over_Ethernet'&gt;POE&lt;/a&gt; hardware was. At first, I had the POE adaptor connected between the edgerouter and the AP, because I wasn't sure if it could optimally power both devices. I found an &lt;a href='https://www.youtube.com/watch?v=f7FeYsJqotc&amp;list=PLDBkup9c8YMgZaE50hAjP7rbbVriTlyQf&amp;index=1'&gt;informative guide&lt;/a&gt; that indicated that the POE adaptor could indeed power both.&lt;p&gt;&lt;p&gt;&lt;pre&gt;&lt;code&gt;Modem  --
        |
         --&amp;gt; POE Adaptor --&amp;gt; &amp;#40;&amp;#42;eth0&amp;#42;&amp;#41;  edgerouter-x  &amp;#40;&amp;#42;eth4&amp;#42;&amp;#41; --&amp;gt; AP Lite
        |
Power  --
 &lt;/code&gt;&lt;/pre&gt; &lt;div id=&quot;caption&quot;&gt;Digram describing the correct link up&lt;/div&gt; &lt;/p&gt;&lt;/p&gt;&lt;p&gt;Once I swapped the cables all around, I had to go into the router configuration and enable the POE for &lt;code&gt;eth4&lt;/code&gt;. Afterwards, the AP lit up, indicating that it was connected and powered.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;issues&amp;#95;linking/configuring&amp;#95;the&amp;#95;ap&quot;&gt;&lt;/a&gt;Issues linking/configuring the AP&lt;/h2&gt;This was the problem I spent the most time on. I had to install the configuration software for the Ubiquiti access point, but the &quot;Linux binary&quot; was a .deb, and I didn't feel like extracting the contents of the package so that I could install it on Solus (yet). So instead, I spun up a few Ubuntu VMs to try it out, but I over-looked the fact that VMs on my laptop use a different subnet (192.168.&lt;strong&gt;122&lt;/strong&gt;. &amp;#42;) for the virtual network. I had hoped that because the VM's network was routed through my laptop, which was connected directly to the edgerouter, it would still be able to see the access point. Regardless... the AP couldn't see the VM and vice versa. Finally, I admitted that the issues were most likely caused by the 192.168.122.* IP address that the VM was assigned.&lt;p&gt;&lt;center&gt; &lt;img alt=&quot;During initial setup, I was connecting the router wrong&quot; src=&quot;../../img/posts/ubiquiti-setup-issues/ubuntu.png&quot; width=&quot;45%&quot;&gt; &lt;img alt=&quot;During initial setup, I was connecting the router wrong&quot; src=&quot;../../img/posts/ubiquiti-setup-issues/venomoth.png&quot; width=&quot;35%&quot;&gt; &lt;/center&gt; &lt;div id=&quot;caption&quot;&gt;I spun up a new Ubuntu VM (Venomoth) to host the Ubifi controller&lt;/div&gt;&lt;/p&gt;&lt;p&gt;By this point, I had also learned that the Linux software is more of a server service, and not a GUI desktop application. So, I concluded that spinning up a dedicated VM on my server to host the wifi controller was worth it. Virtual machines hosted on my server automatically get configured on the main subnet, so it also resolved my issue. I was able to detect and configure the access point immediately. This setup made more sense anyway, as I can always connect to the AP controller by going to the VM's IP on my browser,  just like I can with my router.&lt;/p&gt;&lt;p&gt;Well, that was all of my setup &quot;&lt;em&gt;issues&lt;/em&gt;&quot;. There was nothing I would consider to be an actual &lt;em&gt;issue&lt;/em&gt;, just some confusions of an Ubiquiti/POE first-timer. Like I stated earlier, I am sure I could redo the setup in about 15 minutes without any issues... 10 now that I recorded everything in the post!&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Thu, 29 Jun 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/upgrading-network-to-ubiquiti/
</guid>
<link>
http://ryan.himmelwright.net/posts/upgrading-network-to-ubiquiti/
</link>
<title>
Home Network Ubiquiti Upgrade
</title>
<description>
&lt;p&gt;A few weeks ago, I went back to Pennsylvania for a week to attend my college swim team reunion, and my brother's high school graduation. While I was away, the wifi-router Rebecca and I were using decided to die (of course). When I returned, I setup our old router as a &lt;em&gt;temporary&lt;/em&gt; fix. It was terrible. So, I began researching how I should upgrade our network. This time around, I am doing this &lt;em&gt;correctly&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/upgrading-to-ubiquiti-edgerouter/linksys-WRT1900.png&quot; width= 45%&gt; &lt;img src=&quot;../../img/posts/upgrading-to-ubiquiti-edgerouter/linksys-E1200.png&quot; width= 45%&gt; &lt;/center&gt; &lt;div id=&quot;caption&quot;&gt;The Linksys WRT-1900 that died (left), and the terrible backup Linksys E1200 (right)&lt;/div&gt;&lt;/p&gt;&lt;p&gt;The router that died was a Linksys WRT 1900. When I got home, I setup our old router as a temporary fix. It's a very basic Linksys E1200. After using it for just a few hours, I remembered why I hated it so much. It is slower than a snail, and seems to stop working each day or so, requiring me to unplug and re-plug it daily (I think it is something with DHCP. It keeps trying to reassign IPs to devices, and then doesn't seem to understand how to accept their requests afterwards). Thus, the more &lt;em&gt;temporary&lt;/em&gt; this solution was, the better.&lt;/p&gt;&lt;p&gt;If I am redoing our network setup, I want to do it &lt;em&gt;properly&lt;/em&gt; this time, splitting out the router from the wireless access point using &lt;em&gt;good&lt;/em&gt; hardware and software. My plan is to get an ubiquity edge-router-x, and pair it with an Ubiquiti wireless access point.&lt;/p&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/upgrading-to-ubiquiti-edgerouter/edgerouter-x.png&quot; alt=&quot;Ubiquity Edgerouter-x&quot; width=&quot;45%&quot;&gt; &lt;img src=&quot;../../img/posts/upgrading-to-ubiquiti-edgerouter/ap-ac-lite.png&quot; alt=&quot;Ubiquity Access Point Lite&quot; width=&quot;45%&quot;&gt; &lt;/center&gt; &lt;div id=&quot;caption&quot;&gt;The EdgeRouter-x (right) and an Ubiquity access point lite (right)&lt;/div&gt;&lt;/p&gt;&lt;p&gt;Originally I wanted to build a small pfsense box to use as a router, but after digging a little deeper and doing some research, I saw that the EdgeRouter would more than meet my needs and is a great start to a network upgrade. Additionally, at $50 (USD), it truly is a great deal. As for the wireless access point, I was always considering an UniFi device, and I thought the EdgeRouter should pair rather seamlessly, considering both products are made by Ubiquiti.&lt;/p&gt;&lt;p&gt;From what I read, the EdgeRouter is a great router with an okay firewall, while pfsense is an amazing firewall that can do routing. So, if I want to dig more into pfsense in the future, I can still set up a firewall box, and connect it in front of the router.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Modem --&amp;gt; pfsense --&amp;gt; EdgeRouter-x -&amp;gt; devices
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So... I think I've finalized my decision and will purchase the items soon. I will update when I get them.&lt;/p&gt;&lt;p&gt;&lt;div id=&quot;caption&quot;&gt;Update (06/24/2017): I have followed through with this purchase, and the items arrived from Amazon. Expect a post or two about my experience setting them up (and yes, I added this update before actually publishing this post)&lt;/div&gt;&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Mon, 26 Jun 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/Started-Using-i3blocks/
</guid>
<link>
http://ryan.himmelwright.net/posts/Started-Using-i3blocks/
</link>
<title>
Refreshing my i3 setup with i3blocks
</title>
<description>
&lt;p&gt;The last couple of weeks I have shifted back to using the i3 window mangers. When I fired it up, my fingers danced across the keyboard, remembering all of the personalized keybindings I have cultivated in my i3 configuration over the years. It is a simple, beautiful setup... well, beautiful minus one of the components. My i3status bar was looking rather bland and dated, especially compared some of the i3 setups posted by all the cool kids over at &lt;a href='https://www.reddit.com/r/unixporn/'&gt;/r/unixporn&lt;/a&gt;. I decided it was time for a refresh.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;i3status&quot;&gt;&lt;/a&gt;i3status&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/starting-i3/i3status.png&quot; alt=&quot;One of my simple i3status setups&quot; /&gt; &lt;div id=&quot;caption&quot;&gt;One of my simple i3status setups&lt;/div&gt;&lt;/p&gt;&lt;p&gt;When I first configured i3 several years ago, I used i3status because it was easy to use with i3 and did everything by default. Over time, I learned how to create and modify &lt;a href='https://github.com/himmAllRight/dotfiles/blob/master/i3/.config/i3/i3status.conf'&gt;my own .i3status.conf&lt;/a&gt; so that I could get it to play nice with un-standerd configurations (ex: &lt;code&gt;/Data&lt;/code&gt; partitions and such). While i3status served me well for many years, using the same-old setup has become boring. I started noticing several other nice looking status bar tools being used in i3 setups, and wanted to try them out.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;polybar&quot;&gt;&lt;/a&gt;Polybar&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/starting-i3/polybar.png&quot; alt=&quot;The example polybar&quot; /&gt; &lt;div id=&quot;caption&quot;&gt;The example polybar&lt;/div&gt;&lt;/p&gt;&lt;p&gt;The first bar I saw and tried was &lt;a href='https://github.com/jaagr/polybar'&gt;polybar&lt;/a&gt;. I started with it because some of the examples look awesome. It looks very modern and has an infinite number of features. I set it up and was able to use the example bar just fine. However, when I started to customize my own, I started to run into a few issues. The biggest issue was polybar not detecting my work-space names, along with other elements. Additionally, due to the support for several window managers, the example configuration file seemed cluttered, and I was never sure what I could edit, and what I should delete. After some frustration, I decided put it aside for now. I might come back to it one day when I'm bored.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;i3blocks&quot;&gt;&lt;/a&gt;i3blocks&lt;/h2&gt;Next, I learned of &lt;a href='https://github.com/vivien/i3blocks'&gt;i3blocks&lt;/a&gt;. It appeared to have everything I wanted in a status bar, yet remained simple, respecting the &lt;a href='https://i3wm.org/docs/i3bar-protocol.html'&gt;i3bar protocol&lt;/a&gt;. So I gave it a whirl.&lt;h3&gt;&lt;a name=&quot;downloading&amp;#95;from&amp;#95;the&amp;#95;repos&quot;&gt;&lt;/a&gt;Downloading from the Repos&lt;/h3&gt;Just like installing any other package on Linux, I decided to first check to see it it was in the &lt;a href='https://dev.solus-project.com/'&gt;Solus Repos&lt;/a&gt;:&lt;pre&gt;&lt;code&gt;sudo eopkg sr i3block
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It was. So, I installed it (&lt;code&gt;sudo eopkg it i3blocks&lt;/code&gt;) and started learning how to setup my configuration.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;fonts&quot;&gt;&lt;/a&gt;Fonts&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/starting-i3/awesome-font.png&quot; alt=&quot;A Very Small Sampling of the Awesome Fonts&quot; /&gt; &lt;div id=&quot;caption&quot;&gt;A &lt;em&gt;Very Small&lt;/em&gt; Sampling of the Awesome Fonts&lt;/div&gt;&lt;/p&gt;&lt;p&gt;The first hurdle I came across when first launching i3blocks was that I did not have all the fonts used in the default configuration installed. I temporarily removed the special fonts from the config, just so I could check that everything was working. But what's the fun in that? One of the biggest reasons I wanted to redo my bar was to have cool modern icon fonts! So, I found the &lt;a href='http://fontawesome.io/'&gt;font awesome&lt;/a&gt; package in the Solus repos and installed it.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo eopkg it font-awesome-ttf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the awesome fonts at my disposal, I had a plethora of icons to use. So I went through and picked out icons for each of the work-space tabs and status markers.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;finding&amp;#95;git&amp;#95;repos&quot;&gt;&lt;/a&gt;Finding Git Repos&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/starting-i3/i3block-new-repo-examples.png&quot; alt=&quot;The example polybar&quot; /&gt; &lt;div id=&quot;caption&quot;&gt;Example of Modules in new i3-block repo&lt;/div&gt;&lt;/p&gt;&lt;p&gt;While researching how to configure i3blocks, I started encountering several different GitHub repos and forks of the project. Some forks seemed to have additional modules that my repo version didn't. I downloaded and built &lt;a href='https://github.com/Anachron/i3blocks'&gt;this one&lt;/a&gt; to try out. I then configured i3 to point to the new build instead, and got started setting up my own blocks.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;forking&amp;#95;my&amp;#95;own&amp;#95;for&amp;#95;solus&amp;#95;tweaks&quot;&gt;&lt;/a&gt;Forking my own for Solus Tweaks&lt;/h3&gt;As I was configuring the individual blocks, I noticed that many of them didn't work by default on my computers. I dug deeper by opening up and peeking at the actual bash scripts blocks refer to. I noticed that many of them were trying to query data from applications that are &lt;em&gt;not&lt;/em&gt; used in Solus. For example, the &lt;code&gt;battery&lt;/code&gt; block didn't work for me because it relied on &lt;code&gt;acpi&lt;/code&gt;, which, while often used in Arch Linux for battery information (I use it myself when on arch) is not packaged in Solus. Instead, Solus relies on &lt;code&gt;upower&lt;/code&gt;. To fix my issues, I cobbled together my own &lt;code&gt;battery&lt;/code&gt; bash script, that queried battery information using &lt;code&gt;upower&lt;/code&gt; instead. Note, the &lt;code&gt;BATTERY&amp;#95;ICON&lt;/code&gt; uses the battery fonts (which likely won't show in the browser). Unless it is charging... then it uses a lightning bolt :) .&lt;p&gt;&lt;p&gt;&lt;pre&gt;&lt;code&gt;#!/bin/bash

BATTERY=0
BATTERY&amp;#95;STATE=$&amp;#40;echo &amp;quot;${BATTERY&amp;#95;INFO}&amp;quot; | upower -i $&amp;#40;upower -e | grep 'BAT'&amp;#41; | grep -E &amp;quot;state|to\ full&amp;quot; | awk '{print $2}'&amp;#41;
BATTERY&amp;#95;POWER=$&amp;#40;echo &amp;quot;${BATTERY&amp;#95;INFO}&amp;quot; | upower -i $&amp;#40;upower -e | grep 'BAT'&amp;#41; | grep -E &amp;quot;percentage&amp;quot; | awk '{print $2}' | tr -d '%'&amp;#41;
URGENT&amp;#95;VALUE=10

if &amp;#91;&amp;#91; &amp;quot;${BATTERY&amp;#95;POWER}&amp;quot; -gt 87 &amp;#93;&amp;#93;; then
    BATTERY&amp;#95;ICON=&amp;quot;ï&amp;quot;
elif &amp;#91;&amp;#91; &amp;quot;${BATTERY&amp;#95;POWER}&amp;quot; -gt 63 &amp;#93;&amp;#93;; then
     BATTERY&amp;#95;ICON=&amp;quot;ï&amp;quot;
elif &amp;#91;&amp;#91; &amp;quot;${BATTERY&amp;#95;POWER}&amp;quot; -gt 38 &amp;#93;&amp;#93;; then
     BATTERY&amp;#95;ICON=&amp;quot;ï&amp;quot;
elif &amp;#91;&amp;#91; &amp;quot;${BATTERY&amp;#95;POWER}&amp;quot; -gt 13 &amp;#93;&amp;#93;; then
     BATTERY&amp;#95;ICON=&amp;quot;ï&amp;quot;
elif &amp;#91;&amp;#91; &amp;quot;${BATTERY&amp;#95;POWER}&amp;quot; -le 13 &amp;#93;&amp;#93;; then
     BATTERY&amp;#95;ICON=&amp;quot;ï&amp;quot;
else
    BATTERY&amp;#95;ICON=&amp;quot;ï&amp;quot;
fi


if &amp;#91;&amp;#91; &amp;quot;${BATTERY&amp;#95;STATE}&amp;quot; = &amp;quot;discharging&amp;quot; &amp;#93;&amp;#93;; then
    echo &amp;quot;${BATTERY&amp;#95;ICON} ${BATTERY&amp;#95;POWER}%&amp;quot;
    echo &amp;quot;${BATTERY&amp;#95;ICON} ${BATTERY&amp;#95;POWER}%&amp;quot;
    echo &amp;quot;&amp;quot;
else
    echo &amp;quot;ï§ ${BATTERY&amp;#95;POWER}%&amp;quot;
    echo &amp;quot;ï§ ${BATTERY&amp;#95;POWER}%&amp;quot;
    echo &amp;quot;&amp;quot;
fi

if &amp;#91;&amp;#91; &amp;quot;${BATTERY&amp;#95;POWER}&amp;quot; -le &amp;quot;${URGENT&amp;#95;VALUE}&amp;quot; &amp;#93;&amp;#93;; then
  exit 33
fi
 &lt;/code&gt;&lt;/pre&gt; &lt;/p&gt;&lt;/p&gt;&lt;p&gt;Over the past few weeks, it seems to work well enough. As I continued to &lt;em&gt;tweak&lt;/em&gt;, or downright &lt;em&gt;create&lt;/em&gt; blocks to work well in Solus, I eventually decided that it might be a good idea to just &lt;a href='https://github.com/himmAllRight/i3blocks'&gt;create my own fork&lt;/a&gt; of the repo. This way, I can have my own i3blocks repo that works well with Solus. I noticed that the implementation of &lt;code&gt;i3blocks&lt;/code&gt; found in the Solus repos is also using non-Solus items for it's scripts (ex: acpi for the battery). Maybe one of these days I'll jump into irc and see how people feel about swapping in mine instead (or at least one that works better in Solus)...&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;color&amp;#95;update&amp;#95;for&amp;#95;i3&amp;#95;&amp;&amp;#95;rofi&quot;&gt;&lt;/a&gt;Color Update for i3 &amp; rofi&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/starting-i3/rofi-run.png&quot; alt=&quot;New Color Scheme for rofi launcher&quot; /&gt; &lt;div id=&quot;caption&quot;&gt;New color scheme for rofi launcher&lt;/div&gt;&lt;/p&gt;&lt;p&gt;When I started using i3 several years ago, I used &lt;a href='http://tools.suckless.org/dmenu/'&gt;dmenu&lt;/a&gt; as my launcher (it's the launcher used in &lt;a href='http://dwm.suckless.org/'&gt;dwm&lt;/a&gt;, another tiling window manager I used to use). I eventually switched to &lt;a href='https://davedavenport.github.io/rofi/'&gt;rofi&lt;/a&gt; after seeing it used in some very nice window manager setups (sound familiar?). However, I always used the plain default theme and never bothered to improve it. With all the work I did making i3bars look nice, I thought I should at least make rofi match. Making the color theme wasn't nearly as hard as I anticipated it to be. That's mostly because I found and used the &lt;a href='https://davedavenport.github.io/rofi/p11-Generator.html'&gt;rofi theme generator&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/starting-i3/rofi-window.png&quot; alt=&quot;New rofi window switcher&quot; /&gt; &lt;/center&gt; &lt;div id=&quot;caption&quot;&gt;Newly configured rofi window switcher&lt;/div&gt;&lt;/p&gt;&lt;p&gt;While touching up rofi, I learned it can also switch through already opened windows (Previously, I  only used it to launch new programs). I really liked that in my new i3 setup, it also displayed the work-spaces, icon font and all. I immediately bound it to my Super+Tab key for easy use.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;conclusion&quot;&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;&lt;video width=100% controls&gt;  &lt;source src=&quot;../../img/posts/starting-i3/i3-gaps-demo.mp4&quot; type=&quot;video/mp4&quot;&gt;  &lt;source src=&quot;movie.ogg&quot; type=&quot;video/ogg&quot;&gt;Your browser does not support the video tag.&lt;/video&gt;&lt;div id=&quot;caption&quot;&gt;Little video demoing my new i3gaps setup with i3blocks&lt;/div&gt;&lt;p&gt;Thus far, I have been very satisfied with my current i3 setup. Replacing i3status with i3blocks, combined with adding small improvements, for example, the awesome fonts, really helped to enhance the look and feel of my i3 configuration. Additionally, ROFI much better now that it matches everything.&lt;/p&gt;&lt;p&gt;I am glad to be using i3 again. It is so efficient to use and I love flying around the work-spaces and windows. It is particularly useful on &lt;a href='../../pages/homelab/#kadabra'&gt;kedabra's&lt;/a&gt; 12&quot; screen, as it utilizes all of the limited resolution. If you have never used a tiling window manager in Linux, I strongly suggest you give it a shot. It can take some time to get up and going the first time, but once a custom configuration is built, it always feels like home.&lt;/p&gt;&lt;p&gt;To show off my new i3 setup with i3bars, I've posted a small video at the top of this section. Enjoy!&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Thu, 22 Jun 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/exporting-proxmox-vms/
</guid>
<link>
http://ryan.himmelwright.net/posts/exporting-proxmox-vms/
</link>
<title>
Exporting Proxmox VMs
</title>
<description>
&lt;p&gt;For a long time I have been thinking about replacing my server's proxmox install with vanilla Debian or CentOS, mostly for learning purposes. I would first setup zfs on the new system and import my existing data pools. Then, I would use either a system like ovrit or just plain kvm/lxc to run my VMs and containers. In order to do this though... I have to first figure out how export my containers and VMs running in Proxmox. As it turns out... exporting the VMs wasn't very hard...&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;exporting&amp;#95;proxmox&amp;#95;vm&amp;#95;disk&quot;&gt;&lt;/a&gt;Exporting Proxmox VM Disk&lt;/h2&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/exporting-proxmox-vms/proxmox-logo.png&quot; alt=&quot;Proxmox logo&quot; /&gt; &lt;/center&gt;&lt;/p&gt;&lt;p&gt;My Proxmox VMs are setup on an LVM virtual group, with each virtual drive being a lvm volume passed to the VM. So, I wanted to be able to extract these disks to something I could more easily transfer. I ended up converting the lvm volumes to qcow2 images because it was easy and I've actually experienced okay performance with qcow2 on my workstations. Additionally, qcow2 being a single file, is easy to move around and I can always convert them to something else on the final system. To export one of the VMs, I ran the command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;qemu-img convert -O qcow2 /dev/pve/vm-108-disk-1 /Data/freebsd-vm.qcow2
&lt;/code&gt;&lt;/pre&gt;That was it. It took a few minutes to finish, but honestly that is all I had to do (I'm sure I should of taken a snapshot or something then copy that, but this seemed to work fine). When it completed, I copied the image down to my desktop and decided to test it out with virt-manager.&lt;h2&gt;&lt;a name=&quot;importing&amp;#95;the&amp;#95;image&amp;#95;to&amp;#95;virt-manager&quot;&gt;&lt;/a&gt;Importing the image to Virt-Manager&lt;/h2&gt;&lt;p&gt;I opened up virt-manager and selected the button to create a new VM. At the first prompt, instead of selecting my usual &quot;Local install media (ISO image or CDROM)&quot; option, I choose to &quot;Import an existing disk image&quot;.&lt;/p&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/exporting-proxmox-vms/import-image.png&quot; alt=&quot;Proxmox logo&quot; /&gt; &lt;/center&gt;&lt;/p&gt;&lt;p&gt;At the second menu, I opened up the browse menu to see my already configured locations. From there, I found where I had saved the converted qcow2 image, and selected it.&lt;/p&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/exporting-proxmox-vms/select-qcow2-image.png&quot; alt=&quot;Proxmox logo&quot; /&gt; &lt;/center&gt;&lt;/p&gt;&lt;p&gt;Next, I continued setting up the virtual specs (CPU, RAM, etc.) for the machine just as I would with any other VM setup. When I was done, I started the VM and FreeBSD booted right up. I logged in and compared the installed applications and files with the still running proxmox VM. They were identical.&lt;/p&gt;&lt;p&gt;That's all I really have for this post. It was extremely simple to export the VMs. I know I'm not fully done yet and still have to import the VMs to the final system, but I'll save that for a later post. Right now... I have quite a few VM images to convert, so I might as well get started.&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Fri, 16 Jun 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/Updating-Pi-Cluster-With-Ansible/
</guid>
<link>
http://ryan.himmelwright.net/posts/Updating-Pi-Cluster-With-Ansible/
</link>
<title>
Updating the Pi Cluster with Ansible
</title>
<description>
&lt;p&gt;With Ansible configured on the Pi cluster, it is time to have it do something useful. When working with a clustered system, even the simplest tasks become tedious and time consuming. For example, updating the system. While I could manually update each of the 3 pi nodes, it is not scalable to 10 or 30 nodes, let alone hundreds or thousands. Tools like Ansible, make doing tasks such a supdating clustered systems, trivial again. In this post, I will walk through setting up an Ansible playbook to update my Pi cluster.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;hosts&amp;#95;file&quot;&gt;&lt;/a&gt;Hosts File&lt;/h3&gt;The first task when using Ansible is to setup the &lt;code&gt;hosts&lt;/code&gt; file. No, not the normal &lt;code&gt;/etc/hosts&lt;/code&gt; file, but the &lt;em&gt;other&lt;/em&gt; one &lt;em&gt;just&lt;/em&gt; for Ansible, which can be found at &lt;code&gt;/etc/ansible/hosts&lt;/code&gt;. Configuring the Ansible hosts file is fairly straightforward. Groups of computers are defined using &lt;code&gt;&amp;#91;brackets&amp;#93;&lt;/code&gt;, with computer ip/hostnames of the group are listed below. For example:&lt;p&gt;A nice feature of group definitions is that hierical structures can be constructed using the &lt;code&gt;:child&lt;/code&gt; suffix in order to create groups of groups. For example, for my &lt;a href='../../pages/homelab'&gt;homelab&lt;/a&gt;, I like to make an ansible hosts file that splits out my servers based on their distribution, and then group those by their packaging type. This makes it easier for me to do generic updates, which is what I mostly use ansible for (at this point). So, for example:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;#91;ubuntu&amp;#93;
mrmime
geodude

&amp;#91;debian&amp;#93;
ninetales

&amp;#91;fedora&amp;#93;
fedora-test

&amp;#91;centos&amp;#93;
tangels

&amp;#91;arch&amp;#93;
meowth
staryu
diglet

&amp;#91;deb:children&amp;#93;
ubuntu
debian

&amp;#91;rpm:children&amp;#93;
fedora
centos

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For use with the cluster, I kept it simple, although I did opt to create rpi/bpi subgroups:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;#91;cluster:children&amp;#93;
rpis
bpis

&amp;#91;rpis&amp;#93;
pi0
pi1

&amp;#91;bpis&amp;#93;
bpi
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;ping&amp;#95;hosts&quot;&gt;&lt;/a&gt;Ping Hosts&lt;/h3&gt;Once the hosts file is setup, it can be tested using the &lt;code&gt;ping&lt;/code&gt; module. I tested my &lt;code&gt;cluser&lt;/code&gt; group, as well as the &lt;code&gt;rpis&lt;/code&gt; and &lt;code&gt;bpis&lt;/code&gt; subgroups.&lt;pre&gt;&lt;code&gt;ansible rpis -m ping
ansible bpis -m ping
ansible cluster -m ping
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Assuming the steps of &lt;a href='../Ansible-On-Pi-Cluster'&gt;the last post&lt;/a&gt; were done correctly, this should work. If not, double check that post and make sure everything looks correct.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;playbooks&quot;&gt;&lt;/a&gt;Playbooks&lt;/h3&gt;After confirming that the hosts file is properly configured, I started to dig into playbooks. Playbooks are Ansible's scripting system used to configure, deploy, and orcistrate systems. They can describe ways in which systems should be configured (ex: enable ssh), or outline a set of steps for an IT task (ex: running updates, restarting a server). As stated in the &lt;a href='https://docs.ansible.com/ansible/playbooks.html'&gt;playbook documentation&lt;/a&gt;:&lt;p&gt;&lt;div id=&quot;post-quote&quot;&gt; &lt;em&gt;&quot;If Ansible modules are the tools in your workshop, playbooks are your instruction manuals, and your inventory of hosts are your raw material.&quot;&lt;/em&gt; &lt;/div&gt;&lt;/p&gt;&lt;p&gt;Playbook files are expressed using &lt;a href='https://docs.ansible.com/ansible/YAMLSyntax.html'&gt;YAML syntax&lt;/a&gt;, which is easy to read, but still powerful. The first step when creating a new playbook, being a YAML file, is to set the header and footer. The header consists of three &lt;code&gt;-&lt;/code&gt;'s at the top of the file, and the footer ends the file with three periods (&lt;code&gt;.&lt;/code&gt;). This indicates the start and end of the document.&lt;/p&gt;&lt;p&gt;When writing a playbook to update the pi cluster, I first needed to declare what systems the playbook is used with. To do that, I used the &lt;code&gt;hosts&lt;/code&gt; key, and provided it with the &lt;code&gt;cluster&lt;/code&gt; group name, which is defined in my &lt;code&gt;/etc/ansible/hosts&lt;/code&gt; file, as the value.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
- hosts: cluster

...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After the hosts are defined, modules can be added to update the nodes. To list the tasks, I used the &lt;code&gt;taks:&lt;/code&gt; key, with the same indentation as the &lt;code&gt;hosts:&lt;/code&gt; keyword. Instead of using a single value, I provided the &lt;code&gt;tasks:&lt;/code&gt; keyword with a list of things to do. The first task I want to do when updating the nodes is to check that they running and connected. This can be accomplised with the &lt;a href='https://docs.ansible.com/ansible/ping_module.html'&gt;ping module&lt;/a&gt; that I used earlier in the post. The ping module will try to connect to each node, verify that a usable python is installed, and return &lt;code&gt;pong&lt;/code&gt; upon success. To add the module, I added &lt;code&gt;- ping: &amp;#126;&lt;/code&gt;, indented, to the line below &lt;code&gt;tasks:&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
- hosts: cluster

  tasks:
    - ping: &amp;#126;
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;apt&amp;#95;module&quot;&gt;&lt;/a&gt;Apt Module&lt;/h3&gt;After defining the ping module, I started to get a bit fancier. Well... a little bit fancier. Each node in my pi cluster is running some verison of Ubuntu, which uses apt as it's package manager. If I wanted to ssh into each node and update them manually, the steps I would follow would be to 1) run the command &lt;code&gt;sudo apt-get update&lt;/code&gt; to update the repository cache, and 2) run &lt;code&gt;sudo apt-get upgrade&lt;/code&gt; to actually install the updates. To recreate these commands in the playbook, I used the &lt;a href='https://docs.ansible.com/ansible/apt_module.html'&gt;apt module&lt;/a&gt;. To start with updating the repository cache, I added the following lines to my playbook:&lt;pre&gt;&lt;code&gt;- name: Update APT package manager repositories cache
  become: true
  apt:
    update&amp;#95;cache: yes
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;name:&lt;/code&gt; defines the name of the task, and is the text printed out to the console when executing this step of the playbook. Setting the &lt;a href='https://docs.ansible.com/ansible/become.html'&gt;&lt;code&gt;become&lt;/code&gt;&lt;/a&gt; key to &lt;code&gt;true&lt;/code&gt; tells Ansible to run the command with privilege escalation (sudo). Lastly, the remaining two lines run the &lt;code&gt;update&amp;#95;cache:&lt;/code&gt; functionality of the apt module. &lt;/p&gt;&lt;p&gt;With the repositories updated on each node, I can have ansible run the updates by adding the following lines to the playbook (after the cache update ones):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;- name: Upgrade installed packages
  become: true
  apt:
    upgrade: dist
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This set of commands is very similar to the last group. The &lt;code&gt;name:&lt;/code&gt; again provides a description of what the task is doing, and privilege escalation is used again via &lt;code&gt;become: true&lt;/code&gt;. The only difference is that the apt module is using the &lt;code&gt;upgrade: dist&lt;/code&gt; command instead. This will run the updates for any installed packages on the system.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;update&amp;#95;cluster&amp;#95;playbook&quot;&gt;&lt;/a&gt;Update Cluster Playbook&lt;/h3&gt;&lt;p&gt;I then had a completed playbook to update the pi cluster:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;---
- hosts: cluster

  tasks:
    - ping: &amp;#126;

    - name: Update APT package manager repositories cache
      become: true
      apt:
        update&amp;#95;cache: yes

    - name: Upgrade installed packages
      become: true
      apt:
        upgrade: dist
...

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The last step is to test it out! Playbooks can be executed using the &lt;code&gt;ansible-playbook&lt;/code&gt; command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;ansible-playbook update-cluster.yml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When running the playbook, ansible will first attempt to gather facts about each node, and then begin to run each of the tasks defined in the playbook. At each step, it will print out the &lt;code&gt;name&lt;/code&gt; of each task, followed by the status/result for each node. When it completes, all the nodes in the cluster should be updated. Now you can update three+ computers with a single command! Enjoy!&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Thu, 25 May 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/Ansible-On-Pi-Cluster/
</guid>
<link>
http://ryan.himmelwright.net/posts/Ansible-On-Pi-Cluster/
</link>
<title>
Configuring Ansible on the Pi Cluster
</title>
<description>
&lt;p&gt;In my &lt;a href='http://ryan.himmelwright.net/posts/Setting-up-the-pi-cluster/'&gt;previous post&lt;/a&gt;, I pieced together my &lt;a href='http://ryan.himmelwright.net/pages/homelab/#cluster'&gt;pi cluster&lt;/a&gt;, and installed variations of Ubuntu 16.04 Server on each of its nodes. With the cluster built, I quickly needed an easy way to maintain and interact with the system as a whole. This, is where &lt;a href='https://www.ansible.com/'&gt;Ansible&lt;/a&gt; comes in. In this post, I will walk through the steps I took to setup Ansible on my Cluster.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;ansible&quot;&gt;&lt;/a&gt;Ansible&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/setting-up-ansible-pi-cluster/ansible-logo.png&quot; style=&quot;width: 150px; float: left; margin: 0px 15px 5px 5px;&quot;/)&lt;/p&gt;&lt;p&gt;Ansible is an open source, configuration management and automation system. It is written in Python, and financially backed by &lt;a href='http://www.redhat.com'&gt;Red Hat&lt;/a&gt;. It simplifies the management of groups of computers, through the use of modules (standalone units of work. for example, apt, ping, rpm, etc). Ansible is script-able using simple YAML files, known as playbooks, that define a set of orchestration tasks for one or many computers. These scripts can be edited and version controlled, creating a simple &lt;a href='https://en.wikipedia.org/wiki/Infrastructure_as_Code'&gt;infrastructure as code&lt;/a&gt; setup.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;setting&amp;#95;up&amp;#95;the&amp;#95;user&amp;#95;account&quot;&gt;&lt;/a&gt;Setting up the User Account&lt;/h2&gt;When Ansible executes commands on the PIs, it will do so from the user-account (ryan) that I setup in the last post. However, many of these commands will require Root privledges. While I previously setup sudo and added the &lt;code&gt;ryan&lt;/code&gt; account to the &lt;code&gt;sudo&lt;/code&gt; group ... it required that I manually enter my password. Ansible did not like this, so I had to update the sudo configuration to allow the &lt;code&gt;ryan&lt;/code&gt; account to run &lt;code&gt;sudo&lt;/code&gt; commands with out a password. To do this, I opened the &lt;code&gt;sudoers&lt;/code&gt; file:&lt;pre&gt;&lt;code&gt;sudo visudo
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and added the following line to the end of the file:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;ryan  ALL=&amp;#40;ALL:ALL&amp;#41; NOPASSWD: ALL
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I repeated this on each of the nodes, and afterwards was no longer promted for a password when running &lt;code&gt;sudo&lt;/code&gt; commands. This made Ansible happy.&lt;/p&gt;&lt;p&gt;&lt;a name=&quot;ssh&quot;&gt;&lt;/a&gt;&lt;h2&gt;&lt;a name=&quot;setup&amp;#95;ssh&amp;#95;keys&quot;&gt;&lt;/a&gt;Setup SSH Keys&lt;/h2&gt;Well... &lt;em&gt;almost&lt;/em&gt; happy. &lt;/p&gt;&lt;p&gt;Ansible's main method of communication is via ssh, which by default, prompts me for a password when connecting. Ansible &lt;em&gt;really&lt;/em&gt; hates passwords. So, I had to configure ssh to use keys instead. Honestly, this is proabaly a good step to do regardless, now that the &lt;code&gt;ryan&lt;/code&gt; account no longer uses a password when running &lt;code&gt;sudo&lt;/code&gt;. To setup key-based logins, I appended the contents of my &lt;a href='../../pages/homelab/#alakazam'&gt;main computer&lt;/a&gt;'s ssh public key*, to each pi's &lt;code&gt;authorized&amp;#95;keys&lt;/code&gt; file. This can all be done using a magic one-line pipe command (x3, one for each pi):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;cat &amp;#126;/.ssh/id&amp;#95;rsa.pub | ssh pi0 &amp;quot;cat &amp;gt;&amp;gt; &amp;#126;/.ssh/authorized&amp;#95;keys&amp;quot;
cat &amp;#126;/.ssh/id&amp;#95;rsa.pub | ssh pi1 &amp;quot;cat &amp;gt;&amp;gt; &amp;#126;/.ssh/authorized&amp;#95;keys&amp;quot;
cat &amp;#126;/.ssh/id&amp;#95;rsa.pub | ssh bpi &amp;quot;cat &amp;gt;&amp;gt; &amp;#126;/.ssh/authorized&amp;#95;keys&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;&amp;#42;Note: If keys are not already generated, they can be created using the command:&lt;/em&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;ssh-keygen
&lt;/code&gt;&lt;/pre&gt;&lt;h4&gt;&lt;a name=&quot;key&amp;#95;only&amp;#95;login&quot;&gt;&lt;/a&gt;Key Only Login&lt;/h4&gt;To help secure access to the PIs (and to get on Ansible's good side), I configured sshd to disable password logins, and only allow connections from clients with approved keys. To disable password authentication, I opened the &lt;code&gt;/etc/ssh/sshd&amp;#95;config&lt;/code&gt; file, found the line containing &lt;code&gt;# PasswordAuthentication yes&lt;/code&gt;, changed the &lt;code&gt;yes&lt;/code&gt; to a &lt;code&gt;no&lt;/code&gt;, and unncommented it by removing the &lt;code&gt;#&lt;/code&gt;.&lt;p&gt;While I was in the &lt;code&gt;sshd&amp;#95;config&lt;/code&gt; file, I also set &lt;code&gt;PermitRootLogin&lt;/code&gt; to &lt;code&gt;no&lt;/code&gt;, for good measure.&lt;/p&gt;&lt;p&gt;Lastly, I reset the &lt;code&gt;sshd&lt;/code&gt; service and repeated the steps for each pi:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo systemctl restart sshd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Afterwards, I was unable to login to the PIs from a computer with unauthorized ssh keys.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/setting-up-ansible-pi-cluster/terminal-play.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/setting-up-ansible-pi-cluster/blocked-ssh-attempt.gif'&quot; onmouseout=&quot;this.src='../../img/posts/setting-up-ansible-pi-cluster/terminal-play.png'&quot;&gt; &lt;/p&gt;&lt;p&gt;But, I was still able to loging from the authorized computer.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/setting-up-ansible-pi-cluster/terminal-play.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/setting-up-ansible-pi-cluster/accepted-ssh-attempt.gif'&quot; onmouseout=&quot;this.src='../../img/posts/setting-up-ansible-pi-cluster/terminal-play.png'&quot;&gt; &lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;install&amp;#95;python&quot;&gt;&lt;/a&gt;Install Python&lt;/h2&gt;The last issue Ansible complained about was that it needed python installed on the Pis. Like everything else, the Bananna Pi already had this setup, but I had to install it on the two Raspberry Pis. It was simple enough:&lt;pre&gt;&lt;code&gt;sudo apt-get install python
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;a name=&quot;install&amp;#95;ansible&quot;&gt;&lt;/a&gt;Install Ansible&lt;/h2&gt;&lt;p&gt;I have a confession. So, you know how I have been fun and cheery by anthropomorphisizing Ansible, saying that it was &lt;em&gt;&quot;happy&quot;&lt;/em&gt; or &lt;em&gt;&quot;frusterated&quot;&lt;/em&gt; during the previous steps? That wasn't true. I made it up. Ansible wasn't &lt;em&gt;actually&lt;/em&gt; installed yet. &lt;em&gt;So... to install Ansible...&lt;/em&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo eopkg it ansible
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I used &lt;code&gt;eopkg&lt;/code&gt; because I am currently running &lt;a href='https://solus-project.com'&gt;Solus&lt;/a&gt;. You might use &lt;code&gt;sudo apt-get install ansible&lt;/code&gt;, &lt;code&gt;sudo dnf install ansible&lt;/code&gt;, or &lt;code&gt;pacaur -S ansible&lt;/code&gt; depending on whatever distro you are using.&lt;/p&gt;&lt;p&gt;That's all for &lt;em&gt;setting up&lt;/em&gt; Ansible. I'll cut this post off here, but in the next post, I'll walk through the steps on how to get Ansible to be useful.&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Sun, 21 May 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/Setting-up-the-pi-cluster/
</guid>
<link>
http://ryan.himmelwright.net/posts/Setting-up-the-pi-cluster/
</link>
<title>
Setting Up My Pi Cluster
</title>
<description>
&lt;p&gt;I have a Raspberry Pi 2, a Raspberry Pi 3, and a Banana Pi. A while ago, I constructed a small tower to house my pi devices. Since then, I have additionally acquired a power source, and some CAT6 cable to connect them all up to a switch. I hope to use the Pis as a mini clustered environment, where I can learn (and play) with some of the &quot;Devops&quot; technologies/techniques out there. This post will briefly explain the initial setup of &lt;a href='../../pages/homelab/#cluster'&gt;my cluster&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h1&gt;&lt;a name=&quot;setting&amp;#95;up&amp;#95;the&amp;#95;os&amp;#95;images&quot;&gt;&lt;/a&gt;Setting up the OS Images&lt;/h1&gt;Before doing anything with the hardware, I had to setup the pi &quot;hard drives&quot; (micro SD cards), so they could boot. &lt;h3&gt;&lt;a name=&quot;ubuntu&amp;#95;for&amp;#95;raspberry&amp;#95;pi&quot;&gt;&lt;/a&gt;Ubuntu for Raspberry PI&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/Setting-Up-Pi-Cluster/ubuntu-logo.jpg&quot; style=&quot;width: 200px%; float: right; margin: 0px 10px 0px 10px;&quot;/&gt;&lt;/p&gt;&lt;p&gt;After mucking around with Rapsbian and Hypriot one Sunday, I decided to just go with a plain Ubuntu image for the Raspberry Pis. I don't have anything against these specific OSes, but I am mostly setting up this cluster to simulate what I would do on a &quot;real&quot; system. For me, that often means using a straight OS like Ubuntu.&lt;/p&gt;&lt;p&gt;Luckily, Canonical makes special &lt;a href='https://wiki.ubuntu.com/ARM/RaspberryPi'&gt;Ubuntu ARM images&lt;/a&gt;, specifically for the Raspberry Pi. I download the 16.04 server version for both the &lt;a href='http://cdimage.ubuntu.com/ubuntu/releases/16.04/release/ubuntu-16.04.2-preinstalled-server-armhf+raspi2.img.xz'&gt;raspberry pi 2&lt;/a&gt; and &lt;a href='http://www.finnie.org/software/raspberrypi/ubuntu-rpi3/ubuntu-16.04-preinstalled-server-armhf+raspi3.img.xz'&gt;raspberry pi 3&lt;/a&gt;. The process to write these images to the microSD card differs slightly from ones I've used in the past. It still uses &lt;code&gt;dd&lt;/code&gt;, but the image is first piped through &lt;code&gt;xzcat&lt;/code&gt;, as such:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;xzcat ubuntu-16.04.2-preinstalled-server-armhf+raspi2.img.xz | sudo dd bs=4M of=/dev/mmcblk0
xzcat ubuntu-16.04-preinstalled-server-armhf+raspi3.img.xz   | sudo dd bs=4M of=/dev/mmcblk0
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;armbian&quot;&gt;&lt;/a&gt;Armbian&lt;/h3&gt;&lt;p&gt;The one issue that I have with the Banana Pi compared to the Raspberry Pi, is that it is commonly not supported. It can be hard to find a bananna pi specific image, and the raspberry pi ones usually do not work. For example, while Canonical linked to Raspberry Pi images, it did not mention the banana pie.  This is where &lt;a href='https://www.armbian.com/'&gt;Armbian&lt;/a&gt; comes in.&lt;/p&gt;&lt;p&gt;Armbian is a lightweight Debian and Ubuntu based distribution, that provides builds for various ARM devices. Thus the name, &lt;em&gt;ARM-bian&lt;/em&gt;. One of these many supported devices... is the &lt;a href='https://www.armbian.com/banana-pi/'&gt;banana pi&lt;/a&gt;. I downloaded the Ubuntu 16.04 Server flavor of Armbian for the Banana PI, and copied it to my micro SD card with the command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo dd if=Armbian&amp;#95;5.25&amp;#95;Bananapi&amp;#95;Ubuntu&amp;#95;xenial&amp;#95;next&amp;#95;4.9.7.img  of=/dev/mmcblk0 bs=1M
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;hardware&amp;#95;setup&quot;&gt;&lt;/a&gt;Hardware Setup&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/Setting-Up-Pi-Cluster/pi-cluster.png&quot; style=&quot;width: 40%; float: right; margin: 0px 10px 0px 10px;&quot;/&gt;&lt;/p&gt;&lt;p&gt;After the operating system images have been copied the SD cards, the hardware can be setup. I started by inserting the microSD cards into the PIs, being careful to use the correct card with each device. Unlike the Raspberry PIs, the Bananna PI uses a normal SD card instead of a microSD, so I just left it in the converter card I used to connect it to my computer when imaging.&lt;/p&gt;&lt;p&gt;After adding the &quot;hard drives&quot;, I connected each PI to my network switch, via Ethernet. In the future, I would like to put the cluster on it's own mini (managed?) switch so that I can have the nodes on their own private network, but connected to my main network. For now, this works.&lt;/p&gt;&lt;p&gt;Lastly, plug in the power connectors. Pi devices can be very finicky when not properly powered, so it is a good idea to use an capable USB charging device. I have had trouble in the past with my devices not working correctly due to insufficient power (especially the bpi). I knew this problem would be an even more pronounced with the cluster because I planned to connect a HD to the bpi with a SATA connector. So, I picked up an &lt;a href='https://www.amazon.com/Anker-Charger-PowerPort-Multi-Port-Samsung/dp/B00VH8ZW02/ref=sr_1_1?ie=UTF8&amp;qid=1493860165&amp;sr=8-1&amp;keywords=Anker+power+port+5'&gt;Anker Power Port 5&lt;/a&gt; and it has been working great.&lt;/p&gt;&lt;p&gt;Lastly, two nice features of the banana pi is that it has a 1 GB ethernet port, &lt;em&gt;and&lt;/em&gt; a SATA connector with power. So, to utilize this functionality, and get the most out of the bpi, I ordered &lt;a href='https://www.amazon.com/JBtek-Connectors-Banana-Supply-Terminals/dp/B00ZP0L0VS/ref=sr_1_1?ie=UTF8&amp;qid=1493860481&amp;sr=8-1&amp;keywords=banana+pi+sata'&gt;the appropriate SATA connector&lt;/a&gt; from amazon for a few bucks. When it arrived, I connected it to the SATA and SATA power ports on the pi, and then to an old 300GB laptop HD I had laying around (it was the drive that came with &lt;a href='../introducing-kadabra/'&gt;kadabra&lt;/a&gt;). After the drive was connected, running &lt;code&gt;lsblk&lt;/code&gt; on the bpi automatically showed a &lt;code&gt;/dev/sda&lt;/code&gt; device, in addition to the typical &lt;code&gt;mmcblk0&lt;/code&gt; microSD device. I  mounted the drive to a folder using the following command to test it out:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo mount /dev/sda1 Data
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With the hard drive mounted, I was able to browse its contents and see of all the crap still on it. The combination of the GB network and large HD makes the bpi a great little storage node, which is how I intend to use it.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;bootup&amp;#95;and&amp;#95;connecting&amp;#95;via&amp;#95;ssh&quot;&gt;&lt;/a&gt;Bootup and Connecting via SSH&lt;/h3&gt;&lt;p&gt;When the Pis are plugged in, they should automatically boot up. In order to connect to them, I found their IPs from my main computer using &lt;code&gt;nmap&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo nmap -sP 192.168.1.0/24
&lt;/code&gt;&lt;/pre&gt;&lt;div id=&quot;caption&quot;&gt;This command may differ depending on your network setup&lt;/div&gt;&lt;p&gt;The Raspberry PIs have &lt;code&gt;&amp;#40;Raspberry Pi Foundation&amp;#41;&lt;/code&gt; in the MAC address lines, and my Banana Pi had &lt;code&gt;bananapi&lt;/code&gt; in the host name. Once I had the IP addresses, I could ssh in using the default usernames and passwords for the images (the user/pass should be listed on the sites). After logging in for the first time, each PI prompted me to change the password (as it should).&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;adding&amp;#95;a&amp;#95;sudo&amp;#95;user&quot;&gt;&lt;/a&gt;Adding A Sudo User&lt;/h3&gt;&lt;p&gt;When connecting to remote devices, I don't like to be logged in as root, so the first thing I did was setup my user account with sudo privileges, on the two Raspberry Pis (Armbian actually prompted me through these steps the first time I logged into the Banana pi. Kudos to them).&lt;/p&gt;&lt;p&gt;To add the user, set it's password (important), and then add it to the sudo group, I used the following commands:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;useradd -m -s /bin/bash ryan
passwd ryan
usermod -a -G sudo ryan
&lt;/code&gt;&lt;/pre&gt;&lt;div id=&quot;caption&quot;&gt;Yes, I know I can add the user to the sudo group in the &lt;code&gt;useradd&lt;/code&gt; command, but I prefer to do it with &lt;code&gt;usermod&lt;/code&gt;. Personal Preference.&lt;/div&gt;&lt;p&gt;That's it. At this point, all of my the PIs are minimally set up accessible. The next steps include updating packages, setting up ssh keys, and configuring .... &lt;a href='https://www.ansible.com'&gt;Ansible&lt;/a&gt;. But that will all be in the &lt;em&gt;next post&lt;/em&gt;. See you then!&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Fri, 05 May 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/ZFS-Backups-To-LUKS-External/
</guid>
<link>
http://ryan.himmelwright.net/posts/ZFS-Backups-To-LUKS-External/
</link>
<title>
ZFS Snapshot Backups to an External Drive with LUKS
</title>
<description>
&lt;p&gt;I have been using &lt;a href='https://en.wikipedia.org/wiki/ZFS'&gt;ZFS&lt;/a&gt; data pools to store data on &lt;a href='../../pages/homelab/#ninetales'&gt;my server&lt;/a&gt; for some time now. As great as that is, I am ashamed to admit that I have not had a &lt;em&gt;true&lt;/em&gt; backup system in place (raid/mirrors are not backup). I have a backup solution that I have attempted in the past, but ran into an issue and let it drift to the side. That changes now. It's time to revisit my solution, and complete it to the end.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/ZFS-Backups-To-LUKS-External/drives.png&quot;&quot; alt=&quot;Server and External Drives&quot; /&gt; &lt;div id=&quot;caption&quot;&gt;My server's hot-swap drive bays and the external backup drive&lt;/div&gt;&lt;/p&gt;&lt;p&gt;Currently, my server is configured with two main zfs mirrored pools. The first one, &lt;code&gt;Data&lt;/code&gt;, is built on 2 x 3TB hard drives, providing 2.72 TB of usable disk space. It contains all of my wife's and my data, organized into sub-category pools (ex: &lt;code&gt;Data/Music&lt;/code&gt;, &lt;code&gt;Data/Pictures&lt;/code&gt;, &lt;code&gt;Data/ryan&lt;/code&gt;, etc). The second, &lt;code&gt;Backups&lt;/code&gt;, is built on the 2 x 1TB hard drives from my old desktop, creating a 928 GB usable pool . It stores the automatic backups of some of the VMs and LXC containers hosted on the server.&lt;/p&gt;&lt;p&gt;Before I had my 3TB drives, I bought a 2TB external hard drive to backup the 1TB drives to. While it isn't as large as the total usable space on my server, it is enough to store my data backups to, for the time being.&lt;/p&gt;&lt;p&gt;My goal is to setup a zfs pool on the external drive, so I can use zfs's send &amp; receive functionality to send bi-weekly-ish incremental snapshots to it. When I am not running backups, I want to store the drive at an off-site location. With the drive being stored elsewhere, I want to ensure that the data is protected, so I will be encrypting the it using &lt;a href='https://en.wikipedia.org/wiki/Linux_Unified_Key_Setup'&gt;LUKS&lt;/a&gt;, the Linux disk encryption software.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;setting&amp;#95;up&amp;#95;luks&quot;&gt;&lt;/a&gt;Setting up LUKS&lt;/h3&gt;&lt;p&gt;&lt;a href='https://gitlab.com/cryptsetup/cryptsetup/blob/master/README.md'&gt;LUKS&lt;/a&gt; (Linux Unified Key Setup) is the standard for Linux disk encryption. I will use it to encrypt the external drive, and then present the LUKS mapper devices to ZFS as a block device. To do this, we need to first install &lt;code&gt;cryptsetup&lt;/code&gt; with &lt;code&gt;sudo apt-get install cryptsetup&lt;/code&gt; (Assuming you are on a Debian-based operating system). Once that is installed, we can use the &lt;code&gt;cryptsetup&lt;/code&gt; command to configure LUKS on the drive.&lt;/p&gt;&lt;p&gt;The cryptsetup tool has a plethora of settings and options. After researching around, I decided to use options that the author of &lt;a href='http://www.makethenmakeinstall.com/2014/10/zfs-on-linux-with-luks-encrypted-disks/'&gt;this post&lt;/a&gt; used, because they were doing something very similar to what I am trying. I configured LUKS on my external drive using the following command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;cryptsetup luksFormat --cipher aes-xts-plain64 --key-size 512 --iter-time 10000 --use-random -y /dev/sdf
&lt;/code&gt;&lt;/pre&gt;&lt;code&gt;&amp;ndash;cipher aex-xts-plain64&lt;/code&gt;and &lt;code&gt;&amp;ndash;key-size 512&lt;/code&gt; refer to the algorithm and key size used to encrypt the data. In general, the larger the key, the harder the encryption is to crack.&lt;p&gt;&lt;code&gt;&amp;ndash;iter-time 10000&lt;/code&gt; and &lt;code&gt;&amp;ndash;use-random -y&lt;/code&gt; are additional precautions to make it more difficult to crack the encryption. The &lt;code&gt;&amp;ndash;iter-time 10000&lt;/code&gt; means it will spend at least 10 seconds processing the passphrase each time the disk is unlocked. This makes it much harder to brute-force the passphrase. &lt;/p&gt;&lt;p&gt;Once the device is encrypted, we need to unlock it and map it as a device. This is done using the command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo cryptsetup luksOpen /dev/sdf sdf-enc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;/dev/sdf&lt;/code&gt; is the external disk, and &lt;code&gt;sdf-enc&lt;/code&gt; is whatever you want to name the unlocked device. This is the name that what will be used when referring to the unlocked device. With the drive is encrypted and unlocked, it's time for some ZFS magic.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;creating&amp;#95;a&amp;#95;zfs&amp;#95;pool&quot;&gt;&lt;/a&gt;Creating a ZFS Pool&lt;/h3&gt;&lt;p&gt;I am creating a zpool using just my single external drive, so the setup is very basic. No mirrors, no zvols. A simple zpool is created with the simple command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zpool create externalBackup sdf-enc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's it. &lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;taking&amp;#95;base&amp;#95;snapshots&quot;&gt;&lt;/a&gt;Taking Base Snapshots&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/ZFS-Backups-To-LUKS-External/snapshot.gif&quot; alt=&quot;Taking a ZFS snapshot&quot; /&gt; &lt;div id=&quot;caption&quot;&gt;Taking a ZFS snapshot&lt;/div&gt;&lt;/p&gt;&lt;p&gt;With a zpool initialized on the externalDrive, I can now send snapshots to it. To start, I created a base snapshot to send. Starting with the smaller pool, &lt;code&gt;/Backups&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zfs snapshot -r Backups@VM-LXC-BackupBase
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This command creates a recursive snapshot of my &lt;code&gt;Backups&lt;/code&gt; zpool, named &lt;code&gt;VM-LXC-BackupBase&lt;/code&gt;. Making a base snapshot for my &lt;code&gt;/Data&lt;/code&gt; zpool is nearly the same:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zfs snapshot -r Data/DataBackupBase
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;sending&amp;#95;the&amp;#95;base&amp;#95;snapshots&quot;&gt;&lt;/a&gt;Sending the Base Snapshots&lt;/h3&gt;&lt;p&gt;After taking base snapshots of the zpools, I can transfer them to the external drive using the zfs &lt;code&gt;send&lt;/code&gt; and &lt;code&gt;recv&lt;/code&gt; commands. Again, starting with the &lt;code&gt;VM-LXC-BackupBase&lt;/code&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zfs send Backups@VM-LXC-BackupBase | sudo zfs recv externalBackup/VM-LXC-BackupBase
&lt;/code&gt;&lt;/pre&gt;&lt;div id=&quot;caption&quot;&gt;Looking back, I realized I named this poorly... The external zpool should be &lt;code&gt;/externalBackup/VM-LXC-Backup&lt;/code&gt;, not &lt;code&gt;BackupBase&lt;/code&gt;, that name is just for the first &lt;em&gt;snapshot&lt;/em&gt;. Oh well.&lt;/div&gt;&lt;p&gt;Now for the slightly harder pool, &lt;code&gt;/Data&lt;/code&gt;, with all of the sub zpools. The first time I attempted this, only the parent &lt;code&gt;Data&lt;/code&gt; snapshot was copied, but none of the children were (&lt;code&gt;Data/Music&lt;/code&gt;, &lt;code&gt;Data/Pictures&lt;/code&gt;, etc). After some digging around the docs and online I realized I was missing the &lt;code&gt;-R&lt;/code&gt; to my &lt;code&gt;zfs send&lt;/code&gt; command.  Also note, that when using the &lt;code&gt;-R&lt;/code&gt; flag, the snapshot name for the destination pool are not specified (because it is copying multiple). It will use the same snapshot names from the source pool.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zfs send -R Data@DataBackupBase | sudo zfs recv externalBackup/DataBackup
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;incremental&amp;#95;backups&quot;&gt;&lt;/a&gt;Incremental Backups&lt;/h3&gt;&lt;p&gt;Taking a snapshot of my data and sending it to an external drive is nice, but I don't want to send all of the data each time I backup. Transferring can take a very long time, especially as my data pools continue to grow. I don't want to sit around all day, listening to hard drives hum as my data transfers.&lt;/p&gt;&lt;p&gt;&lt;center&gt;&lt;img src=&quot;../../img/posts/ZFS-Backups-To-LUKS-External/aint-nobody-got-time-for-that.gif&quot; alt=&quot;no time&quot; /&gt;&lt;/center&gt;&lt;/p&gt;&lt;p&gt;A useful feature of the zfs &lt;code&gt;send&lt;/code&gt; and &lt;code&gt;recv&lt;/code&gt; commands is the ability to send &lt;em&gt;incremental&lt;/em&gt; snapshots. This means when I want to update my backups, I can just send the &lt;em&gt;changes&lt;/em&gt; between the two snapshots. This is similar to &lt;a href='https://en.wikipedia.org/wiki/Diff_utility'&gt;source code diffs&lt;/a&gt;, but for file systems.&lt;/p&gt;&lt;p&gt;To send incremental snapshots, the &lt;code&gt;-i&lt;/code&gt; or &lt;code&gt;-I&lt;/code&gt; flag is used. The difference between the two is that the &lt;code&gt;-i&lt;/code&gt; flag will send the difference between the two snapshots listed, whereas &lt;code&gt;-I&lt;/code&gt; will send a series of snapshots between the two listed. For example, if I've taken several snapshots of my data (&lt;code&gt;A&lt;/code&gt;, &lt;code&gt;B&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt;, and &lt;code&gt;D&lt;/code&gt;), but have neglected to copy them to the external drive since snapshot &lt;code&gt;A&lt;/code&gt;, I can use &lt;code&gt;-I A D&lt;/code&gt; in my &lt;code&gt;zfs send&lt;/code&gt; command, and all four of the snapshots will be sent to the external.&lt;/p&gt;&lt;p&gt;To send an incremental update to my backup, I first created new snapshot for my pools (this time with a date):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zfs snapshot -r Backups@VM-LXC-Backup20170418
sudo zfs snapshot -r Data@DataBackup20170418
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, I sent the incremental changes between the base snapshots, and new ones I just made:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zfs send -R -i Backups@VM-LXC-BackupBase Backups@VM-LXC-Backup20170418 | sudo zfs recv externalBackup/VM-LXC-BackupBase
sudo zfs send -R -i Data@DataBackupBase Data@DataBackup20170418 | sudo zfs recv externalBackup/DataBackup
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Notice that I specify &lt;em&gt;two&lt;/em&gt; snapshots in the send command, to define the range of differences to send. &lt;/p&gt;&lt;h4&gt;&lt;a name=&quot;a&amp;#95;minor&amp;#95;issue&quot;&gt;&lt;/a&gt;A Minor Issue&lt;/h4&gt;&lt;p&gt;The first time I tried sending an incremental backup, I encountered a minor issue. ZFS gave me an error stating that my destination had been changed since last snapshot (meaning the base snapshot on the externalBackup pool). I looked this up online and it seems that sometimes, just looking around the pool can change files. Some people recommended setting the destination pool to read-only, so I did that to my backup pool with:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zfs set readonly=on externalBackup
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I am not sure if this will eliminate this problem in the future, but I guess I will find out.&lt;/p&gt;&lt;p&gt;I still had the error when sending, so I added the &lt;code&gt;-F&lt;/code&gt; flag to the &lt;code&gt;zfs recv&lt;/code&gt; command. I am not sure if this was the &lt;em&gt;best&lt;/em&gt; solution, but it seemed to be okay. I also thought about rolling back to the snapshot, and then copying which is likely a safer method (if you don't mind losing the &quot;changes&quot; on the destination pool).&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;safely&amp;#95;closing&amp;#95;and&amp;#95;removing&amp;#95;the&amp;#95;external&amp;#95;drive&quot;&gt;&lt;/a&gt;Safely Closing and Removing the External Drive&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/ZFS-Backups-To-LUKS-External/export-drive.gif&quot; alt=&quot;Exporting the zpool&quot; /&gt; &lt;div id=&quot;caption&quot;&gt;Exporting the zpool and closing the LUKS device&lt;/div&gt;&lt;/p&gt;&lt;p&gt;When the incremental backups finishes transferring, the external drive can be removed. The sequence of steps to do this safely are 1) export the zpool 2) close the LUKS device, and 3) unplug the drive. To export the zpool and close the LUKS device I used the commands:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zpool export externalBackup
sudo cryptSetup luksClose sdf-enc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After that, I was able to unplug the external drive, and store it in a safe location, until I need to backup data to it again.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;opening&amp;#95;and&amp;#95;importing&amp;#95;zpool&amp;#95;for&amp;#95;recurring&amp;#95;backups&quot;&gt;&lt;/a&gt;Opening and Importing zpool for Recurring Backups&lt;/h3&gt;Lastly, there are a few steps to take when reconnecting the drive to run a daily/monthly/weekly (whatever) backup. First, the drive must be decrypted and mounted, using the same command as above: &lt;pre&gt;&lt;code&gt;sudo cryptSetup luksOpen /dev/sdf sdf-enc
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, the zpool on the drive must be imported so that it can be used from the main system. Like exporting the pool, the command is simple:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;sudo zpool import externalBackup
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's it. Now the steps detailing taking snapshots and sending incremental backups can be repeated.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;summary&quot;&gt;&lt;/a&gt;Summary&lt;/h3&gt;I am happy with this solution for now. It allows me to leverage ZFS a bit more, and become more familiar with it. The biggest issue I will likely face is space on the external drive. Luckily, ZFS makes it easy to delete old snapshots. In the future, I might also consider using an online backup solution like &lt;a href='https://www.tarsnap.com/'&gt;Tarsnap&lt;/a&gt;, but I need to find a cost-effective one first. I'll be sure to update as I continue to expand my backup solution.&lt;p&gt;&lt;div id=&quot;post-meta&quot; style=&quot;float: right;&quot;&gt;Post Updated 05/12/2017&lt;/a&gt;&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Thu, 20 Apr 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/LIA-1-0-Beta-Released/
</guid>
<link>
http://ryan.himmelwright.net/posts/LIA-1-0-Beta-Released/
</link>
<title>
LIA 1.0 Beta Released
</title>
<description>
&lt;p&gt;I have released the 1.0 Beta version for a personal project of mine: the &lt;strong&gt;L&lt;/strong&gt;edger &lt;strong&gt;I&lt;/strong&gt;mport &lt;strong&gt;A&lt;/strong&gt;ssistant, or &lt;a href='https://github.com/himmALlRight/LIA/'&gt;LIA&lt;/a&gt;. This post will talk briefly about the background of LIA, what it does, and explain the beta release. &lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;what&amp;#95;is&amp;#95;lia?&quot;&gt;&lt;/a&gt;What is LIA?&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/LIA-1-0-Beta-Released/creditCardDownload.png&quot; alt=&quot;Credit Card Statement CSV&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Example Cred Card Statement CSV File&lt;/em&gt;&lt;/p&gt;&lt;p&gt;A while ago, I discovered &lt;a href='http://www.ledger-cli.org'&gt;Ledger&lt;/a&gt;, the command line double-entry accounting application. Its powerful, yet simple design attracted me, and I wanted to try it out. To use it effectively however, I needed a method to import our bank and credit card statements into ledger journals. Then, I could use ledger to analyze the finances. However, there was an issue. While there are several great ledger convert/import options out there, many were more complicated than what I was looking for. So...I wrote my own. &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/LIA-1-0-Beta-Released/ledger-journal.png&quot; alt=&quot;Example Ledger Journal File&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Example Ledger Journal File&lt;/em&gt;&lt;/p&gt;&lt;p&gt;When I started writing LIA, I just wanted a python script that could help me convert the contents of a .csv file into a ledger-journal formatted file (without any of the fancy features. Just the basics). I thought it was a simple task and should only take me a few hours. It was, and it did. I wrote the the first basic implementation of LIA on a Sunday afternoon. While coding that bare-bones version, I realized that even though it &lt;em&gt;technically worked&lt;/em&gt;, it would not be enjoyable to use, and therefore I would never use it. So I decided to expand it into a full project, something more than a simple script.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;what&amp;#95;does&amp;#95;lia&amp;#95;do?&quot;&gt;&lt;/a&gt;What does LIA do?&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/LIA-1-0-Beta-Released/LIA-demo.gif&quot; alt=&quot;LIA Running&quot; /&gt;&lt;/p&gt;&lt;p&gt;LIA executes the core functionality that originally prompted me to write it: converting bank/credit card statement csv files into ledger journal files. Beyond that basic functionality,  LIA has a few nice features that help the user manually convert these files in an enjoyable way. By going through each transaction manually, the user has full control to make sure data is being input correctly. However, LIA helps make this otherwise dull process fast and efficient. Some of LIA's features that help accomplish this are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Data order is recognized by a header mechanism&lt;/li&gt;&lt;li&gt;Prompts the user to potentially edit the transaction information&lt;/li&gt;&lt;li&gt;Sets default transaction information from the values of the csv file&lt;/li&gt;&lt;li&gt;Manual transaction entries when needed (No input file)&lt;/li&gt;&lt;li&gt;Supports multiple destination accounts&lt;/li&gt;&lt;li&gt;Automatic placement system. The user can specify a file containing rules to automatically place transactions. (ex: anything with &quot;Dunkin&quot; in the description will default to Expenses:Food:Coffee)&lt;/li&gt;&lt;li&gt;Colored prompts&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;a name=&quot;what&amp;#95;does&amp;#95;lia&amp;#95;1.0&amp;#95;beta&amp;#95;mean?&quot;&gt;&lt;/a&gt;What does LIA 1.0 Beta mean?&lt;/h2&gt;&lt;h3&gt;&lt;a name=&quot;lia&amp;#95;1.0&quot;&gt;&lt;/a&gt;LIA 1.0&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/LIA-1-0-Beta-Released/release-todo.png&quot; alt=&quot;My 1.0 Todo List&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;My Todo list to release the 1.0 Version&lt;/em&gt;&lt;/p&gt;&lt;p&gt;When I expanded LIA to a personal project, I recorded several features that would make converting CSV statements easier, and got started. I worked on the project here and there, adding each feature over time. These features are what I determined were required in order for the application to be acceptably &lt;em&gt;usable&lt;/em&gt;. When all of those requirements were met, I would release an official 1.0 Branch.&lt;/p&gt;&lt;p&gt;The main functionality of LIA has been implemented for a while now. Being a python application, it has been possible to run LIA by calling the files with python. However, I didn't want to release the 1.0 version without first making an installer. I wanted LIA to be run like a normal linux application. I have now finished configuring the project and a &lt;code&gt;setup.py&lt;/code&gt; file, so users can use python's setuptools to install LIA as an application on their computer. Additionally, I have even packaged LIA as a Solus eopkg. It looks like I am ready for release.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;beta&quot;&gt;&lt;/a&gt;Beta&lt;/h3&gt;Sort of. Until now, I have been developing, but not using LIA day to day. I want to spend some time actually &lt;em&gt;using&lt;/em&gt; the application to see if there are any remaining issues. Also, I have not confirmed that it fully does what is needed for ledger. I want to get a few ledger users to quickly look at it and let me know if they see any issues. After testing it for a bit, I will release it as the official 1.0 release. This will mean it should be stable enough for people to use, if they so choose to.&lt;h2&gt;&lt;a name=&quot;more&amp;#95;information&quot;&gt;&lt;/a&gt;More Information&lt;/h2&gt;To test out LIA, read some documentation, or find out more  &lt;a href='https://github.com/himmAllRight/lia/'&gt;check it out&lt;/a&gt; on &lt;a href='https://github.com/himmAllRight'&gt;my github page&lt;/a&gt;. I plan to continue to develop it further in the future. If you have a suggestion, or even some code you'd like to contribute, feel free to let me know, either on github or my &lt;a href='../../pages//about/'&gt;other contact methods&lt;/a&gt;. Enjoy!
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Mon, 17 Apr 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/New-Theme-Immutable/
</guid>
<link>
http://ryan.himmelwright.net/posts/New-Theme-Immutable/
</link>
<title>
New Website Theme: Immutable
</title>
<description>
&lt;p&gt;When I first started using &lt;a href='http://cryogenweb.org'&gt;Cryogen&lt;/a&gt; to generate this website, I wanted to create a personalized theme. This desire led me to hack a the default theme into a mutant, which I boringly named &quot;&lt;i&gt;ryan1&lt;/i&gt;&quot; (I anticipated it to be temporary). It looked like a relic, designed from when I first learned how to make a web page... the early 2000's. Like &lt;del&gt;many&lt;/del&gt; all websites from that time, it was not mobile friendly. I hope to change all of that, by introducing my new website theme: &lt;b&gt;&lt;i&gt;Immutable&lt;/i&gt;&lt;/b&gt;.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;p&gt;&lt;a href='../../img/posts/New-Theme-Immutable/ryan1-home.png'&gt;&lt;img src=&quot;../../img/posts/New-Theme-Immutable/ryan1-home.png&quot; alt=&quot;Homepage with old ryan1 Theme&quot; /&gt;&lt;/a&gt; &lt;div id=&quot;caption&quot;&gt;Homepage with the old Theme&lt;/div&gt;&lt;/p&gt;&lt;p&gt;&lt;a href='../../img/posts/New-Theme-Immutable/immutable-home.png'&gt;&lt;img src=&quot;../../img/posts/New-Theme-Immutable/immutable-home.png&quot; alt=&quot;Homepage with Immutable Theme&quot; /&gt;&lt;/a&gt; &lt;div id=&quot;caption&quot;&gt;Homepage with the new Immutable Theme&lt;/div&gt;&lt;/p&gt;&lt;p&gt;While it may possibly still look dated (I wouldn't know, I'm a backend dev), it addresses several of the issues I had with the &lt;em&gt;ryan1&lt;/em&gt; theme. Here are a few examples of these improvements:&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;removed&amp;#95;the&amp;#95;sidebar&amp;#95;&amp;&amp;#95;dispersed&amp;#95;its&amp;#95;contents&quot;&gt;&lt;/a&gt;Removed the Sidebar &amp; Dispersed Its Contents&lt;/h3&gt;&lt;p&gt;&lt;a href='../../img/posts/New-Theme-Immutable/sidebar-changes.png'&gt;&lt;img src=&quot;../../img/posts/New-Theme-Immutable/sidebar-changes.png&quot;&gt;&lt;/a&gt; &lt;div id=&quot;caption&quot;&gt;The sidebar components have been distributed to other parts of the site&lt;/div&gt;&lt;/p&gt;&lt;p&gt;I have to be honest here... I originally planned on keeping the side bar when I started to build the theme. I liked how it held all of my links (Github, LinkedIn, etc), recent posts, and tags in one, easy to find, location. I also liked having my avatar picture in the side bar. I felt it made the site more personable (or maybe I'm just egotistical). After working on the base of the theme however, I realized the site might be better off without it. I've relocated the items to other locations of the site. The majority of the links have been relocated to the drop-down menu (more on that  below), and I at least added my picture to the &lt;a href='../../pages/about/'&gt;About Page&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;I might reinstate a sidebar in the future, but only if it looks &lt;em&gt;good&lt;/em&gt; and I can add it &lt;em&gt;correctly&lt;/em&gt;. The way I implemented the old sidebar caused many of the issues prompting this new theme, and I do not want to bring back those problems.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;removed&amp;#95;the&amp;#95;bad&amp;#95;footer&quot;&gt;&lt;/a&gt;Removed the Bad Footer&lt;/h3&gt;&lt;a href='../../img/posts/New-Theme-Immutable/ryan1-bad-footer.png'&gt;&lt;img src=&quot;../../img/posts/New-Theme-Immutable/ryan1-bad-footer.png&quot;&gt;&lt;/a&gt;&lt;div id=&quot;caption&quot;&gt;Bad Footer Placements&lt;/div&gt;&lt;p&gt;One of the issues created by the sidebar and my poor css floats, was the footer. On pages with a large enough the main content, it looked fine, consisting of a dark gray bar &lt;em&gt;along the bottom of the page&lt;/em&gt; . However, when viewing a page with a small content section, such as the &lt;em&gt;About&lt;/em&gt; page, the footer would rise up behind the sidebar. It looked terrible.&lt;/p&gt;&lt;p&gt;&lt;a href='../../img/posts/New-Theme-Immutable/immutable-footer.png'&gt;&lt;img src=&quot;../../img/posts/New-Theme-Immutable/immutable-footer.png&quot;&gt;&lt;/a&gt; &lt;div id=&quot;caption&quot;&gt;New Footer&lt;/div&gt;&lt;/p&gt;&lt;p&gt;In the &lt;em&gt;Immutable&lt;/em&gt; theme, I have fixed the footer and removed the gray bar. The background looks great, and the text is clearly visible over it, making the bar no longer required. I like minimal footers. I only need a small copyright statement, and I enjoy having a &lt;a href='http://cryogenweb.org'&gt;Cryogen&lt;/a&gt; shout-out here. So that's all I have.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;mobile&amp;#95;support&quot;&gt;&lt;/a&gt;Mobile Support&lt;/h3&gt;&lt;a href='../../img/posts/New-Theme-Immutable/mobile-changes.png'&gt;&lt;img src=&quot;../../img/posts/New-Theme-Immutable/mobile-changes.png&quot;&gt;&lt;/a&gt;&lt;div id=&quot;caption&quot;&gt;Mobile viewing the homepage and a post, on both the old theme and Immutable&lt;/div&gt;&lt;p&gt;The biggest reason for making the new theme was that viewing the website on a mobile device was a poor experience... unusable even. Again, because I implemented the sidebar poorly, it always remained on the side. Even on a narrow mobile screen. There was not enough room for the actual main content section, and pages/posts consisted of a skinny line of text down the side of the phone. Images... well, don't get me started on how well images were displayed. &lt;em&gt;Immutable&lt;/em&gt; solves these issues. The main content window takes up the majority of the screen, allowing for easy content reading. &lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;mobile&amp;#95;navigation&quot;&gt;&lt;/a&gt;Mobile Navigation&lt;/h3&gt;&lt;a href='../../img/posts/New-Theme-Immutable/mobile-menu.png'&gt;&lt;img src=&quot;../../img/posts/New-Theme-Immutable/mobile-menu.png&quot;&gt;&lt;/a&gt;&lt;div id=&quot;caption&quot;&gt;Main navigation drop-down and the extended drop-down menu on mobile&lt;/div&gt;&lt;p&gt;In addition to better viewing, site navigation has also been improved on mobile. When I say &lt;em&gt;improved&lt;/em&gt;, I of course mean &lt;em&gt;added&lt;/em&gt;, as is was sort-of non-existent before. In &lt;em&gt;ryan1&lt;/em&gt; there was an drop-down menu icon, but when it was tapped... nothing happened. At all. Now, there is an icon that drops down a site navigation menu when tapped. At the bottom of the navigation items, there is a &lt;em&gt;more&lt;/em&gt; tab. When clicked, it extends the menu to also include my contact links (Github, LinkedIn, etc.), recent posts, and the list of post tag links.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;continued&amp;#95;work&quot;&gt;&lt;/a&gt;Continued Work&lt;/h3&gt;While its name is &lt;em&gt;immutable&lt;/em&gt;, the actual theme itself is not (bad joke). There are a few things I plan on tweaking over time. For example, I don't love the fonts and spacing and I will continue to improve them. I also want to edit the &lt;code&gt;code&lt;/code&gt; colors. I did a quick edit of the colors so that they worked with the theme, but they not what I ultimately want. I use the code segments a lot on this site, so it is important that they look nice.&lt;p&gt;Well, that is it. I finally got around to making a new theme, and plan to make it even better over time. I hope you enjoy, even on a phone ;).&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Tue, 11 Apr 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/LFS-SBUs-and-Binutils/
</guid>
<link>
http://ryan.himmelwright.net/posts/LFS-SBUs-and-Binutils/
</link>
<title>
Linux from Scratch - SBUs and Binutils
</title>
<description>
&lt;p&gt;Well, after all of the preparation, we are ready to start compiling packages. This post cover compiling all the packages, but it will detail the first build of &lt;a href='https://www.gnu.org/software/binutils/'&gt;Binutils&lt;/a&gt;, which is arguably the most important package to compile. Why is Binutils so crucial? It determines the SBU time for your build system. What's an SBU? Read on to find out!&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;sbus&quot;&gt;&lt;/a&gt;SBUs&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/LFS-SBUs-Binutils/SBU-table.png&quot; alt=&quot;SBU Table&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;A table of package SBUs and their predicted build time&lt;/em&gt;&lt;/p&gt;&lt;p&gt;When completing LFS, people commonly want to know how long it will take to compile each package. Unfortunately, build times are very much dependent on the power and configuration of the system the packages are being compiled on. Some packages may take a few minutes on a powerful workstation, but hours on an aged laptop. While it cannot be said how long a specific build will take on any device, we can normalize how long each package build takes comparatively to each other. This normalization is done using Stand Build Units, or SBUs.&lt;/p&gt;&lt;p&gt;A SBU is the unit of time measurement it takes to make and install a standard package. Each package in the LFS book has a SBU value, so that build times can be gauged. So, if The first package to be constructed in the book (and in this post), is Binutils, so that is the package which SBUs are normalized to. For example, if it took 10 minutes to build Binutils on your machine, then 1 SBU = 10 minutes for that machine. This means a 4.5 SBU package can be expected to take ~45 minutes to build.&lt;/p&gt;&lt;h4&gt;&lt;a name=&quot;sbu&amp;#95;accuracy&quot;&gt;&lt;/a&gt;SBU Accuracy&lt;/h4&gt;SBUs are not completely accurate, and should be used as an estimate at best. Due to the many factors that may differ between setups, SBUs can be off by dozens of minutes in worst-case scenarios. Certain make options might also throw the system off.&lt;p&gt;For example, systems with multiple cores can run &quot;parallel make&quot; using the &lt;code&gt;-j&lt;/code&gt; make-flag, as in &lt;code&gt;make -j4&lt;/code&gt;. This tell &lt;em&gt;make&lt;/em&gt; to compiled the package using multiple cores. Parallel compilation has the potential to speed up the build process significantly. However, due to how compilation jobs are divided for parallel builds, SBUs are even harder to predict and may be even more sporadic. Just remember that and don't expect too much SBU accuracy when using &lt;code&gt;make -j&lt;/code&gt;. Also, if you ever run into a problem during a build step, it is a good idea to first retry with a single processor build. If this does not fix the issue itself, the error message can at least be more easily analyzed.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;my&amp;#95;encountered&amp;#95;issues&amp;#95;with&amp;#95;tar...&quot;&gt;&lt;/a&gt;My Encountered Issues with tar...&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/LFS-SBUs-Binutils/tar-error.png&quot; alt=&quot;Tar issues&quot; /&gt;  &lt;/p&gt;&lt;p&gt;The first time I attempted to make binutils, I encountered a few errors. The gist of it was that I was not able untar the package correctly, at least from the &lt;em&gt;lfs&lt;/em&gt; user. Everything worked fine from the &lt;em&gt;root&lt;/em&gt; or even &lt;em&gt;ryan&lt;/em&gt; user accounts, but running tar on &lt;em&gt;lfs&lt;/em&gt; returned the following error:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;tar &amp;#40;child&amp;#41;: bzip2: Cannot exec: Too many levels of symbolic links
tar &amp;#40;child&amp;#41;: Error is not recoverable: exiting now
tar: Child returned status 2
tar: Error is not recoverable: exiting now
&lt;/code&gt;&lt;/pre&gt;I searched around but much of the initial advice didn't help my problem. It often indicated that my /usr/bin/bzip2 might be a symlink and should be altered. That wasn't the case. Then tried something that illuminated the issue: I removed the &lt;code&gt;/tools/bin&lt;/code&gt; from the begging of the &lt;code&gt;path&lt;/code&gt; variable (defined in the &lt;em&gt;lfs&lt;/em&gt; &lt;code&gt;.bashrc&lt;/code&gt; file). That temporarily fixed the issues. So I knew the problem was related to the symlink I setup in &lt;a href='../LFS-Final-Preparation-Steps'&gt;the previous LFS post&lt;/a&gt;, specifically the &lt;code&gt;ln -sv $LFS/tools /&lt;/code&gt; command. It must have failed and I wasn't paying attention.&lt;p&gt;Now that I was knew what the problem was, I was able to fix it by running the following commands (some of them might need to be run from a &lt;em&gt;root/sudo&lt;/em&gt; account):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;rm -rf $LFS/tools
rm -rf /tools
mkdir -pv $LFS/tools
ln -sv $LFS/tools /
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;These commands remove and reset the &lt;code&gt;tools&lt;/code&gt; symlinks. I then made sure to re-add &lt;code&gt;/tools/bin&lt;/code&gt; to the begging of the &lt;code&gt;path&lt;/code&gt; var in the &lt;em&gt;lfs&lt;/em&gt; &lt;code&gt;.bashrc&lt;/code&gt; and test it. Problem fixed!&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;extracting&amp;#95;binutils&quot;&gt;&lt;/a&gt;Extracting BinUtils&lt;/h3&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/LFS-SBUs-Binutils/tar-binutils.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/LFS-SBUs-Binutils/tar-binutils.gif'&quot; onmouseout=&quot;this.src='../../img/posts/LFS-SBUs-Binutils/tar-binutils.png'&quot;&gt;  &lt;/center&gt;&lt;/p&gt;&lt;p&gt;It is important that Binutils is built first in the process. This is mostly because when Glibc and GCC are built, they perform various tests on the linker and assembler to figure out which of their own features to enable.&lt;/p&gt;&lt;p&gt;To start building BinUtils, move to the sources directory (&lt;code&gt;$LFS/sources&lt;/code&gt;) and extract the package with (If you encounter issues, see section above):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;tar xfjv binutils-2.27.tar.bz2
&lt;/code&gt;&lt;/pre&gt;&lt;em&gt;Note: You're version might be different&lt;/em&gt;&lt;p&gt;The Binutils documentation recommends building it in a dedicated &lt;code&gt;build&lt;/code&gt; directory, so lets go ahead and make, then enter, that directory:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;mkdir build
cd build
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;making&amp;#95;&amp;&amp;#95;executing&amp;#95;a&amp;#95;build&amp;#95;script&quot;&gt;&lt;/a&gt;Making &amp; Executing a Build Script&lt;/h3&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/LFS-SBUs-Binutils/binutils-script-start-play.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/LFS-SBUs-Binutils/binutils-script-start.gif'&quot; onmouseout=&quot;this.src='../../img/posts/LFS-SBUs-Binutils/binutils-script-start-play.png'&quot;&gt;  &lt;/center&gt;&lt;/p&gt;&lt;p&gt;Now it is time to build. Normally, this would best be done by sequentially performing a series of &lt;em&gt;configure&lt;/em&gt;, &lt;em&gt;make&lt;/em&gt;, and &lt;em&gt;make install&lt;/em&gt; commands, but for the first binutils compilation, we want to get an accurate reading on how long it takes (to determine our SBU time). To accomplish this easily, I put all of the commands into a bash script. This way, I could execute the script, and easily time the whole process using the &lt;code&gt;time&lt;/code&gt; utility. To create the script, I wrote the following commands into a file (&lt;code&gt;build-binutils.sh&lt;/code&gt;):&lt;/p&gt;&lt;pre&gt;&lt;code&gt;#!/bin/bash

../configure --prefix=/tools            \
             --with-sysroot=$LFS        \
             --with-lib-path=/tools/lib \
             --target=$LFS&amp;#95;TGT          \
             --disable-nls              \
             --disable-werror
make

case $&amp;#40;uname -m&amp;#41; in
  x86&amp;#95;64&amp;#41; mkdir -v /tools/lib &amp;amp;&amp;amp; ln -sv lib /tools/lib64 ;;
esac

make install
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The various options of the &lt;code&gt;configure&lt;/code&gt; command mean the following:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&amp;ndash;prefix=/tools&lt;/code&gt;: Configures the build to install the Binutils programs to the /tools directory&lt;/li&gt;&lt;li&gt;&lt;code&gt;&amp;ndash;with-sysroot=$LFS&lt;/code&gt;: For cross compilation, tells the build system to look in our $LFS directory for the target system libraries, as needed.&lt;/li&gt;&lt;li&gt;&lt;code&gt;&amp;ndash;with-lib-path=/tools/lib&lt;/code&gt;: configures the library path that the linker should be configured to use.&lt;/li&gt;&lt;li&gt;&lt;code&gt;&amp;ndash;target=$LFS&amp;#95;TGT&lt;/code&gt;: the machine description in the &lt;code&gt;LFS&amp;#95;TGT&lt;/code&gt; variable is slightly different than the value returned by the &lt;em&gt;config.guess&lt;/em&gt; script, so this option will tell the &lt;em&gt;configure&lt;/em&gt; script to adjust Binutil's build system for building the cross linker.&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-nls&lt;/code&gt;: disables the internationalization, as it is not needed for the temporary tools.&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-werror&lt;/code&gt;: Prevents the build from stopping in the event that there are warnings from the host's compilier.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Also, the &lt;code&gt;case&lt;/code&gt; statement creates a symlink to ensure the sanity of the tool chain, if building on a &lt;em&gt;x86_64&lt;/em&gt; architecture.&lt;/p&gt;&lt;p&gt;To runs the script, first make it executable, &lt;/p&gt;&lt;pre&gt;&lt;code&gt;chmod +x build-binutils.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Finally, time and execute the script: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;time ./build-binutils.sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;When the script completes, the time it took to run it will be printed out. Congratulations, this is the SBU for your system!&lt;/p&gt;&lt;p&gt;Once I had my standard single-thread SBU value, I wanted to do a run with the &lt;code&gt;-j4&lt;/code&gt; make flag for comparison. To &quot;reset&quot;, I deleted the contents of the &lt;code&gt;binutils/build/&lt;/code&gt; directory, as well as &lt;code&gt;$LFS/tools/&lt;/code&gt;. I then edited my &lt;code&gt;build-binutils.sh&lt;/code&gt; script to do a parallel compile by changing &lt;code&gt;make&lt;/code&gt; line to &lt;code&gt;make -j4&lt;/code&gt;. I then re-ran the script with &lt;code&gt;time&lt;/code&gt;. &lt;em&gt;Note: This is not described anywhere in the official documentation, but is just my best guess at what to do for a re-run of binutils. I very well may be missing steps. However, remember LFS is a learning experience, so we will find out&lt;/em&gt;!&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;checking&amp;#95;the&amp;#95;build&quot;&gt;&lt;/a&gt;Checking the Build&lt;/h3&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/LFS-SBUs-Binutils/binutils-check-play.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/LFS-SBUs-Binutils/binutils-check.gif'&quot; onmouseout=&quot;this.src='../../img/posts/LFS-SBUs-Binutils/binutils-check-play.png'&quot;&gt;  &lt;/center&gt;&lt;/p&gt;&lt;p&gt;After the build is complete, it is a good idea to run the tests, &lt;em&gt;especially&lt;/em&gt; for binutils. In this case, use the make command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;make -k check
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;building&amp;#95;the&amp;#95;chapter&amp;#95;5&amp;#95;tools&amp;#95;from&amp;#95;here&amp;#95;on&amp;#95;out...&quot;&gt;&lt;/a&gt;Building the Chapter 5 Tools From Here on Out...&lt;/h3&gt;For the sake of time, I will not be writing posts detailing the build process for each of the remaining packages in Chapter 5. I might keep a little log about how each of the builds went and post it, but I am unsure. If I encounter any major snags along the way, I will be sure to write a post detailing them. Otherwise, with any luck, my plan is to keep compiling and see you in Chapter 6!
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Tue, 04 Apr 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/LFS-Final-Preparation-Steps/
</guid>
<link>
http://ryan.himmelwright.net/posts/LFS-Final-Preparation-Steps/
</link>
<title>
Linux from Scratch - Final Preparation Steps
</title>
<description>
&lt;p&gt;Now that the &lt;em&gt;repeated&lt;/em&gt; setup steps have been defined in &lt;a href='http://ryan.himmelwright.net/posts/LFS-Repeated-Setup-Steps/'&gt;my previous LFS post&lt;/a&gt;, there are a &lt;em&gt;few&lt;/em&gt; more preparation steps to complete in order to start building the LFS system. I promise... we will start compiling soon. If all goes well, this should be the last preparation post.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;downloading&amp;#95;sources&quot;&gt;&lt;/a&gt;Downloading Sources&lt;/h3&gt;When it comes down to it, Linux from scratch is just a bunch of packages, and the Linux kernel, all compiled from source and linked together. To build all of this, we need to download the source code... for &lt;em&gt;all&lt;/em&gt; of those packages. Luckily, LFS keeps a list of what is needed, and downloading it is trivial. &lt;em&gt;(Note: These commands should be run as &lt;b&gt;root&lt;/b&gt;)&lt;/em&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/LFS-Final-Preparation-Steps/make-sources-dir.png&quot; alt=&quot;Making the sources directory&quot; /&gt; &lt;/center&gt;&lt;/p&gt;&lt;p&gt;First, lets make a new directory to put all of the source code. To make the directory:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;mkdir -v $LFS/sources
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The LFS book suggests for this directory to be writable and sticky. A &quot;Sticky&quot; directory allows only the file owner to delete a file in it. To make the directory both writable and sticky, use the command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;chmod -v a+wt $LFS/sources
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/LFS-Final-Preparation-Steps/wget-sources-play.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/LFS-Final-Preparation-Steps/wget-sources.gif'&quot; onmouseout=&quot;this.src='../../img/posts/LFS-Final-Preparation-Steps/wget-sources-play.png'&quot;&gt;  &lt;/center&gt;&lt;/p&gt;&lt;p&gt;To download all of the source packages at once, download &lt;a href='http://www.linuxfromscratch.org/lfs/view/stable-systemd/wget-list'&gt;the LFS wget list&lt;/a&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;wget http://www.linuxfromscratch.org/lfs/view/stable-systemd/wget-list
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After downloading the wget list, it can be used as the input-file for wget. This will download all the sources with one command:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;wget --input-file=wget-list --continue --directory-prefix=$LFS/sources
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It should take a few minutes to download everything (or longer if on a poor connection).&lt;/p&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/LFS-Final-Preparation-Steps/sources-md5-play.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/LFS-Final-Preparation-Steps/sources-md5.gif'&quot; onmouseout=&quot;this.src='../../img/posts/LFS-Final-Preparation-Steps/sources-md5-play.png'&quot;&gt;  &lt;/center&gt;&lt;/p&gt;&lt;p&gt;Ever since LFS-7.0, a &lt;a href='http://www.linuxfromscratch.org/lfs/view/stable-systemd/md5sums'&gt;md5sums file&lt;/a&gt; is provided, which can be downloaded and used to verify the integrity of downloaded packages. Download this file, again with &lt;em&gt;wget&lt;/em&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;wget http://www.linuxfromscratch.org/lfs/view/stable-systemd/md5sums
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then, compare the hashes in the list to the &lt;a href='https://en.wikipedia.org/wiki/Md5sum'&gt;md5sum&lt;/a&gt; for each of the source packages. This is done with the commands:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;pushd $LFS/sources
md5sum -c md5sums
popd
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The results should all say &lt;em&gt;OK&lt;/em&gt;. If not, try re-downloading the sources and verifying again.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;creating&amp;#95;the&amp;#95;$lfs/tools&amp;#95;directory&quot;&gt;&lt;/a&gt;Creating the $LFS/tools Directory&lt;/h3&gt;LFS is built in two main steps. The first step builds a set of temporary tools to build the system, but not be included as part of the Final LFS system itself. To help prevent these tools from accidentally being included in the final system, they are kept in a separate directory that can be deleted after they have served their purpose. Make this directory as root:&lt;pre&gt;&lt;code&gt;mkdir -v $LFS/tools
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Next, we will create a &lt;code&gt;/tools&lt;/code&gt; symlink to the host system. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;ln -sv $LFS/tools /
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This enables the tool-chain to be compiled so that it always refers to &lt;code&gt;/tools&lt;/code&gt;, which ensures that the compiler, assembler, and linker will work in both the first, and second steps of the LFS build.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; &lt;em&gt;I did this step wrong the first time (I think it failed), and encountered errors later when trying to run tar. If you encounter issues as well, jump to &lt;a href='../LFS-SBUs-and-Binutils/'&gt;my next post&lt;/a&gt; to see how I resolved these issues&lt;/em&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;adding&amp;#95;the&amp;#95;lfs&amp;#95;user&quot;&gt;&lt;/a&gt;Adding the LFS User&lt;/h3&gt;Running a system as root is a dangerous. Running the wrong command can completely obliterate a system, and having a typo bork the LFS build, or even the host system, would be horrific. To prevent this, the book recommends creating an unprivileged user to build the packages from. To do so, first create an &lt;em&gt;lfs&lt;/em&gt; group and then create + add a &lt;em&gt;lfs&lt;/em&gt; user to it using the commands (as root, ironic for this section...):&lt;pre&gt;&lt;code&gt;groupadd lfs
useradd -s /bin/bash -g lfs -m -k /dev/null lfs
&lt;/code&gt;&lt;/pre&gt;If you are not familiar with the &lt;em&gt;useradd&lt;/em&gt; command, then &lt;a href='https://en.wikipedia.org/wiki/RTFM'&gt;&lt;em&gt;RTFM&lt;/em&gt;&lt;/a&gt; by typing &lt;code&gt;man useradd&lt;/code&gt;. I'm just kidding (although reading the man pages is never a bad idea). Here is a quick summary of what all of the flags mean. &lt;ul&gt;&lt;li&gt;&lt;code&gt;-s /bin/bash&lt;/code&gt; sets our &lt;em&gt;lfs&lt;/em&gt; user's default shell to &lt;em&gt;bash&lt;/em&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;-g lfs&lt;/code&gt; adds the user to the &lt;em&gt;lfs&lt;/em&gt; group that was created in the previous command&lt;/li&gt;&lt;li&gt;&lt;code&gt;-m&lt;/code&gt; creates the user's home directory (&lt;em&gt;/home/lfs&lt;/em&gt;)&lt;/li&gt;&lt;li&gt;&lt;code&gt;-k /dev/null&lt;/code&gt; changes the input direction to the special null device to prevent the copying of files from a skeleton directory&lt;/li&gt;&lt;li&gt;lastly, &lt;code&gt;lfs&lt;/code&gt; is the new user's name.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Before logging into the user, the password must be set. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;passwd lfs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We also want to grant the &lt;em&gt;lfs&lt;/em&gt; user full access to the tools directory we made (&lt;em&gt;$LFS/tools&lt;/em&gt;), so lets make &lt;em&gt;lfs&lt;/em&gt; the owner of that directory:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;chown -v lfs $LFS/tools
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Do the same for the sources directory we made:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;chown -v lfs $LFS/sources
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Lastly, login as &lt;em&gt;lfs&lt;/em&gt;!&lt;/p&gt;&lt;pre&gt;&lt;code&gt;su - lfs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;Note: the &quot;-&quot; tells su to start a login shell, rather than a non-login shell. This mostly ensures that various files are read at login to setup environment variable and other profiles.&lt;/em&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;setting&amp;#95;up&amp;#95;the&amp;#95;build&amp;#95;environment&quot;&gt;&lt;/a&gt;Setting up the Build Environment&lt;/h3&gt;Now with the &lt;em&gt;lfs&lt;/em&gt; user created, we need to setup a proper working environment for that user. To do this, we will create the &lt;code&gt;.bash&amp;#95;profile&lt;/code&gt; and &lt;code&gt;.bashrc&lt;/code&gt; files. &lt;h5&gt;&lt;a name=&quot;creating&amp;#95;.bash&lt;i&gt;profile&quot;&gt;&lt;/a&gt;Creating .bash&lt;/i&gt;profile&lt;/h5&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/LFS-Final-Preparation-Steps/set-bash-profile.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/LFS-Final-Preparation-Steps/set-bash-profile.gif'&quot; onmouseout=&quot;this.src='../../img/posts/LFS-Final-Preparation-Steps/set-bash-profile.png'&quot;&gt;  &lt;/center&gt;&lt;/p&gt;&lt;p&gt;When logging in as the &lt;em&gt;lfs&lt;/em&gt; user, the shell first reads the &lt;code&gt;/etc/profile&lt;/code&gt; of the host, followed by the &lt;code&gt;.bash&amp;#95;profile&lt;/code&gt;. So, lets start with the &lt;code&gt;.bash&amp;#95;profile&lt;/code&gt;. Create/open &lt;code&gt;.bash&amp;#95;profile&lt;/code&gt; and add the following line to it:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;exec env -i HOME=$HOME TERM=$TERM PS1='\u:\w\$ ' /bin/bash
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This line replaces the running shell with a new one that contains a completely empty environment, except the &lt;em&gt;HOME&lt;/em&gt;, &lt;em&gt;TERM&lt;/em&gt;, &lt;em&gt;PS1&lt;/em&gt; variables. This ensures that there are no stray environment variables, that may interfere with the build environment.&lt;/p&gt;&lt;h5&gt;&lt;a name=&quot;creating&amp;#95;.bashrc&quot;&gt;&lt;/a&gt;Creating .bashrc&lt;/h5&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/LFS-Final-Preparation-Steps/set-bashrc.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/LFS-Final-Preparation-Steps/set-bashrc.gif'&quot; onmouseout=&quot;this.src='../../img/posts/LFS-Final-Preparation-Steps/set-bashrc.png'&quot;&gt;  &lt;/center&gt;&lt;/p&gt;&lt;p&gt;The new instance of this the shell is a non-login shell, so it does not read the &lt;code&gt;/etc/profile&lt;/code&gt; or &lt;code&gt;.bash&amp;#95;profile&lt;/code&gt; files. However, it does read the &lt;code&gt;.bashrc, so lets go ahead and create that. Open &lt;/code&gt;~/.bashrc` and add the following lines:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;set +h
umask 022
LFS=/mnt/lfs
LC&amp;#95;ALL=POSIX
LFS&amp;#95;TGT=$&amp;#40;uname -m&amp;#41;-lfs-linux-gnu
PATH=/tools/bin:/bin:/usr/bin
export LFS LC&amp;#95;ALL LFS&amp;#95;TGT PATH

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;set +h&lt;/code&gt; line turns off bash's hash function. This is normally a usefully feature, as it essentially caches the path-names of executables. Removing this will ensure that the newly compiled tools will always be found by the shell once they are available, because the shell will have to re-search the &lt;em&gt;PATH&lt;/em&gt; each time. Similarly, placing &lt;code&gt;/tools/bin&lt;/code&gt; ahead of the standard &lt;code&gt;/bin:/usr/bin&lt;/code&gt; &lt;em&gt;PATH&lt;/em&gt; &lt;em&gt;(line 6)&lt;/em&gt;, also helps force the shell to immediately locate up all the programs in chapter 5 after installation. These two techniques will hopefully prevent the risk of using old programs from the host instead of the newly compiled ones.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;umask 022&lt;/code&gt; line defines the &lt;a href='https://en.wikipedia.org/wiki/Umask'&gt;umask&lt;/a&gt; to 022, which sets up the system so that created files and directories are only writable by their owner, but are readable and executable by anyone.&lt;/p&gt;&lt;p&gt;The &lt;code&gt;LFS=/mnt/lfs&lt;/code&gt; line should look familiar, as it sets the &lt;code&gt;LFS&lt;/code&gt; variable to our LFS mount point.&lt;/p&gt;&lt;p&gt;Lastly, setting the &lt;code&gt;LC&amp;#95;ALL&lt;/code&gt; variable to &lt;code&gt;POSIX&lt;/code&gt; or &lt;code&gt;C&lt;/code&gt; ensures that everything will work as expected in the &lt;em&gt;chroot&lt;/em&gt; environments (regarding localization settings).&lt;/p&gt;&lt;p&gt;To enable this new environment we've setup, source the user-profile:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;source &amp;#126;/.bash&amp;#95;profile
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Congratulations! We are now ready to start compiling some code in the next post!&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Tue, 21 Mar 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/LFS-Repeated-Setup-Steps/
</guid>
<link>
http://ryan.himmelwright.net/posts/LFS-Repeated-Setup-Steps/
</link>
<title>
Linux from Scratch - Repeated Setup Steps
</title>
<description>
&lt;p&gt;During the Linux From Scratch process, there may be times when the build environment (computer, VM, chroot, whatever) must be restarted. If so, there are a few steps from the setup phase that have to be re-initialized. This post maps out those steps.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;setting&amp;#95;the&amp;#95;$lfs&amp;#95;variable&quot;&gt;&lt;/a&gt;Setting The $LFS Variable&lt;/h3&gt;After setting up the virtual disk for my LFS build, I needed to define where I wanted to eventually mount it. This location is important, because it is the path that the $LFS variable is set to. The $LFS variable is used throughout the book, to easily point to where the LFS system is being built.&lt;p&gt;&lt;center&gt;&lt;a href='../../img/posts/LFS-Repeated-Setup-Steps/Setting-LFS-var.png'&gt;&lt;img src=&quot;../../img/posts/LFS-Repeated-Setup-Steps/Setting-LFS-var.png&quot; alt=&quot;Setting the LFS variable&quot; /&gt;&lt;/a&gt;&lt;/center&gt;&lt;/p&gt;&lt;p&gt;To set the #LFS variable, I ran the following command: *&lt;/p&gt;&lt;p&gt;&lt;code&gt;export LFS=/mnt/lfs&lt;/code&gt;&lt;/p&gt;&lt;p&gt;To check that the variable set correctly, just print it out using echo (if successful, the path that was specified should print out).&lt;/p&gt;&lt;p&gt;&lt;code&gt;echo $LFS&lt;/code&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;ensuring&amp;#95;the&amp;#95;$lfs&amp;#95;variable&amp;#95;is&amp;#95;&lt;em&gt;always&lt;/em&gt;&amp;#95;set&quot;&gt;&lt;/a&gt;Ensuring the $LFS Variable is &lt;em&gt;Always&lt;/em&gt; Set&lt;/h3&gt;There are several ways to ensure that the &lt;em&gt;$LFS&lt;/em&gt; variable is always loaded during login. One method the book recommends is to edit the &lt;em&gt;.bash-profile&lt;/em&gt; found in both &lt;em&gt;~&lt;/em&gt; and &lt;em&gt;/root, by appending the export command defined above to them. This way every time the build machine resets, simply logging into the system (which loads &lt;/em&gt;bash&lt;em&gt;, assuming it is the default), will export the &lt;/em&gt;$LFS* variable.&lt;h3&gt;&lt;a name=&quot;mounting&amp;#95;the&amp;#95;lfs&amp;#95;partition(s)&quot;&gt;&lt;/a&gt;Mounting the LFS Partition(s)&lt;/h3&gt;&lt;p&gt;After setting the &lt;em&gt;$LFS&lt;/em&gt; variable, I could finally mount my LFS drive/partition to that location. First, I ensured that the directory existed by running:&lt;/p&gt;&lt;p&gt;&lt;code&gt;mkdir -pv $LFS&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Note: In this command, the -v again means verbose, so a message will be printed for each directory created. The -p flag is for &amp;ndash;parents, and will instruct &quot;mkdir&quot; to also make parent directories, as needed. So, if &lt;code&gt;/mnt/&lt;/code&gt; does not already exist, will be created along with &lt;code&gt;/mnt/lfs&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;After creating the directories, I mounted them with the command:&lt;/p&gt;&lt;p&gt;&lt;code&gt;sudo mount -v -t ext4 /dev/sdb $LFS&lt;/code&gt;&lt;/p&gt;&lt;p&gt;If multiple partitions are being used for the LFS build (&lt;em&gt;such as a separate &lt;code&gt;/home&lt;/code&gt; partition&lt;/em&gt;), they should also be mounted at this time.&lt;/p&gt;&lt;p&gt;&lt;center&gt; &lt;img src=&quot;../../img/posts/LFS-Repeated-Setup-Steps/mounting-play.png&quot; name=&quot;pic&quot; onmouseover=&quot;this.src='../../img/posts/LFS-Repeated-Setup-Steps/mount-check.gif'&quot; onmouseout=&quot;this.src='../../img/posts/LFS-Repeated-Setup-Steps/mounting-play.png'&quot;)&gt;  &lt;/center&gt;&lt;/p&gt;&lt;p&gt;After mounting my partition, the LFS book recommended that I check that the partition was not mounted with restrictive permissions. To do this, I ran the &lt;code&gt;mount&lt;/code&gt; command again, but this time without any parameters. From the output, I was able to see and confirm that the partition was not mounted with restrictive permissions, such as &lt;code&gt;nosuid&lt;/code&gt; or &lt;code&gt;nodev&lt;/code&gt;. If either of these options are set, the partition should be remounted.&lt;/p&gt;&lt;p&gt;Lastly, if a &lt;em&gt;swap&lt;/em&gt; partition is being used, do not forget to enable it using &lt;code&gt;swapon&lt;/code&gt;:&lt;/p&gt;&lt;p&gt;&lt;code&gt;swapon -v /dev/xxx&lt;/code&gt;  (with &lt;em&gt;xxx&lt;/em&gt; the name of the swap partition)&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;conclusion&quot;&gt;&lt;/a&gt;Conclusion&lt;/h3&gt;Remember, if the LFS host system is restarted for any reason, these steps must be completed upon logging into the rebooted system. Even if measures were taking to &lt;em&gt;always&lt;/em&gt; complete these steps (such as adding the &lt;em&gt;$LFS&lt;/em&gt; variable to the bash profile, or mounting the partitions via the &lt;em&gt;fstab&lt;/em&gt; file), it is still a good idea to check and make sure that they &lt;em&gt;actually&lt;/em&gt; initialized as  intended. This can prevent several headaches down the road.
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Mon, 13 Mar 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/new-dotfiles/
</guid>
<link>
http://ryan.himmelwright.net/posts/new-dotfiles/
</link>
<title>
My New Dotfiles Management - Using GNU Stow
</title>
<description>
&lt;p&gt;I have maintained a &quot;dotfiles&quot; repository since I made my github account in 2013. However, overtime it became more of a post-apocalyptic wasteland, cluttered with remnants of obsolete configurations and scraps of scripts. It was no longer the pristine, culled, collection that I desired. I also did not have an efficient method of easily linking the files on a new system. I had to manually make symlinks for each dotfile. I knew there were &lt;em&gt;much&lt;/em&gt; better dotfiles setups out there, but I never got around to it. Until now.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more&amp;ndash;&gt;&lt;/p&gt;&lt;p&gt;One day, after reading &lt;a href='http://brandon.invergo.net/news/2012-05-26-using-gnu-stow-to-manage-your-dotfiles.html'&gt;this post&lt;/a&gt;, I finally decided to sit down and clean up my dotfiles directory. I wanted to re-organize it so that I could use &lt;a href='http://freecode.com/projects/gnustow'&gt;GNU Stow&lt;/a&gt; to initialize my dotfiles. &lt;/p&gt;&lt;p&gt;After setting it all up, I decided to just start from scratch with a &lt;a href='https://github.com/himmAllRight/dotfiles'&gt;new repository&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;using&amp;#95;stow&amp;#95;and&amp;#95;dotfiles&quot;&gt;&lt;/a&gt;Using Stow and dotfiles&lt;/h2&gt;If you haven't seen it before, I highly suggest reading the post I have linked above. But in the meantime, I can provide a quick summary of how my dotfiles are setup. &lt;p&gt;&lt;center&gt;&lt;img src=&quot;../../img/posts/new-dotfiles/dotfiles.png&quot; alt=&quot;My Dotfiles Dir&quot; /&gt;&lt;/center&gt;&lt;/p&gt;&lt;p&gt;Each application has an associated sub-directory (ex: &lt;code&gt;dotfiles/emacs&lt;/code&gt;), which contains all of the dotfiles/folders associated with that application. Structurally, I treat the items in each application directory as if they were in my &lt;code&gt;&amp;#126;&lt;/code&gt;. For example, the &lt;code&gt;vim&lt;/code&gt; sub-directory has my &lt;code&gt;.vimrc&lt;/code&gt;, as well as the &lt;code&gt;.vim/colors/&lt;/code&gt; directory. This is so that when I use stow, it will properly link them in &lt;code&gt;&amp;#126;&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;center&gt;&lt;img src=&quot;../../img/posts/new-dotfiles/vim-dots.png&quot; alt=&quot;Vim dotfiles directory&quot; /&gt;&lt;/center&gt;&lt;/p&gt;&lt;p&gt;When I setup my dotfiles on a new system, or install an application for which I already have dotfiles saved for, setting them up is as easy as typing:&lt;/p&gt;&lt;p&gt; &lt;code&gt;stow application-dir&lt;/code&gt; (ex: &lt;code&gt;stow vim&lt;/code&gt;).   &lt;/p&gt;&lt;p&gt;GNU Stow then links the files under my home directory. In my vim example, this means symlinks are created for &lt;code&gt;&amp;#126;/.vimrc&lt;/code&gt; and &lt;code&gt;&amp;#126;/.vim/colors/&amp;#42;&lt;/code&gt;, pointing to their respective locations in &lt;code&gt;&amp;#126;/dotfiles/vim/&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;center&gt;&lt;img src=&quot;../../img/posts/new-dotfiles/vim-home.png&quot; alt=&quot;Vim dotfiles in Home&quot; /&gt;&lt;/center&gt;&lt;/p&gt;&lt;p&gt;I think this setup is brilliant. Initializing an application's directory is so simple, and I can choose to only initialize specific sub-directories.&lt;/p&gt;&lt;p&gt;In the future, I might make multiple branches of the repository, one for each of my computers, so I can maintain specific configurations. In theory, I could also just make different folders (ex &lt;code&gt;vim-laptop&lt;/code&gt; and &lt;code&gt;vim-server&lt;/code&gt;), but I like the branch idea better because it's a little easier for me to merge changes. We shall see. &lt;/p&gt;&lt;p&gt;Anyway, that's the new setup. Enjoy :-D&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Tue, 07 Mar 2017 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/LFS-Getting-Started/
</guid>
<link>
http://ryan.himmelwright.net/posts/LFS-Getting-Started/
</link>
<title>
Linux from Scratch - Getting Started
</title>
<description>
&lt;p&gt;When I started using &lt;a href='https://www.archlinux.org'&gt;Arch Linux&lt;/a&gt; a while back, I learn about some of the internals of Linux quickly. Ever since then, I have considered building a Linux From Scratch by following the guidelines outlined in &lt;a href='http://www.linuxfromscratch.org'&gt;the book&lt;/a&gt;. Based on my experience with Arch Linux, I'm sure that compiling a system from scratch will continue to teach me about Linux at a much deeper level.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;getting&amp;#95;started&quot;&gt;&lt;/a&gt;Getting Started&lt;/h3&gt;&lt;img src=&quot;../../img/posts/LFS-intro/book-cover.jpg&quot; alt=&quot;Linux from Scratch Logo&quot; /&gt;&lt;p&gt;First, it should be known that this process follows a book that is freely available at &lt;a href='http://www.linuxfromscratch.org'&gt;www.linuxfromscratch.org&lt;/a&gt;. The book is updated from time to time, and there are several versions of it (ex: systemd or not). I am attempting to complete the systemd adaptation. There are also many videos online of people walking through the steps. I find watching such videos can be very helpful to watch.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;setting&amp;#95;up&amp;#95;the&amp;#95;host&amp;#95;system&quot;&gt;&lt;/a&gt;Setting Up the Host System&lt;/h2&gt;&lt;img src=&quot;../../img/posts/LFS-intro/VM-install.png&quot; alt=&quot;VM installation Complete&quot; /&gt;&lt;p&gt;LFS is constructed from a host environment that has the software required to build and compile all the components of the system. This host system can be a current Linux install, a seperate computer that is dedicated to LFS, or a Linux virtual machine. The LFS system is then assembled in a another partition, or even on a separate hard drive.&lt;/p&gt;&lt;p&gt;I setup a KVM virtual machine using Virt Manager for my host system, and then attached a virtual hard drive to build LFS on. I decided to use a &lt;a href='https://www.ubuntu.com/download/desktop'&gt;Ubuntu 16.04 Desktop&lt;/a&gt; install because it should have most of the build tools, and it is easy to install any missing ones. For now, I configured the VM to use 4 cores and 4GB of RAM, but I might decide to increase that when I start compiling packages. I also decided to not worry about any of the fancy partitioning options like setting up LVM or disk encryption, and just let the installer automatically do it for me. Those features are not really needed here and I figured it would just potentially confuse me.&lt;/p&gt;&lt;p&gt;&lt;center&gt;&lt;img src=&quot;../../img/posts/LFS-intro/HD-add.png&quot; alt=&quot;Adding LFS hd&quot; /&gt;&lt;/center&gt;&lt;/p&gt;&lt;p&gt;After the VM finished installing, I shutdown the system and added a virtual drive. This will be the virtual drive that I build the entire LFS system in. Then I started up the VM again, confirmed that everything installed correctly, and installed openssh so that I could just ssh into the system from my desktop if I didn't feel like working inside the VM's GUI.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;setting&amp;#95;up&amp;#95;the&amp;#95;host&amp;#95;environment&quot;&gt;&lt;/a&gt;Setting up the Host Environment&lt;/h3&gt;&lt;h4&gt;&lt;a name=&quot;checking&amp;#95;required&amp;#95;packages&quot;&gt;&lt;/a&gt;Checking Required Packages&lt;/h4&gt;&lt;img src=&quot;../../img/posts/LFS-intro/environment-check-pre.png&quot; alt=&quot;Adding LFS hd&quot; /&gt;&lt;p&gt;Now that the host system was setup, the host &lt;em&gt;environment&lt;/em&gt; had to be configured. Luckily, LFS provides a nice script that can be copy and pasted into a terminal. This script prints out what required packages and programs are not yet installed on the system (make sure to run it as either root, or using sudo). When I ran the script, there were a few missing packages that had to be installed:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;bison&lt;/li&gt;&lt;li&gt;gawk&lt;/li&gt;&lt;li&gt;texinfo (makeinfo)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;So, I just ran a simple &lt;code&gt;apt-get install bison gawk texinfo&lt;/code&gt; command and was good to go. I also had a symlink issue because &lt;code&gt;/bin/sh&lt;/code&gt; was pointing to &lt;code&gt;/bin/dash&lt;/code&gt;, and LFS wants it to point to &lt;code&gt;/bin/bash/&lt;/code&gt;. This was easily resolved using the command &lt;code&gt;ln -sf bash /bin/sh&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/LFS-intro/environment-check-post.png&quot; alt=&quot;Adding LFS hd&quot; /&gt;&lt;/p&gt;&lt;p&gt;After installing those few packages and fixing the symlink, the check script was happy, and I could move on.&lt;/p&gt;&lt;h4&gt;&lt;a name=&quot;checking&amp;#95;libraries&quot;&gt;&lt;/a&gt;Checking Libraries&lt;/h4&gt;&lt;img src=&quot;../../img/posts/LFS-intro/library-check.png&quot; alt=&quot;Adding LFS hd&quot; /&gt;&lt;p&gt;After verifying that my host system had all the required packages, I had to confirm that a few libraries were &quot;consistent&quot;. Again, LFS provides a simple script for this. When I ran it, the three libraries were not found. Tthe books states that all the files should either be &lt;em&gt;absent&lt;/em&gt; or &lt;em&gt;present&lt;/em&gt;. If one or two are there and the others missing, that is a problem. So my system was okay.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;formatting&amp;#95;the&amp;#95;lfs&amp;#95;disk&quot;&gt;&lt;/a&gt;Formatting the LFS Disk&lt;/h3&gt;I added my LFS disk through the Virt Manager settings, which doesn't format it, so that had to be done next. &lt;p&gt;&lt;img src=&quot;../../img/posts/LFS-intro/disks.png&quot; alt=&quot;Adding LFS hd&quot; /&gt;&lt;/p&gt;&lt;p&gt;I first used &lt;code&gt;lsblk&lt;/code&gt; to confirm the disk name. In my case it was the &lt;code&gt;/dev/sdb&lt;/code&gt; disk.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/LFS-intro/mkfs.png&quot; alt=&quot;Adding LFS hd&quot; /&gt;&lt;/p&gt;&lt;p&gt;After getting the disk's path, it was time to format. I decided to format the disk with t the basic, but very solid ext4 file system using the following command (again, as root or using &lt;em&gt;sudo&lt;/em&gt;):&lt;/p&gt;&lt;p&gt;&lt;code&gt;mkfs.ext4 -v /dev/sdb&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Note that the &lt;code&gt;-v&lt;/code&gt; was not required, but I personally prefer to see the output. Also, if I wanted to specify the drive using the UUID, that could be accomlished using the &lt;code&gt;-U&lt;/code&gt; flag to specify a UUID instead of the file path.&lt;/p&gt;&lt;p&gt;The next few preparatory steps before starting to build LFS must be done each time the host system boots, so I think I am going to break that into a separate post. That way, it can be more easily referenced. Enjoy!&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Wed, 01 Mar 2017 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/introducing-kadabra/
</guid>
<link>
http://ryan.himmelwright.net/posts/introducing-kadabra/
</link>
<title>
Introducing Kadabra - My New, Used x230
</title>
<description>
&lt;p&gt;As I start to do more with a computer on the go, the netbooks I previously used just are not cutting it anymore. They were great for minimal use, but couldn't run VMs, over-heated, and didn't have great battery life. Now that I am going to libraries and other locations to work on personal and open source projects, I really needed a better mobile pc setup. &lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;other&amp;#95;considerations&quot;&gt;&lt;/a&gt;Other Considerations&lt;/h3&gt;&lt;img src=&quot;../../img/posts/introducing-kadabra/asus_x201e.png&quot; alt=&quot;Asus x201e&quot; /&gt;&lt;p&gt;I had been keeping an eye open for a new mobile computer for well over a year to find out what is out there. I mostly looked sub $300 ubuntu laptops like the Asus 11&quot;  celeron (x201e) I got in college. I don't need much HD space on my portable computer, because I usually use a minimal OS, and only have my projects (which are git controlled), and sometimes a  &lt;i&gt;little bit&lt;/i&gt; of music. Even with dropping my requirements to computers with &lt;i&gt;very tiny&lt;/i&gt; HDs (often &lt; 60GB), none of the options seemed all that impressive. They usually had Celeron processors and little ram. Even worse, they were not easily expandable. I also briefly entertained the idea of putting Linux on a chrome book, but they had the same issues that all the other sub $300 options had.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;used&amp;#95;thinkpads&quot;&gt;&lt;/a&gt;Used Thinkpads&lt;/h3&gt;&lt;p&gt;When I intensified my search, I started to consider other options. There is one alternative that is very popular among Linux users, but I always seem to forget about it when looking for a new device. That option of course, is buying a used Thinkpad and installing Linux on it. This appeared to be an ideal time to try it out. I don't mind if there is a scratch or two on a cheap device. This is my portable computer after all, so I'm sure a shinny new device wouldn't stay pristine for long anyway. So, I started researching used Thinkpads and loved how much you could get for the money. There were i5 devices with an acceptable bit of ram and &quot;okay&quot; hard drives for under my $300 price point. Better yet, the Thinkpads seemed easy to upgrade .  So, even if the device had a bad battery, or needed a RAM/HD upgrade, &lt;i&gt;I could could do it&lt;/i&gt;. &lt;/p&gt;&lt;p&gt;I eventually narrowed my search down to the X230 or T430s. That year's model seemed like the perfect mix of still being relatively new, while  also being old enough that many business had started to replace them, flooding the market and driving the cost down. They also didn't have the terrible track pad that the x240 and T440s had (without buttons). I eventually decided on the x230 because the main use of this laptop would be portability.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;this&amp;#95;particular&amp;#95;thinkpad&amp;#95;x230&amp;#95;...&quot;&gt;&lt;/a&gt;This Particular Thinkpad x230 ...&lt;/h3&gt;&lt;img src=&quot;../../img/posts/introducing-kadabra/kadabra2.jpg&quot; alt=&quot;Kadabra&quot; /&gt;I found my used x230 on Amazon, for about $185. The vendor an acceptable rating, and the specs were good for the price:&lt;ul&gt;&lt;li&gt;Intel i5-3320M&lt;/li&gt;&lt;li&gt;4 GB RAM&lt;/li&gt;&lt;li&gt;12.5&quot; 1366x768 HD LED Display&lt;/li&gt;&lt;li&gt;320 GB HHD&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The listing also said that it came with a &quot;used 6-cell battery&quot;. So I planned from the beginning to have it replaced. Sure enough, when the laptop arrived,  the battery was completely dead. If I unplugged the laptop, it would shutdown.  So, I ordered a 9-cell battery online to replace it. I added a 4GB stick of RAM that I took from an older laptop, and replaced the slow HHD (with Windows pre-installed), with a cheap 120GB SSD I had lying around. After installing Korora 24 on the new SSD, I had a nice, portable computer that only cost me about $200 (plus some spare parts). As advertised, swapping the battery, adding RAM, and replacing the HD were &lt;i&gt;super simple&lt;/i&gt; and &lt;i&gt;accessible&lt;/i&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;what&amp;#95;i&amp;#95;like&amp;#95;about&amp;#95;it&quot;&gt;&lt;/a&gt;What I like about it&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Track point&lt;/strong&gt; - I love track points. Using other laptops withjust track-pads is really frustrating now. I completely understand why  people are so crazy about them.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Keyboard&lt;/strong&gt; - The keyboard really is great. I feels solid and not like  other laptop keyboards. It gives good feedback and is very nice to type on. I know many  people hate this model because keyboard layout changed from the  older models like the x220, but I still think the x230 has a better  keyboard than most laptops.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Physical buttons&lt;/strong&gt; - The x230 has a physical mute, volume control, and  mic buttons. This is a feature I enjoy much more than I thought I  would.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Upgradability&lt;/strong&gt; - As I have already mentioned, it is &lt;i&gt;very&lt;/i&gt; easy  to upgrade the x230. Right when I got it, I replaced the HHD with an  SSD and added another stick of RAM in under five  minutes. In fact, I have swapped the SSD out temporarily witha second drive several times now to try out different distros on the  hardware. It is just so easy to do.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Feel&lt;/strong&gt; - I really like how this laptop feels. I've already  mentioned that I enjoy the solidness of the keyboard, but I also  love the exterior texture of the case. It has a slight rubbery  feel to it that makes it easy to hold.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Bang for your buck&lt;/strong&gt; - Getting a used thinkpad really is a  great deal. Even counting the minor upgrades I installed, I was able  to get &lt;i&gt;an actual computer&lt;/i&gt; for around the same price as the   &lt;i&gt;netbook&lt;/i&gt; alternatives I was looking at.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Size&lt;/strong&gt; - This is my mobile computer, so I need it to be  small. While it isn't as thin as my wife's macbook air, it is still  very portable. I actually don't mind it being a little bit thicker,  as I find it to be the perfect size to hold and carry around. It is  a similar size to a few of my programming books and slides into my  backpack very easily.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;a name=&quot;what&amp;#95;i&amp;#95;don't&amp;#95;like&quot;&gt;&lt;/a&gt;What I don't like&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Has a little bit of flex&lt;/strong&gt; - While the laptop overall feels pretty  solid, the screen does have a bit of flex when pressed.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Resolution&lt;/strong&gt; - I really hate 1366x768 on laptops. I don't need 1920x1080, which would be very tiny on a 12.5&quot; screen. 1600x900 however...&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Track pad (but honestly who cares)&lt;/strong&gt; - The track-pad isn't great. In fact, it can be downright annoying. The bottom of the track-pad curves around the edge of computer, which looks nice, but rubs against my stomach when I am working with the laptop on my lap. This causes the cursor to fly around and do everything but what I want it to do. This would be a much bigger issue on other laptops, but with how much I use the track point, I really don't care. I usually just disable the track-pad all together.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Speakers aren't great (but again, not a bit deal)&lt;/strong&gt; - The speakers are very quiet and don't  sound very good. This isn't a huge deal for me because being my mobile computer, I am using  headphones 99% of the time. Still, it would be nice if when I occasionally share a video with someone they could actually hear it.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;a name=&quot;conclusions&quot;&gt;&lt;/a&gt;Conclusions&lt;/h3&gt;&lt;img src=&quot;../../img/posts/introducing-kadabra/kadabra.jpg&quot; alt=&quot;Kadabra&quot; /&gt;I have had Kadabra for several months now and still love it. I use it at work daily (to listen tomusic, podcasts, and to have a &lt;i&gt;linux&lt;/i&gt; computer available to me at all times in a Windows office). It is a perfect mix of being portable while still having enough power to accomplish whatever I want to work on. I still prefer to vote with my wallet by purchasing from a vendors like &lt;a href='http://www.system76.com'&gt;System76&lt;/a&gt; when possible, but buying used business hardware, such as thinkpads, is a very affordable alternative. I have no regrets buying my used x230. It is infinitely better than my other options at that price point.&lt;h3&gt;&lt;a name=&quot;update&quot;&gt;&lt;/a&gt;Update&lt;/h3&gt;&lt;i&gt;I have taken so long to publish this post, I am actually now using Arch Linux on Kadabra. It also runs great :)&lt;/i&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Tue, 29 Nov 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/snapd-on-arch/
</guid>
<link>
http://ryan.himmelwright.net/posts/snapd-on-arch/
</link>
<title>
Trying out snapd on Arch Linux
</title>
<description>
&lt;p&gt;The past few weeks I have been listening to all of the buzz about Ubuntu &quot;snaps&quot;, but I just recently decided to try this new technology out.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;snapd&amp;#95;install&amp;#95;and&amp;#95;setup&quot;&gt;&lt;/a&gt;Snapd Install and Setup&lt;/h3&gt;&lt;p&gt;I decided to install snapd on my small netbook (Abra), which is running Arch Linux. So, installing snapd was as easy as running:&lt;/p&gt;&lt;p&gt;&lt;code&gt;pacaur -S snapd&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Now, I use pacaur so that I can install packages from Arch Linux's main repos, as well as the AUR. However, because snapd has actually been moved to the community repos, you can install it with vanilla pacman, without aur support.&lt;/p&gt;&lt;p&gt;&lt;code&gt;sudo pacman -S snapd&lt;/code&gt;&lt;/p&gt;&lt;p&gt;After snapd is installed, it needs to be started. To start the snapd service, just use systemd:&lt;/p&gt;&lt;p&gt;&lt;code&gt;sudo systemctl start snapd&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Additionally, If you want to start the snapd service automatically after a reboot run the command:&lt;/p&gt;&lt;p&gt;&lt;code&gt;sudo systemctl enable snapd&lt;/code&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;using&amp;#95;snap&quot;&gt;&lt;/a&gt;Using snap&lt;/h3&gt;&lt;p&gt;After snapd was installed and running, I started playing with the snap application. The first thing I should note is that to the extent of my knowledge, snap has to be run as root (at least for now). So my commands all start with &lt;code&gt;sudo&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;First, I wanted to find a snap package. This can be done using the &lt;code&gt;snap find&lt;/code&gt; command as follows:&lt;/p&gt;&lt;p&gt;&lt;code&gt;sudo snap find package-name&lt;/code&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;(where &lt;strong&gt;package-name&lt;/strong&gt; is the name of the package to search)&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/arch-snaps/snap-find.png&quot; alt=&quot;Finding Snaps&quot; /&gt;&lt;/p&gt;&lt;p&gt;Just like in any standard package manager search, the potential matches were returned, along with a version number, the developer name, and a summary.&lt;/p&gt;&lt;p&gt;Snap has several other commands. To see a full list of available snap commands and a description for each one, just type:&lt;/p&gt;&lt;p&gt;&lt;code&gt;sudo snap help&lt;/code&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/arch-snaps/snap-help.png&quot; alt=&quot;Snap Help&quot; /&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;testing&amp;#95;a&amp;#95;snap&quot;&gt;&lt;/a&gt;Testing a snap&lt;/h3&gt;&lt;p&gt;After learning about the basic snap commands, I wanted to install a snap to see how well it works. I decided to see if there was a Telegram snap (I heard there was, so it was a good bet). I ran &lt;code&gt;sudo snap find telegram&lt;/code&gt;, and a list of my options appeared.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/arch-snaps/snap-telegram-install.png&quot; alt=&quot;Snap telegram&quot; /&gt;&lt;/p&gt;&lt;p&gt;I choose the last one, and installed it using the command  &lt;code&gt;sudo snap install telegram-serguisens&lt;/code&gt;. A progress bar tracked the download of the snap, and then the installation. That was it. To my delight, within a few seconds the Ubuntu &lt;code&gt;snap&lt;/code&gt; application had downloaded the telegram snap, and installed it on my &lt;i&gt;arch linux&lt;/i&gt; box, without any issue.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;my&amp;#95;only&amp;#95;issue&quot;&gt;&lt;/a&gt;My Only Issue&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/arch-snaps/snap-telegram-menu.png&quot; alt=&quot;Snap Help&quot; /&gt;&lt;/p&gt;&lt;p&gt;Well... &lt;i&gt;almost&lt;/i&gt; without any issues. The one problem I did have was after installing the telegram snap, the executable wasn't in my path so I couldn't start it from my launcher or even a terminal. I think this was actually because snapd wasn't setup fully. I rebooted my computer and telegram now launches just fine. The snap is even identified with its full name (&lt;i&gt;telegram-serguisens&lt;/i&gt;), so I can be sure it is the actual snap, and not another Telegram install.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;thoughts&quot;&gt;&lt;/a&gt;Thoughts&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/arch-snaps/snap-telegram.png&quot; alt=&quot;Snap Help&quot; /&gt;&lt;/p&gt;&lt;p&gt;While the fact that snaps are easy to package and install for developers and users alike, I think my favorite feature was something that I didn't even think about prior to trying it out, and I might not of realized had I installed snapd on another computer...&lt;/p&gt;&lt;p&gt;This little computer is low power, and tends to heat up and go crazy when I install certain packages (particularly ones from the AUR). Sometimes it is so bad that I have to kill the installation and forego that application for awhile. Telegram is one of them. I think this is because the aur build pulls down the telegram .deb package and then has to extract and compile it in order to install it on Arch. This little computer doesn't like that. The snap however, seems to of just download and installed itself. It hardly pegged my CPU at all. If this is true, snaps might have an additional use-case on weaker hardware, like my netbook. (yes, I know snaps might have a bigger disk footprint, but honestly that trade-off is fine with me)&lt;/p&gt;&lt;p&gt;I think the universal application frameworks are a great idea that is very much needed on Linux. Snapd is very promising and I look forward to seeing what it and other solutions have in store for the future of Linux.&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Sun, 17 Jul 2016 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/Trying-out-plasma5/
</guid>
<link>
http://ryan.himmelwright.net/posts/Trying-out-plasma5/
</link>
<title>
Trying Out the Plasma 5 Desktop Environment
</title>
<description>
&lt;p&gt;After watching the continued development of the Plasma 5 desktop environment from a distance, I determined I needed to give it another try. It was just before version 5.6 was released, and the project appeared to be finding it's stride. Right up front, I want to come clean and admit that I have never really liked the KDE/Plasma desktop environment (more on that below). However, with that said... I am still using the plasma desktop on my main computer (months later, and haven't aborted yet**...). Here are my thoughts.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;my&amp;#95;history&amp;#95;with&amp;#95;kde/plasma&quot;&gt;&lt;/a&gt;My History with KDE/Plasma&lt;/h3&gt;&lt;p&gt;Now, as I said above, &lt;i&gt;I have never really liked KDE (now Plasma)&lt;/i&gt;. In fact, sometimes I down right &lt;i&gt;hated&lt;/i&gt; it. It is a great project, and I &lt;i&gt;wanted&lt;/i&gt; to like it. It has so many features and is amazing for power users. I have tried it again and again, desperately wanting to be swept off my feet, but it's design always kept me bolted to the ground. The theming made me feel like I was using a Fisher-Price operating system (which is ironic, because like I said... the plasma desktop is probably one of the best power user environments out there). The bulky features always made it feel childish. So, with that said... I have been using using the Plasma desktop on all of my personal computers for several months. Here are my thoughts.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;pros&quot;&gt;&lt;/a&gt;Pros&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;The theming has come a long way&lt;/strong&gt;. It no longer looks like a  child's toy. Even the default theme is &lt;i&gt;very&lt;/i&gt; appealing. Also, it  has &lt;em&gt;dark themes&lt;/em&gt;, which I am always a fan of.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/plasma-desktop/default-plasma.jpg&quot; alt=&quot;Default KDE Plasma 5.6 Desktop&quot; /&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;I Love the customization.&lt;/strong&gt; I love the level of customization  the plasma desktop allows. I can set transparency, add/remove  panels or widgets, set custom keybindings (very important to me),  and a bunch of other operations very easily.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/plasma-desktop/settings.jpg&quot; alt=&quot;Plasma Settings&quot; /&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Lets me hide window bars&lt;/strong&gt; One customization I love is the ability  to hide the window bars. I am not a fan of window bars, because I  think they look clunky and just take up space. One feature I like  about many tiling window managers is it is usually very easy to hide  the window bars. However, that isn't always the case in Desktop  Environments, but I was pleased with how easy it was to do it in  Plasma.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;It Lets me create an awesome-wm environment, but as a full DE&lt;/strong&gt;  Similar to above, I am able to implement some of the features I love  about tiling window managers like awesome and i3, but with the full  desktop environment. In addition to removing window bars, I like to  easily move and resize windows by hitting the meta or alt key and  left/right clicking the windows. Again, in Plasma this was simple.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;I love krunner. A lot.&lt;/strong&gt; I like using application launchers, and  krunner looks nice, is lightning fast, and gets the job done. I  didn't really know much about krunner during previous attempts at  using KDE. This was definitely contributor to why I liked it much  more this time around.  &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/plasma-desktop/krunner.png&quot; alt=&quot;Plasma Settings&quot; /&gt;   &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;The ability to use old-school animations is fun&lt;/strong&gt; There is not much to say  here. While not very practical, sometimes spinning a desktop cube is  just straight up &lt;i&gt;fun&lt;/i&gt;.  &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/plasma-desktop/cube.png&quot; alt=&quot;Desktop Cube&quot; /&gt;   &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Fast. Even for a full DE&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;a name=&quot;cons&quot;&gt;&lt;/a&gt;Cons&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Multi-monitor support. WTF.&lt;/strong&gt; This was by far the biggest issue I  had. My main computer is a 17&quot; laptop that I connect to two 24&quot;  displays. However, because it is a indeed a laptop, I sometimes move  it around and be semi-mobile with it. This requires disconnecting the  monitors and going from 1 screen to 3 or vice-versa. Well it turns  out that this is usually a pain in the ass for me in Plasma. First,  I have to configure the monitors one-by-one, hitting &quot;apply&quot; between  each configuration (it doesn't like when I try to move and place all  3 displays in one swoop). Second, once I setup the screen placement,  the panels often go crazy and can't be found, or I have to play  with them to set them up correctly. Lastly, sometimes the displays  overlap each other oddly, even though they appear normal in the  display settings. The wallpapers almost never set correctly and my  right-click menu is disabled on some screens but not  others. Basically, it's just a hot mess and the most infuriating  problem I faced when using Plasma. If I used a laptop without  monitors, or even a permanent desktop setup, I would be  fine. However, that is not my use case.  &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/plasma-desktop/wtf-multi-monitor.png&quot; alt=&quot;Plasma Settings&quot; /&gt;   &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Randomly just stops working&lt;/strong&gt; Sometimes, KDE applications just  crash and I can't seem to get them back. Widgets seemed to beak  things more frequently, so I just stopped using them. (Again, not a  good solution)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;A full DE&lt;/strong&gt; While I said above that it was nice having an  environment that resembled a window manager, but had the benefit of  the full suite of applications that come with a desktop environment,  sometimes it was also a pain. There's just a lot of crap that I  don't use. The obvious reminder of this was when I would run  &lt;code&gt;pacman -Syu&lt;/code&gt;, and see that the massive KDE stack would need  updates.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Sometimes all the settings can be very confusing&lt;/strong&gt; Having all  these options is great, but sometimes it was  overwhelming. Additionally, the settings felt disjointed and I  didn't know where the settings for some things where.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;a name=&quot;final&amp;#95;thoughts&quot;&gt;&lt;/a&gt;Final Thoughts&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;I can finally use Plasma&lt;/li&gt;&lt;li&gt;Very fast and lightweight for all that it is&lt;/li&gt;&lt;li&gt;Still has a bit of stability/polish work to go&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;** &lt;i&gt;Update: I took forever to get this post out and I have actually moved off of Plasma. I just couldn't handle the multi-monitor issues I had. However, I will definitely be trying out the Desktop Environment again in the future (I moved to i3-gaps for now. I love my tiling window managers :) )&lt;/i&gt;&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Sun, 26 Jun 2016 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/website-switched-to-cryogen/
</guid>
<link>
http://ryan.himmelwright.net/posts/website-switched-to-cryogen/
</link>
<title>
Using Cryogen for Website
</title>
<description>
&lt;p&gt;Ever since resurrecting my personal website, I have experimented with several static website generators. Thus far, I have tried &lt;a href='https://github.com/kelvinh/org-page'&gt;org-page&lt;/a&gt;, &lt;a href='http://jekyllrb.com/'&gt;Jekyll&lt;/a&gt; (&lt;i&gt;several&lt;/i&gt; times), and even (almost) made  &lt;a href='https://github.com/himmAllRight/ryBlog/blob/master/org-blog.el'&gt;my own emacs org-page solution&lt;/a&gt;. Now that I have started using the &lt;a href='http://clojure.org/'&gt;clojure&lt;/a&gt; programming language, I have come across &lt;a href='http://cryogenweb.org/'&gt;cryogen&lt;/a&gt;. As you may have already guessed, this site is now being generated using cryogen.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;emacs/org-mode&amp;#95;solutions&quot;&gt;&lt;/a&gt;Emacs/org-mode Solutions&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/using-cryogen-for-website/Emacs-icon.png&quot; alt=&quot;emacs logo&quot; /&gt; &lt;img src=&quot;../../img/posts/using-cryogen-for-website/org-mode-unicorn.png&quot; alt=&quot;org-mode unicorn&quot; /&gt;&lt;/p&gt;&lt;p&gt;About a year ago, obsession with &lt;a href='https://www.gnu.org/software/emacs/'&gt;emacs&lt;/a&gt; (and more importantly, org-mode) eventually led me to try out &lt;a href='https://github.com/kelvinh/org-page'&gt;org-page&lt;/a&gt; while revitalizing my personal website. The idea of writing webpage content in .org files was &lt;i&gt;very&lt;/i&gt; appealing and I wanted to gain a more experience writing emacs lisp, so it seemed like a good choice. Overall, org-page was a good learning experience, but I found the documentation and support to be lacking. It seemed to be more of a &lt;a href='http://kelvinh.github.io/'&gt;personal project&lt;/a&gt;, rather than a fully supported framework. while I know &lt;a href='http://cmacr.ae/'&gt;other people&lt;/a&gt; were able to get it working, org-page simply wasn't working for me.&lt;/p&gt;&lt;p&gt;For over a year now, I have used org-mode at work each week to track my hours and to take notes (including code snippets). I then export the org files to html, creating a full index of my work notes/logs. After digging deeper into org-page, realized it was just a fancy wrapper around the org-project functions I used at work. So, I decided to implment &lt;a href='https://github.com/himmAllRight/ryBlog/blob/master/org-blog.el'&gt;my own emacs org-page solution&lt;/a&gt; (well, &lt;i&gt;half&lt;/i&gt; implement... I guess I never fully finished it). Creating my own solution helped me learn even more about org-mode (which helped with my work notes), but I ultimately abandoned using this method for my personal website. Managing my own solution quickly became a pain because I had to setup emacs, install the dependencies, and get a &lt;i&gt;.emacs&lt;/i&gt; file working &lt;i&gt;just right&lt;/i&gt; on any compuer I wanted to generate the site from.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;jekyll&quot;&gt;&lt;/a&gt;Jekyll&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/using-cryogen-for-website/jekyll.png&quot; alt=&quot;jekyll logo&quot; /&gt;&lt;/p&gt;&lt;p&gt;My first experience with &lt;a href='http://jekyllrb.com/'&gt;Jekyll&lt;/a&gt; was about two years ago, right after I graduated college. It was the first true static website generator that I tried and I absolutely loved the concept. You see, I taught myself how to build websites in the early to mid 2000's when I was in middle school, and apparently never developed beyond that point. During college, I maintained a personal site by hand. It was super simplistic html that used tables for the layout, and css for coloring. That's about it. Using a static website generator like Jekyll for the first time was amazing, since it automatically produced static webpages that looked &lt;i&gt;much&lt;/i&gt; better than anything I could do by hand. All I had to worry about was the content. It was what 12-year-old-me longed for (and tried to do using iframes and other messiness). I eventually stopped using Jekyll because I was unable to get the theming quite right, and ... well ... I started &lt;i&gt;really&lt;/i&gt; getting into emacs. But you've already heard that story.&lt;/p&gt;&lt;p&gt;After taking a breif hiatus from Jekyll to adventure deeper into emacs land, I returned. This time, I was able to find and configure a &lt;a href='https://github.com/joshgerdes/jekyll-uno'&gt;enticing theme&lt;/a&gt; that fit my needs. My personal website probably looked the best is ever has, and I really enjoyed it. However, I have recently become frusterated using Jekyll (again). It is a great static website generator, but because I don't often develop in Ruby (right now), setting up the proper ruby gems environment and dependencies on &lt;a href='../../pages/homelab/'&gt;my computers&lt;/a&gt; makes me want to bang my head against the wall. Additionally, I have been learning &lt;a href='http://clojure.org/'&gt;clojure&lt;/a&gt; and while digging through different clojure projects, I found &lt;a href='http://cryogenweb.org/'&gt;cryogen&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;cryogen&quot;&gt;&lt;/a&gt;Cryogen&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/using-cryogen-for-website/cryogen.png&quot; alt=&quot;Cryogen logo&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;a href='http://cryogenweb.org/'&gt;Cryogen&lt;/a&gt; is a static website generator written in &lt;a href='https://clojure.org/'&gt;Clojure&lt;/a&gt;.  If you already have &lt;a href='http://leiningen.org/'&gt;Leiningen&lt;/a&gt; installed (which if using Clojure, you should), starting a new Cryogen application is as easy as entering &lt;code&gt;lein new cryogen project-name&lt;/code&gt; into a terminal. Once the project is created, you can &lt;code&gt;cd&lt;/code&gt; into the directory and run &lt;code&gt;lein ring server&lt;/code&gt;. Clojure will then fire up a local webserver of the compiled project (by default on port 3000). Whenever a change to a project file is saved, the cryogen server re-compiles the project and updates the webserver. As a result, it easy to edit and see the changes live. Cryogen has a rather large, but simple &lt;a href='http://cryogenweb.org/docs/structure.html'&gt;directory structure&lt;/a&gt; that is used to organize the project. This structure is slightly different from Jekyll, and takes a bit of getting to, but I think it does a better job at keeping everything organized once you learn it.&lt;/p&gt;&lt;p&gt;The one thing I &lt;i&gt;really&lt;/i&gt; like about Cryogen is the fact that... well... it's clojure. This means that things can often feel more &quot;lisp-y&quot;. For example, in Jekyll, the preferences and configuration of the website are kept inside a yaml configuration file. Similarly, the meta-data and information for a page or blog post are defined in a very specific yaml header at the top of the markdown files. Cryogen follows a similar concept, but instead of yaml headers, it simply uses a p-list for the &lt;a href='http://cryogenweb.org/docs/configuration.html'&gt;configuration setup&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;To change a post's information (ex: title, author, date), one just has to change the keywords in the list at the top of the post's markdown file. This flexability means that figuring out how to setup use my own configuration was a breeze. For programmers that have previously used Clojure or another LISP, the configuration in Cryogen is very intuitive and natural.&lt;/p&gt;&lt;p&gt;The only &lt;i&gt;downside&lt;/i&gt; (sort of... it's my fault) I have experienced while using Cryogen is that being a smaller community, there isn't much out there in terms of templetes and themes (at least that I was able to find during a lazy search). So, while I was able to easily setup an amazing looking website using Jekyll (by using someone else's hard work), I am forced to be a bit more hands-on using cryogen. Initially, I thought this was a negative, but after spending some time hacking away at the default theme and cleaning some rust off css/html skills, I think I have the site looking &lt;i&gt;good enough&lt;/i&gt; for now. As a bonus, I am starting to re-learn web design. However, I am &lt;i&gt;slowly&lt;/i&gt; catching up, so &quot;modern&quot; design features like mobil support might not happen right away. It's not the best looking site, but I has personal touch, which I guess is good in a personal website.&lt;/p&gt;&lt;p&gt;That's about it. That's why my site suddenly looked different one weekend. If I look forward to using both Clojure and Cryogen more for not only this website, but other personal projects as well.&lt;/p&gt;&lt;p&gt;&lt;i&gt;* PS: Re-reading this post I realize trying Cryogen after getting excited about Clojure is VERY much like when I started using org-page after getting excited about emacs. Hopefully this setup is a keeper that I stick with. ;)&lt;/i&gt;&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Wed, 13 Apr 2016 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/back-on-arch/
</guid>
<link>
http://ryan.himmelwright.net/posts/back-on-arch/
</link>
<title>
Back On Arch, After Frantic Distro-hopping
</title>
<description>
&lt;p&gt;In the last few weeks, I have started my CS masters classes, and needed to setup a productive work environment on my portable laptop (&lt;a href='../../homelab'&gt;abra&lt;/a&gt;). Also, while I love Fedora, the Nvidia stuff was being a pain on my main computer (&lt;a href='../../homelab'&gt;alakazam&lt;/a&gt;), and I was looking for a replacement there as well. So, after a long, drawn out battle trying nearly all of my favorite Linux distros, I have found myself once again using &lt;a href='https://www.archlinux.org/'&gt;Arch Linux&lt;/a&gt; on both of my personal computers.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash;more&amp;ndash;&gt;&lt;/p&gt;&lt;p&gt;&lt;a name=&quot;fedora&quot;&gt;&lt;/a&gt;&lt;h2&gt;&lt;a name=&quot;from&amp;#95;fedora...&quot;&gt;&lt;/a&gt;From Fedora...&lt;/h2&gt;&lt;img src=&quot;../../img/back-on-arch/fedora-logo.png&quot; alt=&quot;Fedora&quot; /&gt;&lt;/p&gt;&lt;p&gt;When I started my journey, I had Fedora on both of my computers. I really like the &lt;a href='https://www.getfedora.org'&gt;Fedora Project&lt;/a&gt; and I think Fedora is a great distribution with a lot of innovative new features. I seems that the Fedora Project is aiming to be the Linux Distro for developers, and I feel that they are really starting to hit that target.&lt;/p&gt;&lt;p&gt;There is one remaining big issue I had while running Fedora on my main computer. Nvidia drivers. They are just a pain to maintain, and kept breaking my system during updates. I know the &lt;a href='http://rpmfusion.org/'&gt;RPM Fusion Repos&lt;/a&gt; are supposed to help, but they just aren't there yet. With my classes starting, I needed something that was a bit more stable (and would hopefully support installing VMWare Workstation 9).&lt;/p&gt;&lt;p&gt;&lt;a name=&quot;ubuntu&quot;&gt;&lt;/a&gt;&lt;h2&gt;&lt;a name=&quot;the&amp;#95;'easy&amp;#95;stability'&amp;#95;of&amp;#95;ubuntu-based?&quot;&gt;&lt;/a&gt;The 'Easy Stability' of Ubuntu-based?&lt;/h2&gt;&lt;img src=&quot;../../img/back-on-arch/ubuntu-mate-logo.png&quot; alt=&quot;Ubuntu Mate&quot; /&gt;&lt;/p&gt;&lt;p&gt;Guided by desires to have a &quot;stable&quot; distro, I decided that the &lt;em&gt;obvious&lt;/em&gt; answer would be to use an &lt;a href='http://www.ubuntu.com/'&gt;Ubuntu&lt;/a&gt;-based distro. So, I went with &lt;a href='https://ubuntu-mate.org/'&gt;Ubuntu Mate&lt;/a&gt;, based on the &lt;i&gt;awesome&lt;/i&gt; work the team has done recently. I've used Ubuntu Mate in the past on several different computers, and in fact, still have it running on &lt;a href='../../homelab/'&gt;charmander&lt;/a&gt;. I had some issues installing Ubuntu Mate on alakazam for some reason, but using a simple &lt;code&gt;nomodeset&lt;/code&gt; at boot seemed work.&lt;/p&gt;&lt;p&gt;After I got it installed, I was able to install the nvidia drivers, but I had other random issues here and there. I also tried installing VMWare, but had issues at every step. To be completely honest, I really wasn't feeling using an Ubuntu distro on alakazam. If I was going to be replacing Fedora, I wanted to make up for it by using something that gave me more power (I've started to get the itch to try out Gentoo again. Spoiler, I am not using Gentoo. At least until my class is over...). While Ubuntu could easily support my needs being the well supported and advanced distro that it is ... I craved something else.&lt;/p&gt;&lt;p&gt;&lt;a name=&quot;opensuse&quot;&gt;&lt;/a&gt;&lt;h2&gt;&lt;a name=&quot;leaping&amp;#95;to&amp;#95;suse?&quot;&gt;&lt;/a&gt;Leaping to Suse?&lt;/h2&gt;&lt;img src=&quot;../../img/back-on-arch/opensuse-logo.png&quot; alt=&quot;OpenSuse Linux&quot; /&gt;&lt;/p&gt;&lt;p&gt;During my last few months on Fedora, I took notice of another rpm distro that was  making noise in the Linux community: &lt;a href='https://www.opensuse.org/'&gt;OpenSuse&lt;/a&gt;. Specifically, the new &lt;a href='https://software.opensuse.org/421/en'&gt;OpenSuse Leap&lt;/a&gt; piqued my interest. I had played with it in a VM a few days earlier and liked what I saw. The OpenSuse installer along with the YaST configuration tool makes it &lt;i&gt;stupid easy&lt;/i&gt; to setup powerful and advanced features in Linux. Want to setup a KVM virtualization environment or a samba share? You basically just have to click a button. Testing out &lt;a href='https://en.opensuse.org/Portal:Snapper'&gt;Snapper&lt;/a&gt; was also slick. I wish more distributions would start to include tools like snapper, built in.&lt;/p&gt;&lt;p&gt;Leap was a solid and extensive distribution. Ultimately though, that was the biggest qualm I had with it: there was a lot going on. I did not know what many of the pre-installed configuration tools were. Normally, I am fine with learning new tools, but I wanted a distribution that I could set up and get to work. OpenSuse had &lt;i&gt;too many&lt;/i&gt; &quot;toys&quot; already in it. I would not be able to resist spending hours learning everything. Ironically, my other complaint was that some of the applications I &lt;i&gt;did&lt;/i&gt; want, were not easily available. Often, they were not included in the default repositories, and while many application websites will provide a &lt;em&gt;.deb download, &lt;/em&gt;.rpms are a bit more scarce. I know there is the wonderful &lt;a href='https://build.opensuse.org/'&gt;openSuse Build Service&lt;/a&gt;, but like &lt;a href='https://copr.fedorainfracloud.org/'&gt;Fedora's copr build system&lt;/a&gt;, I often found it to be hit or miss. Both do a good job at addressing a major issue in their respective distributions, but neither isn't quite to the level of ... well, the &lt;a href='https://aur.archlinux.org/'&gt;AUR&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a name=&quot;antegeros&quot;&gt;&lt;/a&gt;&lt;h2&gt;&lt;a name=&quot;antegeros&quot;&gt;&lt;/a&gt;Antegeros&lt;/h2&gt;&lt;img src=&quot;../../img/back-on-arch/antergos-logo.png&quot; alt=&quot;Antegeros Linux&quot; /&gt;&lt;/p&gt;&lt;p&gt;Which brings me to &lt;a href='https://antergos.com/'&gt;Antergos&lt;/a&gt;. By this point, I was no longer able to hide the fact that I was starting to severely miss many features a distribution like &lt;a href='https://www.archlinux.org/'&gt;Arch Linux&lt;/a&gt; provides. I love that you can easily customize just about &lt;i&gt;anything&lt;/i&gt;. I also appreciate that if I want to try something new, 99% of the time the latest version is already in the official repos or the &lt;a href='https://aur.archlinux.org/'&gt;AUR&lt;/a&gt;. Additionally, when I am trying a new application, or customizing my setup, the &lt;a href='https://wiki.archlinux.org/'&gt;Arch Wiki&lt;/a&gt; has some of &lt;i&gt;the best documentation&lt;/i&gt; in the Linux ecosystem. However, I wanted something that I could just install and have working. I didn't feel like going through a full vanilla Arch install. So I installed Antergos. Antergos has a simple but thorough installer that pulls down all the latest packages during the installation. This leaves the user with an up-to-date and &lt;i&gt;gorgeous&lt;/i&gt; setup after installation.&lt;/p&gt;&lt;p&gt;Unfortunately, the &quot;simplicity&quot; of Antergos (which is sort of the antithesis to the definition of &lt;i&gt;simplicity&lt;/i&gt; in &lt;a href='https://wiki.archlinux.org/index.php/Arch_Linux#Simplicity'&gt;The Arch Way&lt;/a&gt;) always seems to bite me in the end. Eventually, &lt;i&gt;something&lt;/i&gt; breaks, and I have a hard time figuring out &lt;i&gt;what&lt;/i&gt;. While it might be a pain to install &lt;i&gt;everything&lt;/i&gt; in vanilla Arch, the user &lt;i&gt;&quot;has a much fuller understanding of his or her system&lt;/i&gt;&quot; as a result. A few years ago, when I first started using Arch, I thought this argument just stupid gray beard nonsense. Now, I appreciate the benefits of this sentiment, and even agree with it (I've also learned to &lt;a href='https://github.com/himmAllRight/dotfiles/blob/master/archInstallScript.sh'&gt;script&lt;/a&gt; my post install process, so it is less of a pain :P).&lt;/p&gt;&lt;p&gt;After a few days of fighting with Antegeros, I decided to just bite the bullet and install Vanilla Arch. I still think Antegros is a great distribution that works for a bunch of people. It is great for users that want to experience the power of arch Linux, without having to go through all the overhead. Antegeros is actually how I started to learn Arch Linux. Nowadays though, I seem to prefer &lt;i&gt;simplicity&lt;/i&gt; of vanilla Arch. &lt;/p&gt;&lt;p&gt;&lt;a name=&quot;arch&quot;&gt;&lt;/a&gt;&lt;h2&gt;&lt;a name=&quot;all&amp;#95;roads&amp;#95;lead&amp;#95;to&amp;#95;arch&quot;&gt;&lt;/a&gt;All Roads Lead to Arch&lt;/h2&gt;&lt;img src=&quot;../../img/back-on-arch/arch-logo.png&quot; alt=&quot;Arch Linux&quot; /&gt;&lt;/p&gt;&lt;p&gt;I have been running Arch on both of my personal laptops for several weeks now. Arch doesn't magically solve all of my issues, but it makes &lt;i&gt;fixing&lt;/i&gt; them much easier. If something isn't working, the combination of the wiki and the community make the problem &lt;i&gt;much&lt;/i&gt; more approachable. Additionally, the rolling release model appears to mitigate bug-related issues, instead of cause them. For example, I installed Arch on alakazam first, but left Ubuntu Mate on abra (my portable laptop). I did this because my school has a weird network setup that is often difficult to connect to. After searching for hours, I determined that my issues under Ubuntu were caused by a known, but unfixed, bug in my version of network manager. I did not feel like dealing with this, so I installed arch. My internet at school works works fine now. I was able to use the wiki to properly configure my settings, and I was good to go. (Side-note: I never fully got VMWare 9 to work properly on any of my distros, but I came closest with Arch.)&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/back-on-arch/abra-screen.png&quot; alt=&quot;Abra with Arch and Awesome WM&quot; /&gt; &lt;em&gt;Abra running Arch Linux with the &lt;a href='http://awesome.naquadah.org/'&gt;Awesome&lt;/a&gt; window manager&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Being back on arch has been great. I love using tiling window managers like i3, dwm, xmonad, stumpwm, and awesome. While this this is possible on all distributions, it is much easier on arch. Starting with a blank slate, and (again) having the wiki makes setting up alternative desktop environments and window managers a breeze. I now have a &lt;i&gt;very&lt;/i&gt; productive work environment that is tailored to my needs. While Arch Linux might not be a traditional &quot;stable&quot; distribution, I have found it to be much more durable for my use-case.&lt;/p&gt;&lt;p&gt;I am planning to stay on Arch for awhile. That being said, I really did enjoy all the other distributions I tried out. Each one seems to be carving out a niche in the Linux environment:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Fedora is becoming a great distribution for Linux developers. In fact, I still have Fedora 23 (Server Edition) running on my home server. Assuming that the upgrade to 24 goes smoothly (my upgrade from 22 -&gt; 23 went great, thanks to &lt;a href='https://fedoraproject.org/wiki/Features/DNF'&gt;dnf&lt;/a&gt;), I see no reason to switch.&lt;/li&gt;&lt;li&gt;OpenSuse Leap is a solid distribution that is great for power users that want a turn-key distribution with all the bells and whistles. I think it is especially geared toward people with system administration backgrounds.&lt;/li&gt;&lt;li&gt;Ubuntu Mate is really the best distribution out there for people that want a classic feeling Linux environment, with a modern flair. It is what Ubuntu would be if it never left gnome 2. It is also great for low resource hardware, particularly boards like the &lt;a href='https://www.raspberrypi.org/'&gt;raspberry pi&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;Antegros is fantastic for Arch users that hate the Arch install. It is also great for people that want to move to Arch, but aren't yet comfortable with tools like pacman.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It is great to see all the distributions finally finding their groove. This isn't something I could say about Linux 2 years ago. As I have already stated, I plan to stay on Arch Linux for the time being, but I am very excited to continue trying out the new releases of the all distributions listed above. With so many great options, it really is a great time to be a Linux user :) .&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Sun, 13 Mar 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/how-i-asked-my-groomsmen/
</guid>
<link>
http://ryan.himmelwright.net/posts/how-i-asked-my-groomsmen/
</link>
<title>
How I asked my Groomsmen
</title>
<description>
&lt;p&gt;Over the last few months Rebecca (my Fiancee) and I have continued making progress on all the little tasks that we have to complete before our wedding. One of these tasks is asking our intended bridesmaids/groomsmen to be in the wedding.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash;more&amp;ndash;&gt;&lt;/p&gt;&lt;p&gt;Rebecca approached this by asking each of the girls in a way that was somewhat unique to each person, over time. Even though each person was asked differently, all the methods were executed in a very &quot;Rebecca-like&quot; manner.&lt;/p&gt;&lt;p&gt;So, I was told that I couldn't simply ask the guys. I had to figure out a &quot;fun&quot; way to ask them, and if possible, to do it in a way that was very &quot;Ryan-like&quot;.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;asking&amp;#95;the&amp;#95;groomsmen&quot;&gt;&lt;/a&gt;Asking the Groomsmen&lt;/h2&gt;&lt;p&gt;While Rebecca was slowly chipping away at asking her bridesmaids, we kept failing at finding a way to ask the guys. Finally, one night while driving back north to Massachusetts, I said out of frustration:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; &quot;I wish I could just write a stupid piece of code that asks them,  compile it, and give it to them... wait a minute....&quot; &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;At that moment, I started to figure out how I could make it work. The results of that brainstorming session are described below:&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;snail&amp;#95;mail&amp;#95;part&quot;&gt;&lt;/a&gt;Snail Mail Part&lt;/h2&gt;&lt;p&gt;I first had to find a way to give the intended groomsmen a link to get any code that I wrote. So, Rebecca and I designed the tri-fold letter pictured below (Sorry for the photo quality).&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/how-i-asked-my-groomsmen/ask-message1.jpg&quot; alt=&quot;The front of the letter&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Figure 1: The Front of Letter&lt;/em&gt;&lt;/p&gt;&lt;p&gt;The front of the envelope had a simple black boarder and said &quot;She said that I had to make it official.&quot;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/how-i-asked-my-groomsmen/ask-message2.jpg&quot; alt=&quot;The first flap of the letter&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Figure 2: The First Flap of the Letter&lt;/em&gt;&lt;/p&gt;&lt;p&gt;When the reader flipped up that flap, another message read &quot;So we're doing this my way&quot;.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;../../img/posts/how-i-asked-my-groomsmen/ask-message-qr.jpg&quot; alt=&quot;The QR code posted inside the letter&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Figure 3: The QR Code posted on the Inside of the Letter&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Lastly, when the reader folded that flap down, they got a taste of what &quot;my way&quot; might entail when the only thing that was printed on the page was a single QR code.&lt;/p&gt;&lt;p&gt;When the reader scanned the QR code, it opened up a list of instructions on their phone that said:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Find your computer.&lt;/li&gt;&lt;li&gt;Go to &lt;a href='&quot;http://ryan.himmelwright.net/message/&quot;'&gt;http://ryan.himmelwright.net/message/&lt;/a&gt; and follow the instructions. NO LONGER ACTIVE.&lt;/li&gt;&lt;li&gt;Text Me&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;a name=&quot;website&quot;&gt;&lt;/a&gt;Website&lt;/h2&gt;&lt;p&gt;When the intended groomsmen went to the link provided, they saw a webpage that I made, containing our wedding logo on the bottom right, and a welcome message. The welcome message basically stated that the webpage was not the end of the scavenger hunt, and that they would have to download some code that I compiled, that contained the message.&lt;/p&gt;&lt;p&gt;Below the welcome message, I had separate instructions that guided Window, Mac, and Linux users, as well as users that wished to compile from source (sort of).&lt;/p&gt;&lt;p&gt;Below that I had links to the executable downloads for each operating system mentioned. Lastly, I posted the source code for the code they were downloading, because â¦ you knowâ¦ open source. Executable(s)&lt;/p&gt;&lt;p&gt;When the intended groomsmen ran the compiled code (source code posted below), it showed them that it was &quot;decrypting&quot; their message, and printed the percent complete. After about 20% or so, I confessed that there was no &quot;decrypting&quot; and that each message is decoded when printed. I then proceeded to rant in these &quot;decrypting&quot; messages about how I originally wrote a nice GUI python app, but it was a pain to cross compile, and how I eventually just scrapped it and wrote it in LISP. I also mentioned that if they all ran Linux, it wouldn't of been an issue. When it finally reached 100%, I decided to finally give them the message.&lt;/p&gt;&lt;p&gt;Source Code for the executable I wrote containing the message. Nothing fancy, but everything hidden.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;;; Used to build the executable
&amp;#40;defun build-exe &amp;#40;exe-src&amp;#41;
  &amp;#40;sb-ext:save-lisp-and-die exe-src :toplevel #'main :executable t&amp;#41;&amp;#41;

&amp;#40;defun main &amp;#40;&amp;#41;
  &amp;#40;intro-message&amp;#41;
  &amp;#40;decrypt-loading&amp;#41;
  &amp;#40;sleep 1.7&amp;#41;
  &amp;#40;secret-message&amp;#41;&amp;#41;

&amp;#40;defun intro-message &amp;#40;&amp;#41;
  &amp;#40;format t &amp;quot;&amp;#126;a&amp;#126;%&amp;#126;%&amp;quot; &amp;#40;decode-message '&amp;#40;72 101 108 108 111 33 32 80 108 101 97 115 
                                       101 32 119 97 105 116 32 97 32 109 105 110 
                                       117 116 101 32 119 104 105 108 101 32 121 
                                       111 117 114 32 115 101 99 114 101 116 32 
                                       109 101 115 115 97 103 101 32 105 115 32 
                                       100 101 99 114 121 112 116 101 100 33&amp;#41;&amp;#41;&amp;#41;
  &amp;#40;sleep 2&amp;#41;
  &amp;#40;format t &amp;quot;&amp;#126;a&amp;#126;%&amp;quot; &amp;#40;decode-message '&amp;#40;83 116 97 114 116 105 110 103 32 100 101 99 114 
                                     121 112 116 105 111 110 46 46 46&amp;#41;&amp;#41;&amp;#41;
  &amp;#40;sleep 1&amp;#41;&amp;#41;

&amp;#40;defun decrypt-loading &amp;#40;&amp;#41;
  &amp;#40;let&amp;#42; &amp;#40;&amp;#40;messages '&amp;#40;&amp;#40;#\Enq 89 111 117 32 107 110 111 119 44 32 105 116 32 114 101 97 108 108 121
                            32 100 111 101 115 110 39 116 32 116 97 107 101 32 116 104 105 115 32 108 111
                            110 103 32 116 111 32 100 101 99 114 121 112 116 46 46&amp;#41;
                     &amp;#40;#\Newline 73 110 32 102 97 99 116 44 32 105 116 32 116 101 99 104 110 105 99
                      97 108 108 121 32 105 115 110 39 116 32 39 100 101 99 114 121 112 116 105 110
                      103 39 32 97 110 121 116 104 105 110 103 46&amp;#41;
                     &amp;#40;#\Si 69 118 101 114 121 32 109 101 115 115 97 103 101 32 105 115 32 39 100
                      101 99 114 121 112 116 101 100 39 32 119 104 101 110 32 100 105 115 112 108
                      97 121 101 100 46&amp;#41;
                     &amp;#40;#\Dc4 73 110 99 108 117 100 105 110 103 32 116 104 105 115 32 111 110 101 46
                      46 46&amp;#41;
                     &amp;#40;#\Nak 65 110 100 32 84 104 105 115 32 111 110 101 46 46 46&amp;#41;
                     &amp;#40;#\Syn 65 110 100 32 84 104 105 115 32 111 110 101 46 46 46&amp;#41;
                     &amp;#40;#\Etb 65 110 100 32 84 104 105 115 32 111 110 101 46 46 46&amp;#41;
                     &amp;#40;#\Can 65 110 100 32 84 104 105 115 32 111 110 101 46 46 46&amp;#41;
                     &amp;#40;#\Em 65 110 100 32 69 118 101 110 32 84 104 105 115 32 111 110 101 46 46 46&amp;#41;
                     &amp;#40;#\Sub 73 32 116 104 105 110 107 32 73 39 118 101 32 109 97 100 101 32 109 121
                      32 112 111 105 110 116 46&amp;#41;
                     &amp;#40;#\Rs 65 108 115 111 32 115 111 114 114 121 32 102 111 114 32 116 104 101 32
                      99 111 109 109 97 110 100 32 108 105 110 101 32 105 110 116 101 114 102 97 99
                      101 46&amp;#41;
                     &amp;#40;#\! 73 32 119 114 111 116 101 32 97 32 114 101 97 108 108 121 32 110 105 99
                      101 32 71 85 73 32 117 115 105 110 103 32 81 116 53 32 97 110 100 32 80 121
                      116 104 111 110 46&amp;#41;
                     &amp;#40;#\$ 66 85 84 44 32 98 101 99 97 117 115 101 32 121 111 117 32 97 115 115 104
                      111 108 101 115 32 117 115 101 32 101 118 101 114 121 32 111 116 104 101 114
                      32 115 104 105 116 116 121 32 79 112 101 114 97 116 105 110 103 32 83 121 115
                      116 101 109 32 107 110 111 119 110 32 116 111 32 109 97 110 46 46 46&amp;#41;
                     &amp;#40;#\' 73 32 104 97 118 101 32 116 111 32 99 114 111 115 115 45 99 111 109 112
                      105 108 101 32 116 104 105 115 32 97 99 114 111 115 115 32 87 105 110 100 111
                      119 115 44 32 77 97 99 44 32 97 110 100 32 76 105 110 117 120 46&amp;#41;
                     &amp;#40;#\&amp;#42; 65 110 100 32 105 116 32 116 117 114 110 115 32 111 117 116 32 115 101
                      116 116 105 110 103 32 117 112 32 112 121 116 104 111 110 32 97 110 100 32 81
                      116 53 32 111 110 32 97 108 108 32 116 104 111 115 101 32 112 108 97 116 102
                      111 114 109 115 46 46 46&amp;#41;
                     &amp;#40;#\- 73 115 32 97 32 103 105 97 110 116 32 112 97 105 110 32 105 110 32 116
                      104 101 32 97 115 115 46&amp;#41;
                     &amp;#40;#\0 46 46 46 69 115 112 101 99 105 97 108 108 121 32 111 110 32 87 105 110
                      100 111 119 115 46 46 46 40 84 104 97 110 107 115 32 77 105 99 114 111 115
                      111 102 116 41&amp;#41;
                     &amp;#40;#\2 40 83 99 114 101 119 32 121 111 117 32 80 101 116 101 114 32 58 80 41&amp;#41;
                     &amp;#40;#\7 83 111 44 32 73 32 100 101 99 105 100 101 100 32 116 111 32 115 99 114 97
                      112 32 116 104 101 32 71 85 73 32 97 110 100 32 106 117 115 116 32 117 115
                      101 32 109 121 32 112 121 116 104 111 110 32 99 111 100 101 46&amp;#41;
                     &amp;#40;#\: 72 111 119 101 118 101 114 44 32 99 111 109 112 105 108 105 110 103 32
                      105 116 32 119 105 116 104 32 116 104 101 32 114 105 103 104 116 32 118 101
                      114 115 105 111 110 32 111 102 32 112 121 116 104 111 110 32 111 110 32 97
                      108 108 32 116 104 101 32 112 108 97 116 102 111 114 109 115 46 46 46&amp;#41;
                     &amp;#40;#\= 87 97 115 32 97 108 115 111 32 97 32 112 97 105 110 32 105 110 32 116 104
                      101 32 97 115 115 46&amp;#41;
                     &amp;#40;#\@ 65 105 110 39 116 32 110 111 98 111 100 121 32 103 111 116 32 116 105 109
                      101 32 102 111 114 32 116 104 97 116 46&amp;#41;
                     &amp;#40;#\C 83 111 44 32 73 32 104 97 100 32 116 111 32 114 101 45 119 114 105 116
                      101 32 109 121 32 99 111 100 101 32 105 110 32 67 111 109 109 111 110 32 76
                      105 115 112 46&amp;#41;
                     &amp;#40;#\F 76 117 99 107 105 108 121 44 32 73 32 97 109 32 97 32 112 114 111 102 101
                      115 115 105 111 110 97 108 32 76 105 115 112 32 80 114 111 103 114 97 109 109
                      101 114 46&amp;#41;
                     &amp;#40;#\I 66 117 116 32 115 116 105 108 108 46 46 46 32 87 84 70 46&amp;#41;
                     &amp;#40;#\M 66 97 115 105 99 97 108 108 121 44 32 116 104 101 32 109 111 114 97 108
                      32 111 102 32 116 104 105 115 32 115 116 111 114 121 32 105 115 58&amp;#41;
                     &amp;#40;#\P 73 102 32 121 111 117 32 106 101 114 107 115 32 97 108 108 32 117 115 101
                      100 32 76 105 110 117 120 44 32 73 32 119 111 117 108 100 110 39 116 32 111
                      102 32 104 97 100 32 116 104 101 115 101 32 105 115 115 117 101 115 46&amp;#41;
                     &amp;#40;#\S 83 111 32 115 111 114 114 121 32 105 102 32 121 111 117 32 119 111 117
                      108 100 32 112 114 101 102 101 114 32 97 32 110 105 99 101 32 71 85 73 32 97
                      112 112 32 105 110 115 116 101 97 100 32 111 102 32 97 32 116 104 105 115 32
                      99 111 109 109 97 110 100 32 108 105 110 101 32 111 110 101 46&amp;#41;
                     &amp;#40;#\V 66 117 116 32 105 116 39 115 32 114 101 97 108 108 121 32 121 111 117 114
                      32 100 97 109 110 32 102 97 117 108 116 46 32 40 58 80 41&amp;#41;
                     &amp;#40;#\Y 65 110 100 32 98 101 115 105 100 101 115 44 32 116 104 101 114 101 32 105
                      115 32 110 111 116 104 105 110 103 32 119 114 111 110 103 32 119 105 116 104
                      32 116 104 101 32 99 111 109 109 97 110 100 32 108 105 110 101 46&amp;#41;
                     &amp;#40;#\\ 66 117 116 32 73 32 100 105 103 114 101 115 115 46&amp;#41;
                     &amp;#40;#\&amp;#95; 73 32 110 111 116 105 99 101 32 119 101 32 97 114 101 32 110 101 97 114
                      108 121 32 97 116 32 49 48 48 37 46 46 46&amp;#41;
                     &amp;#40;#\b 83 111 32 73 32 103 117 101 115 115 32 73 32 115 104 111 117 108 100 32
                      115 116 111 112 32 114 97 110 116 105 110 103 32 97 110 100 32 115 104 111
                      119 32 121 111 117 32 116 104 101 32 109 101 115 115 97 103 101 46 46 46&amp;#41;
                     &amp;#40;#\d 70 105 110 101 32 58 41 46&amp;#41;&amp;#41;&amp;#41;
         &amp;#40;decrypted-messages &amp;#40;decode-pair-list messages&amp;#41;&amp;#41;&amp;#41;

    &amp;#40;format t &amp;quot;&amp;#126;a&amp;#126;%&amp;quot; &amp;#40;decode-message '&amp;#40;68 101 99 114 121 112 116 105 110 103 32 77 101 115 115 97 103 101 58&amp;#41;&amp;#41;&amp;#41;

    &amp;#40;dotimes &amp;#40;i 101&amp;#41; 
      &amp;#40;cond &amp;#40;&amp;#40;equal i &amp;#40;caar decrypted-messages&amp;#41;&amp;#41;
             &amp;#40;format t &amp;quot;&amp;#126;d% &amp;#126;a   &amp;#126;a &amp;#126;%&amp;quot; i &amp;#40;decode-message '&amp;#40;67 111 109 112 108 101 116 101 46&amp;#41;&amp;#41;
                     &amp;#40;cdar decrypted-messages&amp;#41;&amp;#41;
             &amp;#40;setf decrypted-messages &amp;#40;cdr decrypted-messages&amp;#41;&amp;#41;&amp;#41;
            &amp;#40;t
             &amp;#40;format t &amp;quot;&amp;#126;d% &amp;#126;a&amp;#126;%&amp;quot; i  &amp;#40;decode-message '&amp;#40;67 111 109 112 108 101 116 101 46&amp;#41;&amp;#41;&amp;#41;&amp;#41;&amp;#41;
      &amp;#40;sleep 1&amp;#41;&amp;#41;&amp;#41;&amp;#41;

&amp;#40;defun secret-message &amp;#40;&amp;#41;
  &amp;#40;format t &amp;quot;&amp;#126;%&amp;#126;a&amp;#126;%&amp;#126;%&amp;#126;%- &amp;#126;a&amp;#126;%&amp;#126;%&amp;quot; 
          &amp;#40;decode-message '&amp;#40;83 111 44 32 112 117 116 116 105 110 103 32 97 108 108 32 106 111 107 101 115
                            32 97 110 100 32 110 101 114 100 121 45 110 101 115 115 32 97 115 105 100 101
                            44 32 73 32 100 111 32 104 97 118 101 32 97 110 32 105 109 112 111 114 116 97
                            110 116 32 113 117 101 115 116 105 111 110 32 116 111 32 97 115 107 46 32 65
                            115 32 121 111 117 32 97 114 101 32 112 114 111 98 97 98 108 121 32 97 119 97
                            114 101 44 32 82 101 98 101 99 99 97 32 97 110 100 32 73 32 97 114 101 32 102
                            105 110 97 108 108 121 32 103 101 116 116 105 110 103 32 109 97 114 114 105
                            101 100 32 105 110 32 83 101 112 116 101 109 98 101 114 46 32 84 104 105 115
                            32 105 115 32 119 105 108 108 32 98 101 32 97 32 118 101 114 121 32 115 112
                            101 99 105 97 108 32 42 68 65 89 42 32 105 110 32 109 121 32 108 105 102 101
                            44 32 97 110 100 32 97 115 32 97 32 118 101 114 121 32 115 112 101 99 105 97
                            108 32 42 80 69 82 83 79 78 42 32 105 110 32 109 121 32 108 105 102 101 44 32
                            73 32 119 111 117 108 100 32 108 105 107 101 32 116 111 32 97 115 107 58 32 32
                            87 105 108 108 32 121 111 117 32 98 101 32 111 110 101 32 111 102 32 109 121
                            32 103 114 111 111 109 115 109 101 110 63&amp;#41;&amp;#41;
          &amp;#40;decode-message '&amp;#40;82 121 97 110&amp;#41;&amp;#41;&amp;#41;&amp;#41;

&amp;#40;defun encode-message &amp;#40;message&amp;#41;
  &amp;#40;mapcar #'char-code &amp;#40;concatenate 'list message&amp;#41;&amp;#41;&amp;#41;

&amp;#40;defun decode-message &amp;#40;num-list&amp;#41;
  &amp;#40;map 'string #'code-char num-list&amp;#41;&amp;#41;

&amp;#40;defun encode-pair-list &amp;#40;pair-list&amp;#41;
  &amp;#40;mapcar &amp;#40;lambda &amp;#40;pair&amp;#41; &amp;#40;cons &amp;#40;code-char &amp;#40;car pair&amp;#41;&amp;#41; &amp;#40;encode-message &amp;#40;cdr pair&amp;#41;&amp;#41;&amp;#41;&amp;#41; pair-list&amp;#41;&amp;#41;

;;&amp;#40;load &amp;quot;decryptMessage.cl&amp;quot;&amp;#41;

&amp;#40;defun decode-pair-list &amp;#40;pair-list&amp;#41;
 &amp;#40;mapcar &amp;#40;lambda &amp;#40;pair&amp;#41; &amp;#40;cons &amp;#40;char-code &amp;#40;car pair&amp;#41;&amp;#41; &amp;#40;decode-message &amp;#40;cdr pair&amp;#41;&amp;#41;&amp;#41;&amp;#41; pair-list&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;a name=&quot;message&quot;&gt;&lt;/a&gt;Message&lt;/h2&gt;&lt;p&gt;After putting up with my ranting, I finally posted the message asking the guys to be my groomsmen. It read:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; So, putting all jokes and nerdy-ness aside, I do have an important  question to ask. As you are probably aware, Rebecca and I are finally  getting married in September. This is will be a very special &lt;em&gt;DAY&lt;/em&gt; in  my life, and as a very special &lt;em&gt;PERSON&lt;/em&gt; in my life, I would like to  ask:  Will you be one of my groomsmen?&lt;br /&gt;&lt;/p&gt;&lt;p&gt; Ryan &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;About 2 days after we mailed out the letters, all of then intended groomsmen had messaged me back, confirming that they would be my groomsmen. I also think they enjoyed my methods of asking.&lt;/p&gt;&lt;p&gt;I guess I was successful in asking everyone in a very &quot;Ryan-like&quot; fashion.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;UPDATE&lt;/strong&gt;: The &lt;a href='https://github.com/himmAllRight/groomsmen-ask'&gt;source code repo&lt;/a&gt; for this little project is now publically available on my &lt;a href='https://github.com/himmAllRight'&gt;Github Page&lt;/a&gt;.&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Wed, 06 Jan 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://ryan.himmelwright.net/posts/25-days-of-c/
</guid>
<link>
http://ryan.himmelwright.net/posts/25-days-of-c/
</link>
<title>
25 Days of C
</title>
<description>
&lt;p&gt;As I continue to learn more and more programming languages, I am somewhat ashamed to admit that I have yet to learn C. However, it is not because I am trying to avoid it.&lt;/p&gt;&lt;p&gt;&lt;!&amp;ndash; more &amp;ndash;&gt;&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;the&amp;#95;reason&quot;&gt;&lt;/a&gt;The Reason&lt;/h2&gt;C is one of the top languages I wish to know, and know well. C is the backbone for so much code, especially in the Linux ecosphere that it is almost imperative for one to at least understand it. I keep trying to poke my head into open source projects, and so many of them are built or based on C (especially when looking at projects more at the distro and distro applications level).&lt;p&gt;Also, this spring I will start working on my CS MS degree, and while I think the first course I take will be theory based, I know several other courses that will require it (ex: computer architecture and compilers). Being comfortable with C will allow me to focus on the topics, and not on the syntax.&lt;/p&gt;&lt;p&gt;I have some experience with C++ from my software engineering course I took during undergrad, but that is about it. My goal however is to understand just plain C, which will hopefully make implementing other C-based languages such as C++ a bit easier. My ultimate goal is to eventually have C be one of my top 3 languages (I'm thinking LISP, C, and maybe python or ruby. I know. I'm old school.).&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;the&amp;#95;plan&quot;&gt;&lt;/a&gt;The Plan&lt;/h2&gt;&lt;p&gt;In the last few weeks, I have set up and started looking at &lt;a href='http://c.learncodethehardway.org/book/'&gt;Learn C the Hard Way&lt;/a&gt;. I read the first section or two, but haven't been consistent with working through it.&lt;/p&gt;&lt;p&gt;Now that it is December, I thought I should maybe start a new monthly challenge, or even a &quot;12/25 days till something&quot;. I was thinking about things I've been trying to constantly work on the last few months, and C popped into my head. Learn C the Hard Way fits particularly well because it is broken down nicely into small segments that I can maybe commit to being able to finish 1 per day.&lt;/p&gt;&lt;p&gt;I have to look ahead a bit to see if this challenge is doable, but i think that as of now, the plan is to try to complete at least 1 (I can work ahead if I want to) segment of the book a day for the month of December. I am also going to allow myself the ability to &quot;pre-cache&quot; segments ahead of time so that I don't have to pull away and work on it during the holidays if I don't want to.&lt;/p&gt;&lt;p&gt;Overall, I think this is a good plan that should allow me to start getting some C experience under my belt. I'll be sure to update in the future with how it goes.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;update&quot;&gt;&lt;/a&gt;Update&lt;/h2&gt;&lt;p&gt;So, now that I have made it a good bit through the month, I must admit that I have not adhered to this challenge very strictly. I have done many of the exercises, but I have fallen somewhat behind. Basically, I accomplished a bunch of other things and let this challenge slide. I will continue to work on it, but I haven't been able to keep with with the one exercise per day rate. Oh well.&lt;/p&gt;
</description>
<author>
Ryan Himmelwright
</author>
<enclosure>

</enclosure>
<pubDate>
Thu, 24 Dec 2015 00:00:00 -0500
</pubDate>
</item>
</channel>
</rss>
